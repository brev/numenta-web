---
author: Rob Haitani
brief: Will the future of machine intelligence lead to evil robots and a dystopian apocalypse?  Or robotic butlers and immortal carriers of our memories?  Berkeley
date: 2012/12/13
featured: false
image: ../images/image.png
org: Marketing
tags: Machine Learning, Neuroscience
title: Jeff Hawkins on Skynet vs. C3PO
type: post
---

Will the future of machine intelligence lead to evil robots and a dystopian
apocalypse?  Or robotic butlers and immortal carriers of our memories?  Berkeley
recently uploaded a [video](https://www.youtube.com/user/numenta) of a talk by
Jeff Hawkins that concludes with his thoughts about the future of intelligent
machines.

Most people assume that intelligent machines will be like humans. Instead, Jeff
starts by defining what intelligence is, then removing humans from the equation
and asking what would happen if we applied these principles.  This doesn't
necessarily lead us to C3PO.

In the Berkeley lecture, Jeff states his opinions on whether or not certain
technical advances will happen.   First, it seems inevitable that intelligent
machines will reap the benefits of removing biological constraints.  Our brains
are very slow, and limited in capacity due to the size of the birth canal
("Nature might want to make bigger brains, but they don't come out," Jeff
jokes.)  Intelligent machines will be millions of times faster and with much
larger memory capacity than human brains.  In addition, these machines will not
be limited by human senses.  "Everything a human has to understand we have to
put into something that runs at our speed and through our senses."  Imagine
feeding into intelligent machines input from huge arrays of distributed sensors,
or nano-sensors, or higher-dimensional sensors.  "If I had sensors that really
could live in that world, they could think in that world."

On the other hand, Jeff is skeptical that you will ever be able to upload your
brain to a machine and live forever.  And even if you could, it would be "a very
unsatisfactory experience," at least from the mortal biological perspective
(i.e., yours).  It would probably be more like the Twilight Zone episode where
you are replaced by an exact duplicate.

Jeff also doesn't believe that evil robots will emerge, at least not as an
unintended byproduct. There are simply too many obstacles to overcome even if
evil robots were your intended output.  But he doesn't kid himself into thinking
that intelligent machines will only be used for benign purposes. Any powerful
technology can be used for malevolent purposes.

In closing, Jeff argues that intelligent machines will be "essential for the
survival of our species, and...our mission as a species."  Not only will
intelligent machines provide net benefits to the world in the same way that
computers have, but they will also enable us to discover more about the
universe. For example, Jeff doubts humans will ever explore deep space, but
intelligent machines could.  The Bradbury fan in me hopes this is not true.  But
the point is that even if we did figure out how to send humans into deep space,
it will always be easier and cheaper to send our machines.

Ultimately it boils down to the fact that "we want to know more about things,”
and  “today our brains are how we figure out more."   Therefore, it’s logical to
conclude that an exponential expansion of (machine) intelligence will lead to an
exponential expansion in knowledge.  That's a long way in the future, but here
at Numenta we're passionate about setting humanity on that path.
