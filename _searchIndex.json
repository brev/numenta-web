[{"path":"/404/","text":"Page Not Found Page Not FoundSorry, the page you were looking for does not exist (404). - Please Contact Us if you are having problems, and we will respond as soon as possible. - Visit the Numenta.com homepage for more information. Page Not Found","title":"Page Not Found"},{"path":"/500/","text":"Website Server Error Website Server ErrorSorry, this website is experiencing technical difficulties (500). - Please Contact Us if you are having problems, and we will respond as quickly as possible. - Visit the Numenta.com homepage for more information. Website Server Error","title":"Website Server Error"},{"path":"/anomaly-detection-benchmark/","text":"Anomaly Detection Benchmark Anomaly Detection Benchmark Sensors and data streams are proliferating as the Internet of Things vision becomes realized. However, using the data from these sensors is not so easy. Specifically, being able to identify anomalies in streaming data is surprisingly difficult. Most techniques are a form of thresholds, i.e. predetermined limits that must be set to notify abnormalities. However, thresholds have some glaring weaknesses, including often finding a problem after it has happened, not before, and not adapting to new states, such that false positives can crowd out the important signal. We created the Numenta Anomaly Benchmark (NAB) in order to be able to measure and compare results from algorithms designed to find anomalies in streaming data. NAB is an open source framework consisting of: - A dataset with real-world, labeled data files - A scoring mechanism that rewards early detection and on-line learningResources - Business Paper: The Numenta Anomaly Benchmark - Technical Peer-Reviewed Paper: Evaluating Real-time Anomaly Detection Algorithms the Numenta Anomaly Benchmark - More InformationNext: Papers, Videos & More ","title":"Anomaly Detection Benchmark"},{"path":"/applications/","text":"Applications Applications Video: Intro to our Applications (02:32) While Numenta does not build commercial applications, we have created example HTM applications in several fields such as monitoring stock performance, detecting unusual human behavior, and finding patterns in geospatial data. Additionally, our partners have created commercial applications in the field of monitoring IT infrastructure and understanding natural language. We are confident that many additional applications will be created in the future. HTM is well suited for applications that have the following characteristics: - Data flowing through time: the data can be in the form of numbers, dates, text, or GPS points - A data sampling rate from once per minute to once per hour, with the sweet spot being between once per minute and once every five minutes (faster velocity data can be aggregated or sampled as well) - Data that has inherent structure, i.e. not entirely random - Many models are required rather than one large model - Focus of the application is prediction or anomaly detection The following applications are examples that fit these characteristics: - Highlighting anomalies in the behavior of moving objects, such as tracking a fleet s movements on a truck by truck basis - Understanding if human behavior is normal or abnormal on a securities trading floor - Predicting energy usage for a utility on a customer by customer basis - Predicting failure in a complex machine based on data from many sensors In order to demonstrate these capabilities, we have created several tools and example applications.HTM Studio for Anomaly Detection HTM Studio for Anomaly Detection is a tool that makes it easy to experiment with using HTM to detect anomalies in your own scalar data. Designed for the business-focused user, this tool makes it easy to develop a proof of concept with HTM technology without doing any coding. - More Information - Register to Give FeedbackHTM for Stocks HTM for Stocks is an example application that detects anomalies in publicly traded companies. It continuously models stock price, stock volume, and Twitter volume for top publicly traded companies and alerts you in real time when something unusual is happening. HTM for Stocks is available for free via the App Store or Google Play Store. - More Information - Register to Give FeedbackGrok Grok is a commercial application offered by one of our strategic partners that detects anomalies in servers and applications. It learns continuously, automatically discovers time-based patterns in data, and generalizes from experience. Grok is now available at http://grokstream.com . - Sign Up - More InformationRogue Behavior Detection This example application models normal behavior of individuals by detecting changes in behavior, such as unusual use of files. You can experiment with this application using your own data by downloading our sample application code below. - Whitepaper: HTM for Rogue Behavior - Download Application CodeGeospatial Tracking The example geospatial tracking application detects anomalies in the movement of people, objects, or material using speed and location data. Use this application to enable logistics optimization. You can experiment with this application using your own data by downloading our sample application code below. - Whitepaper: HTM for Geospatial Tracking - Download Application CodeNatural Language Processing One of our partners, Cortical.io, has used Numenta s technology to develop and commercialize Natural Language Processing Solutions. By representing language with highly efficient semantic fingerprints, Cortical.io has built the first semantic engine that can analyze text in real time, in any language. - More InformationNext: Partners ","title":"Applications"},{"path":"/biological-and-machine-intelligence/","text":"Biological and Machine Intelligence (BAMI) Biological and Machine Intelligence (BAMI)Book Sections 1. Introduction 2. HTM Overview 3. Sparse Distributed Representations 4. Encoders 5. Content to be Incorporated 6. Problem Sets 7. Glossary Biological and Machine Intelligence (BAMI) is a living book authored by Numenta researchers and engineers. Its purpose is to document Hierarchical Temporal Memory, a theoretical framework for both biological and machine intelligence. While there s a lot more work to be done on HTM theory, we have made good progress on several components of a comprehensive theory of the neocortex and how to apply that knowledge to practical applications. We would like to share our work as we go. We hope this book will become the standard reference for people who want to learn about HTM cortical theory and its applications for machine intelligence. Going forward we anticipate using two main forms of documentation of our research, one is published research papers and the other is additions to this book, Biological and Machine Intelligence. Just as we make all of our research and technology available in open source, we want to be transparent with this manuscript as well, even well-ahead of its completion. When it is finished, this book will cover all the fundamental concepts of HTM theory. For now, we are sharing the chapters that have been completed, each of which contains a revision history, so you can see what has changed in each chapter. Over time, we will add chapters to BAMI. The Content to be Incorporated section has place holders for new chapters. Importantly, it contains links to updated psuedocode for the current Spatial Pooler and Temporal Memory algorithms. It also has links to scientific papers and other material that cover topics we intend to make into chapters. We welcome your feedback and comments. We will make revisions available on an occasional basis. If you want to be notified about additions and revisions, please follow this Twitter feed: @NumentaBAMI.Citing the Book This release of Biological and Machine Intelligence is not close to being complete, so the book is not formally published . However, we encourage you to cite this book in your own work by using one of these formats:End Reference Hawkins, J. et al. 2016. Biological and Machine Intelligence. Release 0.4. Accessed at http://numenta.com /biological-and-machine-intelligence/ . Bibtex @unpublished{Hawkins-et-al-2016-Book, title={Biological and Machine Intelligence (BAMI)}, author={Hawkins, J. and Ahmad, S. and Purdy, S. and Lavin, A.}, note={Initial online release 0.4}, url={http://numenta.com /biological-and-machine-intelligence/ }, year={2016} } Note that some of the material in BAMI has been formally published; you can look at these papers to get the appropriate citations. ","title":"Biological and Machine Intelligence (BAMI)"},{"path":"/blog/2012/05/23/streams-and-lakes/","text":"Streams and Lakes Wed, May 23, 2012 BlogStreams and Lakes Jeff Hawkins Founder Two weeks ago I attended a workshop at U.C. Berkeley titled, From Data to Knowledge: Machine-Learning with Real-time and Streaming Applications. This was a remarkable workshop, not just because of who presented or its location, but simply because it was a workshop on streaming analytics. Today we hear so much about big data and the database tools you can use to sort through large amounts of data. However at Numenta we see a different future. The future we see is one with billions of data sources streaming data. Every building, server, machine, and windmill will be equipped with multiple sensors. Data from these sensors will flow directly to predictive models, which will make predictions and detect anomalies. Through these models we will take immediate action. This future is about billions of data streams flowing to hundreds of millions of predictive models, not petabytes of data sitting in hard drives to be looked at later, hence Streams and Lakes. This isn t an either or situation. There is plenty of opportunity mining big data repositories, but we believe the growth will occur mostly in the proliferation of data sources and the ability to act on data as soon as it is created. For example, imagine a building adjusting its energy consumption minute-by-minute based on predictions of price and demand several hours in the future. If the price of electricity is predicted to go up later in the day, the building lowers its temperature now and so it can turn off the cooling later, saving money. Today we may do this for a campus or building, tomorrow your refrigerator will do the same. Predictive models for streaming data are fundamentally different than models used on stored data. In my talk at the Berkeley workshop, titled Modeling Data Streams Using Sparse Distributed Representations, I focused on two essential and unique attributes of streaming models. First, they must be online. This means that the models have to learn with each new record. Online models automatically adjust, record by record, as the patterns in the data change. Second, streaming models also must be variable order temporal models. To make good predictions, a model might need to take into account what happened two steps ago, four steps ago, or ten steps ago. Patterns over time, like a melody, are usually more important than what is happening now. At the heart of our product Grok is a novel learning algorithm that is inherently online and variable order. This isn t surprising because it models a slice of the neocortex, which is also online and variable order. Although much of the detail in how these algorithms work is explained in the white paper on our website, my 25-minute talk at Berkeley covered the essentials, yet is simpler and easier to understand. The workshop organizers recorded my talk and posted it online, but the audio is separate from the visuals. We decided to re-record it as a screencast. By the way, I believe the algorithms we use in Grok are key components of machine intelligence. I will be talking about that during my keynote speech on June 11 at the International Symposium on Computer Architecture. More on that in a later blog post. Jeff Hawkins Founder All Blog Posts Jeff Hawkins 2012/05/23 Founder Streams and Lakes","title":"Streams and Lakes"},{"path":"/blog/2012/06/04/how-is-groks-algorithm-different/","text":"How is Grok&#x27;s algorithm different? Mon, Jun 04, 2012 BlogHow is Grok's algorithm different? Subutai Ahmad VP Research NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. A question we get all the time from machine learning fans is: How does Numenta s Hierarchical Temporal Memory (the HTM) compare to traditional machine learning algorithms? There are many ways to answer this question. In this blog entry, I will focus on one specific difference, perhaps the most fundamental one. First a bit of background: There is a well known truism in machine learning, the \"No Free Lunch Theorem,\" which states that no algorithm is inherently better than any other algorithm. What distinguishes one algorithm from the next are the inherent assumptions and how well those assumptions fit the problem domain. For example, if you are predicting data that lies on a straight line, nothing is going to beat linear fitting. If the data lies on a circle, it s hard to imagine a worse technique. By far the most common assumption made in machine learning is the \"i.i.d\" assumption. In statistics, i.i.d. stands for independently and identically distributed, which states that every input record comes from the same probability distribution and is statistically independent of previous and future records. This is a very useful assumption - it makes the math easier, leads to the Central Limit Theorem, allows you to derive accuracy bounds, etc. Just about every popular technique, such as regression, support vector machines, neural networks, Bayesian networks, random forests, and decision trees rely on this assumption. Unfortunately, when you think about the real world of streaming data, this assumption is just plain wrong. Your weekly revenue numbers are not i.i.d. Last week s numbers are a better predictor than the numbers from 13 weeks ago. Yesterday s weather is correlated with today s. The web log for a customer navigating an e-commerce website is likely to follow specific sequences. Your GPS coordinates from 5 minutes ago are an excellent predictor of your current location. The list is endless. Streaming temporal patterns are the very antithesis of i.i.d. The HTM is an inherently temporal learning algorithm, and doesn t care about i.i.d. It greedily constructs sequences and does not assume independence. If you saw a particular revenue pattern the last two weeks, it assumes you are more likely to see it this week. If you haven t seen a pattern for several years, it will likely forget it. Also, HTM assumes that the underlying distribution can change. This is what makes it online or adaptive. If your revenue jumps because you just added an important customer, it will adapt. It inherently assumes your data stream contains sequences and is constantly changing. We didn t invent this - the core ideas are inherent in the neocortex of the brain and lend themselves well to streaming data analytics. HTM is not the only technique to break the i.i.d. assumption. Other algorithms, such as Hidden Markov Models and many time series algorithms, also relax that assumption. So, how is HTM different from HMMs? Good question. I guess we ll just have to tackle that in another blog entry stay tuned! Subutai Ahmad VP Research All Blog Posts Subutai Ahmad 2012/06/04 VP Research How is Grok's algorithm different?","title":"How is Grok&#x27;s algorithm different?"},{"path":"/blog/2012/08/27/the-problem-of-representation/","text":"The Problem of Representation Mon, Aug 27, 2012 BlogThe Problem of Representation Rob Haitani Marketing Years ago, a retiring artificial intelligence researcher told Jeff Hawkins that \"one of biggest problems in AI no, the only problem in AI is the problem of representation.\" If the meaning of that statement isn t intuitively obvious to you, don t worry. It wasn t immediately clear to Jeff either. Jeff explained how he came to understand and address this problem in a recent keynote address at the International Symposium on Computer Architecture. We posted a video of the keynote on YouTube. In this talk, Jeff describes the brain as a predictive modeling system that takes streams of input from the senses and learns sequences in real time. The brain represents its inputs and the state of its world via the activity of neurons. At any point in time most of the neurons are inactive and a few active, thus the brain s representations are sparse. Consequently we call these \"Sparse Distributed Representations (SDRs) in our algorithms. SDRs exhibit unique properties that enable benefits such as semantic generalization and robustness to errors. These properties, in turn, allow the brain to learn about objects and how they relate to each other holistically, without the programmatically defined data structures used in computers. By applying these principles in products like Grok, we can finally address the problem of representation. The talk ends with Jeff s speculation on how the technology will evolve. Grok itself is merely the first iteration of this technology. Unlocking the operating principles of the neocortex will not necessarily culminate in solutions addressing the classic AI problems of vision, language and speech. The history of technology suggests that truly revolutionary technological advancements develop in ways that even its inventors could never imagine. I m reminded of Alexander Graham Bell s prediction, One day there will be a telephone in every major city in the USA. If you d like to know more, make sure to watch the video. Rob Haitani Marketing All Blog Posts Rob Haitani 2012/08/27 Marketing The Problem of Representation","title":"The Problem of Representation"},{"path":"/blog/2012/09/06/big-datas-digital-nervous-system/","text":"Big Data&#x27;s Digital Nervous System Thu, Sep 06, 2012 BlogBig Data's Digital Nervous System Rob Haitani Marketing In a recent Forbes post, Ed Dumbill describes how computers have traditionally been used to digitize real-world business operations, for use in siloed computer applications. He refers to this as a \"digital exoskeleton\" that served as a support system for processes like payroll or inventory management. But a major shift is underway. The arrival of the Internet and web has added a new dimension, bringing in an era of entirely digital business. Customer interaction, payments and often product delivery can exist entirely within computer systems. In this new world, data isn t simply stored inside the exoskeleton. The key trait is to make an organization s feedback loop entirely digital. That is, a direct connection from sensing and monitoring inputs through to product outputs. These are the hallmarks of the digital nervous system. Dumbill concludes by saying we will need more sophisticated approaches to handle the challenges of massive data flows. It s easy to be intimidated by this vision if you are thinking in terms of conventional analytics. But it s only information overload if your method of processing the data is a bottleneck. If I had to sit down every night and analyze the entire day s input of sensory data to my brain, I would be overwhelmed. That s no way to run a nervous system. Fortunately, your brain processes sensory information in real time, and initiates action in response. So when you put your hand on a hot stovetop, you react immediately rather than waiting to build a regression model to incorporate when you detect sudden spikes in temperature. In fact, with visual input, you can predict you will burn your hand and avoid putting it on the stovetop altogether. This is where the nervous system metaphor enters the realm of the literal. As posted previously, Grok s algorithms are designed to replicate the learning and memory processes conducted by the neocortex. Grok learns patterns and makes predictions to drive action in the same way that your brain does. Modeling the neocortex may not be the only way of creating a learning and adaptive prediction engine, but the requirements of the digital nervous system referred to by Dumbill match perfectly with the capabilities of the neocortex. As the age of the digital nervous system dawns, Grok represents the type of technology that will convert massive data flows into value. Rob Haitani Marketing All Blog Posts Rob Haitani 2012/09/06 Marketing Big Data's Digital Nervous System","title":"Big Data&#x27;s Digital Nervous System"},{"path":"/blog/2012/10/01/jeff-hawkins-speaks-at-berkeley/","text":"Jeff Hawkins speaks this week at Berkeley Mon, Oct 01, 2012 BlogJeff Hawkins speaks this week at Berkeley Rob Haitani Marketing This week Jeff Hawkins will present two talks in the prestigious Berkeley Hitchcock Lectures series. Past lecturers include Niels Bohr, Edwin Hubble, Stephen Hawking, Richard Dawkins, and Noam Chomsky. We re proud of the recognition that Jeff s work has received in the academic community. The first lecture, on Tuesday October 2, is called Intelligence and the Brain: Recent Advances in Understanding How the Brain Works. Jeff will present the big picture of what we know so far, and then describe recent progress in a core issue: why neurons are arranged as they are in the neocortex, how this arrangement builds models of the world, and how these models make predictions and generate actions. On Wednesday October 3, Jeff will present his second lecture, Intelligence and Machines: Creating Intelligent Machines by Modeling the Brain. In this talk, Jeff tackles the question of whether intelligent machines are possible. (Spoiler alert: his answer is yes.) Jeff will argue that we can t treat the brain like a black box; the only way to build meaningful machine intelligence is to understand how the brain works, and build technology based on those principles. He will present his vision of how this technology will develop, and you may be surprised by what he has to say. On a personal note, I have been watching Jeff make presentations about his brain research since the early 90s, when I worked at Palm. Jeff used to give brown bag talks for the company at lunch called Brains 101, describing his theories as they developed. At that time, I didn t know an axon from a hole in the ground, but his passion was as obvious as it was contagious. If you have the chance to see Jeff speak live, I d highly recommend it! The lectures are open to the public, both starting at 4:10 pm at the International House Auditorium, 2299 Piedmont Avenue, Berkeley. More information can be found at the Berkeley Graduate Council Lectures website. If you can t make it, we will post links to the videos of the lectures. Rob Haitani Marketing All Blog Posts Rob Haitani 2012/10/01 Marketing Jeff Hawkins speaks this week at Berkeley","title":"Jeff Hawkins speaks this week at Berkeley"},{"path":"/blog/2012/10/07/wait-the-brain-is-a-bloom-filter/","text":"Wait, the brain is a Bloom filter? - @petrillic Sun, Oct 07, 2012 BlogWait, the brain is a Bloom filter? - @petrillic Ian Danforth Engineering This insightful tweet came from the Strangeloop keynote after Jeff Hawkins described Sparse Distributed Representations (SDRs). This isn t the first time someone has noticed that SDRs and Bloom filters use similar data structures, so we d like to describe the significant differences in their implementation and capabilities. Bloom filters are a fast and memory-efficient way to tell if you ve seen something before. They can tell you with 100% confidence that something is new, though they can t tell you for sure if an input has been seen before. (See this excellent visualization by Bill Mill). SDRs, core to Numenta s Cortical Learning Algorithm, are the way we represent and recognize inputs in a system like Grok: The concept of SDRs comes from neuroscience, where sometimes it is called sparse coding. SDRs are the language of brains in the same way that bytes and words are the language of digital computers. Sparse distributed representations have several desirable properties including high capacity, graceful degradation, tolerance to errors, and the ability to simultaneously represent multiple values in one representation. Both Bloom filters and SDRs store information in data structures called bit arrays (or vectors), long strings where each character is either a one or a zero. When encountering a new input, both create a representation of that input by selecting a set of those bits to set as ones, or as we say turn on. Because both choose a small subset of the bits to turn on, these representations can both be considered sparse. Both, depending on the size of the array, have a high capacity to store many inputs, and both can represent multiple inputs simultaneously. We need a bit more detail about Bloom filters to understand how they differ fundamentally from SDRs. To create a Bloom filter, you select one or more hashes. These are functions that take an input and select which small set of bits to turn on in the bit array. Three key properties determine the efficient and predictable nature of Bloom filters. Take, for example, a Bloom filter with three inputs: Monday , Thursday , Friday. In a Bloom filter, the output bits representing these inputs are uniformly distributed across the bit array. The representation of these outputs are independent of any similarities from the inputs. And each input always maps to the same output representations. SDRs, on the other hand, assume the exact opposite! Modeled after the brain, SDRs care about semantic relationships. We care that inputs with similar meanings are stored in similar ways. Because Thursday is much closer to Friday than it is to Monday, SDR representations of the inputs \"Thursday\" and Friday are similar! Semantic relationships allow an SDR to answer not only the question, Have you ever seen this? but also the question Have you ever seen something like this? Today we store inputs in a bit array that is 2000 bits long. Each new input turns on 40 of those bits. If two inputs are very similar they may share a good number of bits that get turned on (violating the independence assumption of Bloom filters) and if they are very different they will almost certainly have a very different set. Going back to our example, let s show a Bloom filter and an SDR the input \"Saturday.\" If Saturday contains a single bit that is not on in the filter, the Bloom filter confidently tells us it has never seen that before. An SDR, on the other hand, would say, Wait a minute, I ve seen something close to that, how about Friday ? An SDR is robust to some variations in input and is able to generalize based on semantic closeness of inputs to previously seen values. These properties are crucial in allowing Grok to correctly identify the same object in different circumstances. Similar inputs get blended, or, as we say, pooled together. When we retrieve values from our data structure even a small overlap on the input will generate some output. You could say our false positive rate is much higher than a Bloom filter. However, overlapping inputs allow us to group similar things together. Also because SDRs produce output when there are partial matches, they are tolerant of noise. We can recognize two similar inputs even if they are obscured, just like a human can recognize a loved-one s face even through the branches of a tree, or a familiar voice in a noisy room. A false positive for a Bloom filter, in contrast, doesn t mean anything. It s governed by chance, not semantic closeness. Bloom filters throw away similarities in inputs, whereas SDRs take advantage of them. SDRs also differ by having dynamic representations. They change over time. The same input doesn t always map to the same representation. When learning new things, which representation you end up with in the SDR depends on what the system has seen before. In addition if you haven t seen an input for a while its representation may have degraded somewhat. Because SDRs retain representations strongly that are regularly reinforced and forget ones that are not, SDRs learn and retain the most important inputs without getting filled up by noise. A Bloom filter is static and will continue to get filled up for as long as it continues to see new inputs. But then again, a Bloom filter that \"forgot\" wouldn t be very useful. As you can see, combining values and storing them in a bit array is a powerful idea. You can end up with a memory-efficient test like the Bloom filter, or a learning system that is general purpose, robust, adaptive, and high capacity like SDRs. There s actually much more to SDRs. I ve only described the use of SDRs in a component of our system called the Spatial Pooler. There s a whole other set of representations in our Temporal Pooler that we don t have time to go into here. You can find more information on SDRs, their properties and how they relate to the brain, in another recent keynote by Jeff Hawkins. For more information on Bloom filters, the wikipedia article is reasonably accessible. Ian Danforth Engineering All Blog Posts Ian Danforth 2012/10/07 Engineering Wait, the brain is a Bloom filter? - @petrillic","title":"Wait, the brain is a Bloom filter? - @petrillic"},{"path":"/blog/2012/10/22/jeff-hawkins-at-strange-loop/","text":"Jeff Hawkins at Strange Loop Mon, Oct 22, 2012 BlogJeff Hawkins at Strange Loop Rob Haitani Marketing Jeff Hawkins recently gave a keynote address at Strange Loop 2012, a multi-disciplinary conference on diverse topics like emerging languages, alternative databases, concurrency and distributed systems. This talk was similar to the keynote speech Jeff gave at the recent ISCA Conference, providing a good overview of the neuroscience and technology behind Grok (e.g.,sparse distributed representations and sequence memory). In this version, Jeff shows an example of how Grok adapts to unexpected change when predicting energy consumption in a building. At first, Grok learns a weekly pattern: energy usage climbs during the day, but drops at night and on weekends, when the building is closed. One week, however, Thursday and Friday are holidays, so the building is closed. Grok predicts that energy will rise on Thursday morning, only to see that its predictions are inaccurate, because energy consumption remains flat in the empty building. Instead of blindly forging ahead with the rest of the regular Thursday pattern, however, Grok adapts automatically and shifts its forecast to predict flat levels. Grok was not trained with data for holidays, but it recognizes that the pattern has changed and adapts accordingly. Jeff also spends a little more time talking about the future of the technology, including the somewhat contrarian opinion that The goal here is not to build human-like things, it s not to pass the Turing Test. I have no interest in that whatsoever. I want to build machines that are useful for humans. The real potential of the technology lies in machines that can think millions of times faster than humans. These machines could have memory systems much larger than the human brain, with creative sensor arrays detecting patterns outside the realm of what humans can perceive intuitively. But they wouldn t get tired and would have neither desires nor sentience. These will be tools that enhance knowledge discovery; they could be the machines that we can send out to explore the universe. You can watch the video here. Rob Haitani Marketing All Blog Posts Rob Haitani 2012/10/22 Marketing Jeff Hawkins at Strange Loop","title":"Jeff Hawkins at Strange Loop"},{"path":"/blog/2012/12/13/jeff-hawkins-on-skynet-vs-c3po/","text":"Jeff Hawkins on Skynet vs. C3PO Thu, Dec 13, 2012 BlogJeff Hawkins on Skynet vs. C3PO Rob Haitani Marketing Will the future of machine intelligence lead to evil robots and a dystopian apocalypse? Or robotic butlers and immortal carriers of our memories? Berkeley recently uploaded a video of a talk by Jeff Hawkins that concludes with his thoughts about the future of intelligent machines. Most people assume that intelligent machines will be like humans. Instead, Jeff starts by defining what intelligence is, then removing humans from the equation and asking what would happen if we applied these principles. This doesn t necessarily lead us to C3PO. In the Berkeley lecture, Jeff states his opinions on whether or not certain technical advances will happen. First, it seems inevitable that intelligent machines will reap the benefits of removing biological constraints. Our brains are very slow, and limited in capacity due to the size of the birth canal ( Nature might want to make bigger brains, but they don t come out, Jeff jokes.) Intelligent machines will be millions of times faster and with much larger memory capacity than human brains. In addition, these machines will not be limited by human senses. Everything a human has to understand we have to put into something that runs at our speed and through our senses. Imagine feeding into intelligent machines input from huge arrays of distributed sensors, or nano-sensors, or higher-dimensional sensors. If I had sensors that really could live in that world, they could think in that world. On the other hand, Jeff is skeptical that you will ever be able to upload your brain to a machine and live forever. And even if you could, it would be a very unsatisfactory experience, at least from the mortal biological perspective (i.e., yours). It would probably be more like the Twilight Zone episode where you are replaced by an exact duplicate. Jeff also doesn t believe that evil robots will emerge, at least not as an unintended byproduct. There are simply too many obstacles to overcome even if evil robots were your intended output. But he doesn t kid himself into thinking that intelligent machines will only be used for benign purposes. Any powerful technology can be used for malevolent purposes. In closing, Jeff argues that intelligent machines will be essential for the survival of our species, and our mission as a species. Not only will intelligent machines provide net benefits to the world in the same way that computers have, but they will also enable us to discover more about the universe. For example, Jeff doubts humans will ever explore deep space, but intelligent machines could. The Bradbury fan in me hopes this is not true. But the point is that even if we did figure out how to send humans into deep space, it will always be easier and cheaper to send our machines. Ultimately it boils down to the fact that we want to know more about things, and today our brains are how we figure out more. Therefore, it s logical to conclude that an exponential expansion of (machine) intelligence will lead to an exponential expansion in knowledge. That s a long way in the future, but here at Numenta we re passionate about setting humanity on that path. Rob Haitani Marketing All Blog Posts Rob Haitani 2012/12/13 Marketing Jeff Hawkins on Skynet vs. C3PO","title":"Jeff Hawkins on Skynet vs. C3PO"},{"path":"/blog/2013/01/03/the-neuroscience-behind-grok/","text":"The Neuroscience Behind Grok, Part 1 Thu, Jan 03, 2013 BlogThe Neuroscience Behind Grok, Part 1 Rob Haitani Marketing NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. We modeled Grok after the human brain because the brain is a predictive modeling system. This is the first post in a series describing what this means: how the brain works, and how this benefits Grok. The content is based on lectures given by Jeff Hawkins describing his detailed, biologically accurate model of a layer of cells in the neocortex, called the Cortical Learning Algorithm (CLA). Contrary to popular opinion, the brain does not compute. Neural activity bears little resemblance to how computers (or neural networks, for that matter) operate. For example, an outfielder does not catch a pop fly by computing a projectile trajectory equation. Instead, she predicts where the ball will fall based on sensory input, starting with the crack of the bat. She makes rapid adjustments in speed and direction, reconciling predictions with the stream of sensory input received as the ball approaches. It turns out this predictive capability is a fundamental principle of intelligence. You constantly make small predictions of what you will see, feel or hear. When you drink coffee, you make a series of predictions about the sensory feedback you ll receive as you bring the cup to your mouth. You re usually unaware of these predictions unless they are violated. For example if the coffee is cold, or you accidentally grabbed a cup of pens, you are surprised. Detecting such anomalies is the flip side of making predictions, and the brain uses both to drive behavior. This activity occurs in the neocortex, the wrinkled outer part of your brain. When you are born, your brain is essentially an empty vessel with structure but no content. As you are continuously bombarded with input from your senses, you begin to build a model of the world, based on the recurring patterns that you see. And bombarded is an understatement. Vision alone consists of an array of a million fibers on your optic nerve, flipping on and off in milliseconds. What you see is not projected inside your head. Instead, the input from your eyes are electrical impulses transmitted at an estimated 10 million bits per second, translated in the darkness of your skull into our perception of images. In sum, you take massive streams of input, learn patterns to make models of everything in your world, and make predictions to generate action: a predictive modeling memory system. Your brain is actually far superior to computers at the generalized tasks of learning and pattern recognition (although obviously we can t compete with computers at executing tasks quickly and accurately). Grok s goal is to combine the best of both worlds. Future posts will summarize three key attributes of human intelligence that we implemented in Grok: Sparse Distributed Representations (SDRs), sequence memory and adaptive learning. For further reading: the basic principles of intelligence are described in Jeff Hawkins book, On Intelligence. His theories of sparse distributed representations were developed after the book was published, and are described further in our resources section. Rob Haitani Marketing All Blog Posts Rob Haitani 2013/01/03 Marketing The Neuroscience Behind Grok, Part 1","title":"The Neuroscience Behind Grok, Part 1"},{"path":"/blog/2013/01/27/introducing-the-first-ever-sparse-football-pool/","text":"Introducing the first ever Sparse Football Pool! Sun, Jan 27, 2013 BlogIntroducing the first ever Sparse Football Pool! Subutai Ahmad VP Research Win a Kindle Paperwhite and a copy of On Intelligence Did you ever think the Super Bowl could help you understand how your brain works? Well, it can! Numenta s core algorithm, the Hierarchical Temporal Memory (HTM), relies on the properties of Sparse Distributed Representations. SDRs are the fundamental way our brain represents information. The concepts behind SDR are deep and thought provoking. We get a lot of questions around this and were wondering how to explain it all in a fun simple way. Enter the Sparse Football Pool. We came up with a simple Super Bowl quiz with rules that closely mimic some operations in the CLA. We hope the quiz will be fun and at the same time illustrate some deep principles behind the SDR. The rules are extremely simple. How exactly do they relate to SDRs? We ll explain it all when we post the winner after the game, but for now here are two tidbits: 1) computing overlap is a fundamental operation with SDRs, and 2) when there are 30 questions and you choose 9, there are 14,307,150 possible combinations of entries! Also, in order to have more people participate, we re also offering a cool prize. The winner will receive a digital copy of On Intelligence as well as an Amazon Paperwhite Kindle. The Three Rules: 1. Answer TRUE or FALSE for each answer. 2. You cannot have more than 9 TRUE answers. If you enter more than 9 TRUE answers, we will take the first 9 only. 3. To figure out the winner, we will compute the overlap score between the actual answers and your answer. The person with the highest overlap score will win. Computing Overlap Score The overlap score simply gives you one point for every answer where you answered TRUE and the correct answer was TRUE. For example, if the answer to question 3 is True and you answered True, you get a point. In all other cases you don t get a point for question 3. Note that since you can only put down 9 TRUE s, the maximum overlap score you can get is 9. In case of ties, the earliest entry will win. (Also, if you submit more than one entry, only the last entry will count.) And Now, The Questions To enter, go to our online submission form. You will be asked to answer the following questions. They are repeated here for reference to help you plan out your answers ahead of time (responses will only be accepted through the online submission form). - The Baltimore Ravens will win the coin toss - There will be a lead change in the first half - There will be three lead changes in the game - There will be no lead changes in the game - The team leading at the end of the first half will lose the game - Colin Kaepernick will have at least one run greater than 20 yards - Joe Flacco will have at least one pass greater than 40 yards - Ray Lewis will get more tackles than Patrick Willis (solo + assisted) - Patric Willis will get more tackles than Ray Lewis (solo + assisted) - Aldon Smith will finally get a sack in the playoffs - Frank Gore will rush for more yards than Ray Rice - Ray Rice will rush for more yards than Frank Gore - There will be a scoreless quarter - There will be more than 10 total points in the first half - Baltimore will score first - San Francisco will score first - There will be a punt or kickoff return that is greater than 40 yards - Joe Flacco will have a higher QB Rating than Colin Kaepernick - Colin Kaepernick will have a higher QB Rating than Joe Flacco - The longest field goal will be more yards than the longest offensive play - There will be a score in the final 2 minutes of the first half - There will be a score in the final 2 minutes of regulation - Frank Gore will score the first touchdown - Vernon Davis will score a touchdown - Ray Rice will score a touchdown - The San Francisco Forty Niners claim their 6th Superbowl Trophy! - The Baltimore Ravens claim their 2nd Superbowl Trophy! - The color of the Gatorade dumped on the winning coach will be orange - JZ will join Beyonce on stage at some point during the halftime show - There will be a Beyonce lip-sync controversy reported on ESPN.com within an hour after the game ends. Subutai Ahmad VP Research All Blog Posts Subutai Ahmad 2013/01/27 VP Research Introducing the first ever Sparse Football Pool!","title":"Introducing the first ever Sparse Football Pool!"},{"path":"/blog/2013/01/29/sparse-football-pool-winner/","text":"Sparse Football Pool Winner Tue, Jan 29, 2013 BlogSparse Football Pool Winner Rob Haitani Marketing Thanks to everyone for participating in the Sparse Football Pool! It was a tight race that, given the game, went down to the wire. The winner had a total of 7 correct responses, which is impressive given that you were only allowed to select 9. In fact, there were two entries with the highest score. But given the rules of the contest, the first entry wins the Kindle and copy of On Intelligence. And that winner is: Ryan McCall! Congratulations! Ryan also beat the best entry from Numenta (we were not allowed to win the public prize but wanted to see how we d do, since our participation wouldn t affect the public winner s chances). The top two Numenta entries had 6 correct answers. We will follow up with a blog post describing how this pool relates to the way the brain stores data. But in the meantime, thank to everyone for participating, and congratulations again Ryan! If only the Niners had won the game :) Rob Haitani Marketing All Blog Posts Rob Haitani 2013/01/29 Marketing Sparse Football Pool Winner","title":"Sparse Football Pool Winner"},{"path":"/blog/2013/02/11/super-bowl-neuroscience/","text":"Super Bowl Neuroscience Mon, Feb 11, 2013 BlogSuper Bowl Neuroscience Subutai Ahmad VP Research We are slowly recovering from the disappointing 49er loss to the Ravens in the Superbowl. For those who watched it, it was a tremendously exciting game. In fact the events of the last few minutes had a significant effect on our Sparse Pool result! We promised to explain how the Sparse Football Pool relates to the brain, the CLA (Numenta s Cortical Learning Algorithm) and Intelligence. The CLA relies on Sparse Distributed Representations, a form of information representation where you have a bunch of 0s and 1s. Most of the numbers are 0s and a few of them are 1s (hence the term Sparse ). In fact, each entry to the pool was an SDR nine 1s and twenty-one 0s. SDRs are also the fundamental way our brain represents information. At any point in time, most of the neurons in our brain are quiet and a small percentage of them are firing. It turns out that this form of representation can have some really interesting properties. I constructed the Football Pool specifically so I could highlight some of these points. In the brain the numbers are, of course, far larger and the situation is a lot more complex, but we can illustrate the basic concepts using the Pool. Numerical Properties Of SDRs Even though there are only a small number of 1s, systems using SDRs can uniquely represent a massive number of patterns. Let s ask the following question: given that you can only select 9 True answers out of 30, how many unique entries are there? The answer turns out to be larger than you might guess: there are 14,307,150 possible unique entries! (I know that sounds like a lot it s based on a concept called \"binomial coefficients\"). In Grok our patterns have 40 bits on out of 2048. The number of unique patterns is an unimaginably large 2.37 x 10^84! Give or take 10^80. What is the chance someone else can have the exact same answer as you? Assuming everything is random, that s just the flip side of the above question: it is 1 in 14,307,150. Even your identical twin would have a hard time guessing your answer. What is the chance of someone getting a perfect score? There were 12 Trues in the final answer. Picking any 9 out of those 12 would be fine. There are 220 possible perfect answers, so again, if everything was random, the chance of getting a perfect score is about 220/14,307,150, or about 1 in 65,032. OK, even if you don t get a perfect score, what is a good score? The chance of getting a score of 8 is 1 in 28,903. The chance of getting a 7 is still very rare: only 1 in 18,065. Now, here s a puzzler: we had less than 150 entries yet two people had a score of 7. How is this possible? Either the constellations were lined up perfectly, or there is something else going on. Turns out we can ignore astrology there is another answer. The fact that a highly improbable event occurred tells us that there is something really non-random happening. Semantic Properties Of SDRs The world is not random, and neither were the questions. The questions were grouped into similar semantic categories and the SDR corresponding to each entry represents these semantics. Here are four aspects of this: SDRs can represent specific information: Each person s answer reveals something about the way they thought about the game. This could be very specific. Suppose you answered True to Question 11 (Frank Gore will rush for more yards than Ray Rice). That tells us you predicted Frank Gore would do well. SDRs can represent complex information: Suppose you answered True to questions 2, 3, 5, 14, 17, 21, and 22 (Question Group 1 below). This probably means you predicted it would be an exciting game. On the other hand if you answered True to questions 6, 9, 10, 11, 16, 19, 23, 24, and 26 (Question Group 2 below) it means you predicted the 49ers were going to dominate the Ravens. So, SDRs can represent something specific but can also implicitly represent complex high level information. Isn t that a key to intelligence and intelligent representations? SDRs represent subtle variations using a distributed code: The questions are overlapping and so the information is distributed. For example, questions 2, 3, and 5 in Group 1 have a lot in common. This means you don t have to answer True to all the questions in Group 1. Even answering True to, say, any 3 or 4 of them would be sufficient to tell us you thought the game was going to be exciting. You can convey more or less subtlety by choosing exactly which ones you answer as True. A partial answer tells us something about your thoughts and no particular answer is critical. This is exactly analogous to the brain: a sparse set of active neurons can represent lots of subtlety and complexity. SDRs can simultaneously represent multiple independent concepts: If you answered True to, say, any 4 of the first set, and any 5 from the second set it means you believed both propositions: the game was going to be exciting, but in the end the 49ers were going to beat the Ravens. The ability to simultaneously represent independent concepts is another property of SDRs. It is particularly important when you are making predictions. Grok s algorithms (and neurons) use this property to make simultaneous predictions about the future in a single step. Can we use all this to say something about our winners? If you look at our winner, Ryan, it looks like he basically guessed that the game would be pretty exciting and that the 49er stars would have a good statistical game. Our second place entry (also with a score of 7) guessed that the game would be exciting and that the Ravens would win. Their guesses weren t perfect, but their basic hunches ended up being correct and hence they had a high overlap score. This could only have happened in a non-random world, with meaningful SDRs. Conversely, if you answered the questions randomly, you probably didn t do too well! We have touched on a few properties of SDRs, some of them subtle. You can represent semantic properties and concepts. You can represent both very specific and very subtle concepts. You can represent multiple concepts simultaneously and this can be used in prediction. Grok (and our brain) relies on all of these properties and more. Of course, there are many other aspects of Grok (such as learning SDRs) that we didn t cover here. To wrap up, I hope you gained some insight into the power of SDRs and how our brains represent information. Most importantly, I hope you had fun with this as I did. Next time your spouse complains you are watching too much football, let them know you are actually involved in the greatest possible scientific quest: understanding human intelligence. Go Niners! Question Group 1 - Overall Game Excitement 1. There will be a lead change in the first half 2. There will be three lead changes in the game 3. The team leading at the end of the first half will lose the game 4. There will be more than 10 total points in the first half 5. There will be a punt or kickoff return that is greater than 40 yards 6. There will be a score in the final 2 minutes of the first half 7. There will be a score in the final 2 minutes of regulation time Question Group 2 - 49er Domination 1. Colin Kaepernick will have at least one run greater than 20 yards 2. Patric Willis will get more tackles than Ray Lewis (solo + assisted) 3. Aldon Smith will finally get a sack in the playoffs 4. Frank Gore will rush for more yards than Ray Rice 5. San Francisco will score first 6. Colin Kaepernick will have a higher QB Rating than Joe Flacco 7. Frank Gore will score the first touchdown 8. Vernon Davis will score a touchdown. 9. The San Francisco Forty Niners claim their 6th Superbowl Trophy! Subutai Ahmad VP Research All Blog Posts Subutai Ahmad 2013/02/11 VP Research Super Bowl Neuroscience","title":"Super Bowl Neuroscience"},{"path":"/blog/2013/02/19/not-your-fathers-neural-network/","text":"Not Your Father&#x27;s Neural Network Tue, Feb 19, 2013 BlogNot Your Father's Neural Network Jeff Hawkins Founder I am often asked, Is Numenta s Hierarchical Temporal Memory a neural network? (For those who don t know, the Hierarchical Temporal Memory, or HTM, is the heart of Grok our streaming data product.) The short answer to this question is Yes, but the problem with this short answer is that the Hierarchical Temporal Memory is quite different than what most people think of as a neural network. The history of artificial neural networks starts with Warren McCulloch and Walter Pitts. In 1943 they were the first to propose creating networks of artificial neurons. They showed that artificial neurons could act like logic gates (AND, OR, etc.) and by connecting them in precise ways we could implement any digital logic. It was ground breaking work but biologically unrealistic. Neural networks remained a minor research area for many years until they resurfaced in a big way in the 1980s. This was partly due to the rediscovery of back propagation, which is a method of training simple neural networks, and it was partly due to a two volume book called Parallel Distributed Processing. The PDP books ignited interest in the field. At this time I was already convinced that the path to machine intelligence required understanding how the brain works so I welcomed the new interest in neural networks. Up to that point in time, symbolic and engineered approaches to A.I. were the dominant approaches to machine intelligence. However, I quickly became disillusioned with the new neural networks. The biggest problem was they ignored time. Brains process flowing streams of sensory data. All inference, prediction, and motor behavior in a brain is built upon memory of sequences of patterns. The vast majority of artificial neural networks completely ignored time and hence were unable to process changing inputs or generate behavior. Without embracing temporal patterns I felt we would not get close to capturing intelligence. There were other problems with the simplistic neural networks of the 1980s. Biological neurons have thousands or tens of thousands of synapses arranged on dendrites which have non-linear properties; artificial neurons typically had just a few synapses on a cell body and ignored dendrite properties. Biological neural networks have detailed prototypical architectures; artificial neural networks ignored these architectures. Neuroscience was starting to develop overall theories of brain function but artificial neural networks were simple HTMssifiers that didn t fit within an overall theory. Basically, for many years most artificial neural network research ignored neurobiology and their applications remained limited to simple HTMssification. When most people think of artificial neural networks they think about the type of neural networks explored in the 1980s. Today the term artificial neural network can refer to many different types of networks. Some strive for biological realism and some don t. So when I am asked if Numenta s Hierarchical Temporal Memory is a neural network, I reply \"Yes, but there many types of neural networks. If you want to compare the HTM to other neural networks, ask do those other networks learn sequences, do they learn in an on-line fashion, do they incorporate neurons that have non-linear dendrites, do they form thousands of connections, does the architecture of the network reflect the known architecture of any part of the brain, and does the network fit within a larger theory of brain function?\" The number of artificial neural networks that fit these criteria is small. The HTM is one of them. BTW, there is one type of early artificial neural network that was applied to sequences. These are called auto-associative memories. In another blog post I will describe how the HTM and auto-associative memories are related. Jeff Hawkins Founder All Blog Posts Jeff Hawkins 2013/02/19 Founder Not Your Father's Neural Network","title":"Not Your Father&#x27;s Neural Network"},{"path":"/blog/2013/03/04/brain-activity-map-project-arrives/","text":"BAM! The Brain Activity Map Project arrives Mon, Mar 04, 2013 BlogBAM! The Brain Activity Map Project arrives Jeff Hawkins Founder Last month the Obama administration announced a new ten year $3B science initiative called the Brain Activity Map Project (BAM). The ultimate goal is to map all the connections in the brain and simultaneously record the activity of all the brain s neurons. What will BAM do for those of us interested in understanding how the brain works and building intelligent machines? The fact that brain research is national news promoted by the U.S. President is great. Reverse engineering the brain is arguably the most important scientific challenge of all time and one we are close to solving. History will mark humanity in two epochs, before and after understanding how brains work, or before and after machine intelligence. National focus and money on this important problem makes sense and will accelerate progress. BAM is modeled after the Human Genome Project. This was a decade long federally funded effort to map the genome. It was a success. But mapping the brain s activities is not a singular thing like mapping the human genome. People don t agree on what it means to map the brain or what success looks like. At the moment it isn t clear exactly what BAM will try to achieve. Regardless, we can be confident that the BAM initiative will accelerate our understanding of brains. But there are several ways this can go. The NIH (National Institutes of Health) will likely to do most of the funding for BAM as it did for the Human Genome Project. Since the NIH focuses almost exclusively on diseases, BAM research will be pushed in directions that may not be best for reverse engineering the brain and building intelligent machines. For example, there is a split in the neuroscience world between scientists who study relatively simple nervous systems (such as worms and slugs) and those who study the neocortex which is what makes humans intelligent. The BAM initiative has stated they will start with invertebrates. Understanding invertebrate nervous systems may lead to a better understanding of how brains grow or how neurons work and fail, but it is less likely to lead to a better understanding of intelligence. For that you have to study the neocortex which only exists in mammals. On the other hand, DARPA (the Defense Advanced Research Projects Administration) is also part of BAM. DARPA is interested in machine intelligence and robotics. BAM dollars that get allocated through DARPA are more likely to advance our understanding of intelligence and more likely to lead to advances in practical hardware for machine intelligence. National research agendas such as BAM sometimes don t succeed. In the 1980 s Japan created the Fifth Generation Computer Systems Project, a bold plan to leapfrog the rest of the world in computer science and artificial intelligence. It failed despite concerted effort and hundreds of millions of dollars of funding. Will BAM be a success like the Human Genome Project or a failure like the Fifth Generation Computer Systems Project? Will BAM accelerate brain theory and machine intelligence or just lead to better understanding of disease? It is too early to answer these questions. It depends on what goals are chosen and who allocates the funds. I am optimistic that good things will emerge from BAM but I don t expect it will achieve the stated goals. Mapping the human genome is a far easier problem than recording from and mapping every neuron in a brain. Mapping the genome is like reading letters on a very long tape. You can make millions of copies of the tape and divide up the mapping task among thousands of tape reading machines. Mapping a brain is like finding the personal relationships of every human on Earth and keeping track of what each person is doing at every moment in time. The size of the problem is daunting but the biggest difficulty is that the connections between neurons, like our relationships, are unique and constantly changing. When it comes to the human neocortex, there is no singular map. We can take analogies like this only so far, my point is that mapping the human brain is qualitatively harder than mapping the genome. Even if BAM does succeed, a complete map of a brain is not going to tell us how it works or what causes mental diseases. The activity and connection maps envisioned by BAM will be useful, but brain theorists today are not lacking in empirical data. We haven t come close to understanding the tremendous amount of data we already have. If we want to understand how brains work, then a better direction is to focus on brain theory, not brain mapping. We should set goals for brain theory and goals for machine intelligence tasks based on those theories. That is what we do at Numenta. For example, we set goals to understand how neurons in the neocortex form sparse distributed representations and then how they learn to predict future events. This resulted in Hierarchical Temporal Memory (HTM) which is the heart of our Grok streaming prediction engine. The next big theoretical challenge we are working on is how the cortex generates behaviors from predictions, what is sometimes called the sensory-motor integration problem. Those of us who are interested in brain theory and machine intelligence should be happy about BAM regardless of how it plays out. But we shouldn t rely on it to advance brain theory or machine intelligence any time soon. I am working on a set of brain theory goals that will accelerate progress in machine intelligence. I hope to discuss these in a future blog post. Jeff Hawkins Founder All Blog Posts Jeff Hawkins 2013/03/04 Founder BAM! The Brain Activity Map Project arrives","title":"BAM! The Brain Activity Map Project arrives"},{"path":"/blog/2013/04/02/numenta-and-complex-event-processing/","text":"Numenta and Complex Event Processing Tue, Apr 02, 2013 BlogNumenta and Complex Event Processing Joe Hayashi Marketing NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. A question we get from time to time is, How is Grok different from complex event processing systems? Like Grok, CEP systems are all about streaming data, but Numenta and CEP systems use this data in different ways. We think Numenta and CEP are highly complementary and I wanted to take a moment to explain why. A key capability of CEP systems is that they can perform database-like operations on streaming data - queries, joins, aggregations, mathematical operations, etc. As data comes in, the results of these operations are continuously updated. Need an instantaneous summary of your firm s market positions? Need to know what the current load is on your cell sites? CEP systems are built to answer these types of questions and to do it continuously. The second hallmark of CEP systems is triggering action. Knowing that your house is on fire is certainly important, but you really want to take action to put out the fire. CEP systems also allow you to create business logic around streaming data and then drive action from it. If a real-time key performance indicator is exceeded, logic can be written in the CEP system to trigger a response and take action. This combination of capabilities - working with real-time data and creating a framework of logic around it - enable many companies to set aside legacy code bases for more flexible CEP environments. Because of this flexibility, you often find CEP systems at the heart of many real-time operational systems. Grok extends CEP into the future As we implement pilot projects with customers who use CEP, we ve come to appreciate how Grok can be a powerful and valuable extension to their CEP deployments. In a nutshell, Grok makes it easy to get predictions from and find anomalies in data streams. It s certainly helpful to know what is happening now, but the next logical question to ask is, what will happen next? The simple view is that business intelligence systems are focused on historical data, CEP systems focus on what is happening right now, and Grok is focused on what is most likely to happen in the future. Real-time prediction One of the pillars of Grok is its ability to develop high quality predictive models automatically. Data streams being used by a CEP system can be trivially repurposed to build predictive models of the data. The predictions from the Grok models can then be easily brought back into the CEP environment. No doubt you ve heard that building good enterprise scale predictive models can be hard for us humans. When you have thousands of data streams and you want to always use the latest information, it becomes even more challenging. Grok can build custom models for each data stream and do it automatically in a way that is always up to date. Grok can provide customers with CEP systems with high quality predictions about what is most likely to happen and this information can be added to the mix of operational information to make the best decision and take the most appropriate actions. Move from hand-built triggers to adaptive modelling In addition to modelling many data streams automatically, Grok can also make the business logic that drives the action from CEP systems much more flexible and adaptive. Many CEP applications look at thresholds of real time data and when these thresholds are violated, actions are triggered. One problem is that it can be a tedious and error prone task to configure these thresholds. But the real problem with thresholds (even moving thresholds) is what what was normal yesterday isn t normal today. Businesses operate in a world that is constantly evolving and your systems can t be hard-coded to the past. Grok models learn continuously from data. Even when Grok is looking for anomalies, its models can adapt to find the new normal in your data, while still recognizing important historical anomalies. This adaptive behavior, when paired with CEP s ability to act on data, is required if you want to drive intelligent action from your operational data. With Grok s focus on streaming data, automated model building, and continuous learning, we believe that Grok is an ideal match for CEP applications in finance, energy, and telecommunications. I should mention that there are a number of excellent CEP system on the market, products like Oracle OEP, Sybase ESP, IBM InfoSphere Streams, and others. We ll be talking more about Grok s fit with these and other products in the coming weeks. Joe Hayashi Marketing All Blog Posts Joe Hayashi 2013/04/02 Marketing Numenta and Complex Event Processing","title":"Numenta and Complex Event Processing"},{"path":"/blog/2013/04/11/the-online-learning-advantage/","text":"The Online Learning Advantage Thu, Apr 11, 2013 BlogThe Online Learning Advantage Rahul Agarwal Engineering Streaming data is the future of data. Businesses need real-time solutions that can keep up with the accelerating pace and scale of information they are collecting. This is why one of the key features that Grok models incorporate is online learning (a technical term our marketing department has affectionately changed to continuous learning ). In this post, I ll talk a little bit about online learning and why we think it is so important for solving the types of problems that Grok tackles. What is online learning? Most machine learning systems are what are called batch learning systems. This means that they are trained once on a static set of data, called the training dataset. The model that is learned from this training set is then used to make predictions for additional data, called the test dataset. This approach assumes that the data is stationary, i.e. that the statistical patterns in the data do not change over time. By contrast, in an online learning system there is no distinction between training and test data. Every record updates the model with new information. Therefore, an online learning model never stops learning and always uses the most recent information. Online learning systems do not assume any stationarity in the data. As patterns in the data change, the model adapts and learns these new patterns. You might be thinking, But Rahul, can t you just take a batch learning system and retrain it periodically? Wouldn t that also allow the model to adapt? To this I would say two things, 1) How did you know my name? 2) Yes you can. However, as I will discuss below, this approach is often suboptimal or not feasible for real-time streaming data problems What are streaming data problems? Grok builds models to make predictions on real-time streaming data. This is high frequency, usually machine-generated data. These data streams measure the change in one or many variables as they change over time. An example of streaming data is measurements from temperature sensors placed on a piece of industrial equipment, such as a wind turbine. Another example could be the CPU and memory usage of a server in a server farm. Recent data is exponentially more valuable than old data. Our founder, Jeff Hawkins, talks about this idea as the half-life of data. For example, a web company may release a new feature that dramatically increases traffic to its servers. Any external factors make streaming data inherently non-stationary, indicating that online learning or retraining is a necessity. Therefore, being able to incorporate the latest data into a model as soon as possible offers a huge advantage. Why online learning helps: Fast Data One issue with retraining batch systems is that it is often too slow to be feasible. Many batch machine learning algorithms are optimized to have long, computationally expensive training phases in order to be faster during testing. This is because training is assumed to happen rarely, often only once. One of the reasons many popular batch learning algorithms are slow is that they rely on iterative optimization techniques as a subroutine for learning. This means that they perform the same computation over the training set for many iterations until the parameters of the model converge (given some convergence criteria). These iterative algorithms can potentially take a long time to run depending on how quickly the model converges. Take the popular sequence learning algorithm, Hidden Markov Models (HMMs). The algorithm to train a full HMM from unlabeled data, called the Baum-Welch algorithm, is an iterative algorithm where each step has complexity O(K^2N), where K is the number of states in the model, and N is the number of records in the training set. This means, even for a moderate number of states, each iteration of the optimization process could take a significant amount of time. Even algorithms that are generally considered more efficient, such as Support Vector Machines (SVMs), still require iterative algorithms during training, introducing an indeterminate, potentially large amount of computation. For streaming data problems, it would be infeasible to retrain models on every record because the training process would be too slow to keep up with the data. Even worse, for very high frequency cases, the data might be coming in so fast that the model is obsolete by the time it is retrained! In an on-line training system such as Grok each new data point is presented just once an Grok can update its model in a few tens of milliseconds. Why online learning helps: Many Models In addition to speed, another advantage of Grok is that it allows you to easily train and deploy hundreds and thousands of models. That means you can deploy a separate model for each turbine in your wind farm, or for each node in your data center. At this scale, it becomes costly to store the large amounts of data for each model in order to retrain them. Instead, online models allow you to fire- and-forget your data. An online learning algorithm learns as soon as a new record is fed to it. After that, there is no need to keep the original record, as the model has already incorporated the new information by updating it s own parameters. Even if you can find enough storage for these records, you still have to make a fundamental decision: how often do you retrain? This is not a trivial decision, and it requires the modeler to make certain assumptions about how long the sequential patterns are in the data. There is also a tradeoff between the size of each training batch. Smaller batches allow you to update the models more frequently, but can lead to issues with data sparsity and overfitting, which means that the model doesn t learn all the different patterns that are present in the data. On the other hand, larger batches will take longer to train on, and it will take longer for models to incorporate the most recent data. In the case of thousands of models, it will not be feasible to customize the batch size for each model, so some assumption must be made to suit all models. Although online learning algorithms, such as our Cortical Learning Algorithm (CLA), generally have some analogous learning rate parameter, Grok automatically determines the best value for each model during the swarming process, removing the need for the data scientist to select a value. Conclusion While batch learning make sense for certain problem domains, online learning is essential for high velocity streaming intelligence applications. While it is possible to munge batch systems into online learning systems, it s like fitting a square peg into a pentagonal hole. This is why Grok s core technology incorporates online learning from the start. In fact, we think that for the future of data (i.e. streaming data, if you were paying attention) online learning is a must-have feature. Rahul Agarwal Engineering All Blog Posts Rahul Agarwal 2013/04/11 Engineering The Online Learning Advantage","title":"The Online Learning Advantage"},{"path":"/blog/2013/05/01/the-neuroscience-behind-grok-part-2/","text":"The Neuroscience Behind Grok, Part 2 Wed, May 01, 2013 BlogThe Neuroscience Behind Grok, Part 2 Rob Haitani Marketing NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. This is the second post in a series describing how the brain works, and how this benefits Grok. The content is based on lectures given by Jeff Hawkins describing Grok s detailed model of a layer of cells in the neocortex, called the Cortical Learning Algorithm (CLA). Previously we quoted an AI expert who said, one of biggest problems in AI no, the only problem in AI is the problem of representation. What exactly are \"representations,\" and why do we say that Sparse Distributed Representations (SDRs) are critical to modeling human intelligence? Representations are patterns in a computer or a brain that represent something in the real world. They are building blocks to understanding our world, that allow us to answer questions such as, what is this? and what does this do? That doesn t sound so complicated. Computer programs use bytes and words to represent everything from your age, to the color of a car, to the features of a product. This works well when all you want your computer to do is keep track of things. But how do you represent the relationship of things in the real world? Coming up with a label called car is easy; knowing a car is similar to a truck or that it can be used for transportation is hard. A car might be related to hundreds of other objects in complicated ways. This type of knowledge is surprisingly difficult to capture in the precise realm of computers. Your brain also forms representations. The brain s representations consist of the activity of neurons, which ultimately derive from the inputs from your senses. The set of neurons representing car are fired when you see any car from any direction, in any lighting condition, even if a door is open or the car is crumpled. To manage this complexity, you d think that all of your neurons must be firing all the time, in a dense cacophony of activity. You d think. But you d be wrong. No matter how furiously your brain is working, only a small percentage of neurons are active at any given time. Most are silent, and the neurons that fire actually inhibit other neurons nearby from firing. How can this be? Let s start by looking more closely at how computers represent data, which is sometimes called dense representations. In a computer representation there are a relatively small number of bits, and all combinations of ones and zeroes are used. In ASCII code, for example, the string 01101101 represents the letter m. The individual 1s and 0s mean nothing. The bits only have meaning as a group, and a programmer assigns the actual representations. This makes them inflexible: if one bit is missing or changed, then the entire meaning changes or is incomprehensible. And an ASCII representation doesn t tell you anything about the properties of the letter m it represents. Sparse Distributed Representations, by contrast, consist of very long strings that are mostly 0s. Grok representations usually have 2,000 digits, of which only 2% (or about 40) are 1s. This emulates the sparsity in the brain, where only a few cells are active at any time. However, each of the 1s has meaning. Imagine a game similar to Twenty Questions, except that you can ask 2,000 questions. It turns out you can build a system where any given word has a \"Yes\" answer to about 40 of those questions, and No for everything else. Note that if any two words share a Yes for the same question, they have something in common. For example, both might be people, or both might be bigger than a breadbox. Also, the questions and answers are not assigned, but are learned through repeated observation. Continuing the analogy, let s say you want to store this information. You don t have to record the answers to all 2,000 questions. You can store the numbers of the 40 questions that had Yes answers (in computer terms, you can store an index of active bits). You can even take a random sample of 10 Yes answers, and still confidently identify your word. This is more like Name That Tune I can name that word in ten Yes answers. If you do the math, it turns out that it is extremely unlikely that you will guess the wrong word if you know ten of the correct Yes answers. But even if you did, it would still share ten common attributes, so your mistake would represent something else that was similar. This principle of semantic generalization is a critical differentiating factor between flexible brains and brittle artificial intelligence. Humans effortlessly use synonyms: car, Prius, \"automobile,\" etc. And our perception also degrades gracefully. If you only see the hood of a car, or a car with someone in front of it, or read the letters \"autmobile,\" you filter out the noise and extract the essence of car from the partial pattern you see. To summarize, SDRs are very long strings of mostly 0s that represent knowledge and meaning, and form the language of the brain. The principles of SDRs enable flexible recognition of similar patterns, and graceful degradation of noisy input. As a result, it is difficult to imagine how to build machine intelligence without SDRs. The next post in this series will discuss how SDRs are used to learn patterns. Further information: - Sparse Distributed Representations - Our Brain s Data Structure - This talk by Subutai Ahmad goes into more detail, including the SDR property of union, which makes it easy to determine if a new pattern has been seen before. This, in turn, forms the basis of Grok s anomaly detection algorithms. - The Neuroscience Behind Grok, Part 1 - This is the first part of this series, providing an overview of how the brain is a predictive modeling memory system. Rob Haitani Marketing All Blog Posts Rob Haitani 2013/05/01 Marketing The Neuroscience Behind Grok, Part 2","title":"The Neuroscience Behind Grok, Part 2"},{"path":"/blog/2014/03/17/navigating-names-at-numenta/","text":"Navigating Names at Numenta Mon, Mar 17, 2014 BlogNavigating Names at Numenta Donna Dubinsky CEO For a company that is launching its first product, we have an unusual number of terms and names, including Numenta, Grok, HTM, and NuPIC. This abundance of names reflects our unusual mission. I m writing this blog post to explain how all these names fit together. Our company was founded over nine years ago as Numenta, and we are returning to using this as our company name. Numenta s mission is to lead the new era of machine intelligence. This mission is ambitious, but it s one that we are proud of and deeply committed to, and we have made real progress towards its achievement. The origin of the word is from the Latin mentis , meaning mind , so a new mind . In order to understand and make practical our machine intelligence technology, we now are building products on top of it. Consequently, Numenta is both a technology and a product company. We are using the name Grok for our first commercial product. We just launched Grok for IT Analytics on AWS (Amazon Web Services). We anticipate creating a variety of Grok products over time, all of which will use our core machine intelligence technology, but include additional functionality targeted at specific customer problems or domains. Our goal with Grok and other products is to become the leading platform for machine intelligence. Once you look deeper into the technology behind Grok and our other applications, you will want to understand where the acronyms fit in. The broad theory described by Jeff Hawkins in his book, On Intelligence, is called Hierarchical Temporal Memory (HTM). HTM is a theory about key characteristics of neocortex, describing learning as a memory-prediction system operating on spatio-temporal data. HTM forms the theoretical underpinnings for our work. The learning algorithms within HTM learn sequences and find patterns in temporal data. These HTM learning algorithms are modeled very closely after biological principles, and can be mapped to a single layer of neurons in the cortex. In 2013, we created an open source project implementing HTM in order to further our mission of being a leader in the new era of machine intelligence. We refer to the open source project as NuPIC (Numenta Platform for Intelligent Computing), and it is hosted at http://numenta.org. So, that s all there is to it! In brief: Name Description Numenta, Inc. Company name, including both technology and products Grok Name for first commercial product, Grok for IT Analytics Hierarchical Temporal Memory (HTM) Theory of neocortex described by Jeff Hawkins in On Intelligence. Includes learning algorithms that find patterns in streaming data, predict next steps, and find anomalies; a core building block for HTM. NuPIC (Numenta Platform for Intelligent Computing) Open source project where HTM is being explored and advanced by the developer community http://numenta.org The home for NuPIC, the open source project http://numenta.com The home for Numenta, the company, and the Grok product As I said up front, Numenta is an unusual company. We work with scientists who are mainly interested in the HTM theory. We work with developers who are mainly interested in our open source project using HTM. And we work with customers who are mainly interested in the Grok product built on top of these technologies, and prefer to think of the underlying technology as a black box. By using terminology to differentiate these audiences, it makes life a bit more complex for us, but we believe that it makes our work and our direction far more clear. Donna Dubinsky CEO All Blog Posts Donna Dubinsky 2014/03/17 CEO Navigating Names at Numenta","title":"Navigating Names at Numenta"},{"path":"/blog/2014/03/20/science-of-anomaly-detection/","text":"The Science of Anomaly Detection Thu, Mar 20, 2014 BlogThe Science of Anomaly Detection Jeff Hawkins Founder I just finished writing a new whitepaper. It is about the science of detecting anomalies. As followers of Numenta know, we have worked for many years to understand how the neocortex works. As I described in On Intelligence, the brain is a prediction machine, one that builds models from streaming data and constantly makes predictions. A large part of our research has been to understand exactly how the neocortex learns and makes predictions. The Cortical Learning Algorithm (CLA), included in our NuPIC open source project, was a major advance in that direction. We also feel it is imperative to find valuable applications for brain-based technology today. So for the past two years we built a prediction engine based on the CLA and started the process of investigating commercial applications. Although we found applications for prediction in many industries, and the CLA worked well in those applications, there were substantial barriers to being able to act on predictions within existing business processes. Further, we learned that there was equal or greater interest in anomaly detection, the flip side of prediction. With this knowledge we looked at the state-of-the-art in anomaly detection technology. We also interviewed many people who use anomaly detection products in their daily routines. We quickly learned two things. One is that simple-to- use products, ones that don t require machine learning experts, didn t perform well. Every person we talked to told us about getting too many false positives and/or too many false negatives. The second thing we learned is that existing tools are designed to be used in data centers, but they caused frustration when people were away from the data center or away from the office. A surprising number of people we interviewed told us that they turned off alerts altogether. We realized that by using the CLA and applying our understanding of neuroscience, we could take a fresh approach, and create a substantially better anomaly detection engine. We also felt we could reinvent how anomalous events are reported and explored, by creating a new type of mobile interface. Our product, Grok, is the result. Grok advances the state-of-the-art in anomaly detection technology and it replaces SMS s, and email alerts with a fun and powerful mobile application. In just a few seconds on your mobile phone you can see which of your applications and servers are acting unusually and if they need further attention. I ve written a paper that explains how we have applied the science of the CLA to the technology of anomaly detection. It illustrates how a simple-to-use product can detect anomalies with subtlety and sophistication by using cortical models. I hope you ll read it and see why I m so excited. In my view, this is one of the first products based on neocortical principles, a system that learns patterns from its temporal data stream, makes predictions, and identifies anomalies. Just what your brain does every moment of every day. Jeff Hawkins Founder All Blog Posts Jeff Hawkins 2014/03/20 Founder The Science of Anomaly Detection","title":"The Science of Anomaly Detection"},{"path":"/blog/2014/04/04/anomaly-of-the-week/","text":"Anomaly of the Week Fri, Apr 04, 2014 BlogAnomaly of the Week Subutai Ahmad VP Research NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. It was Thursday night, March 20th, at 8pm. I was cleaning up the kitchen and getting ready to wind down when my smartphone buzzed: Grok had sent an alert. I know that with Grok it just takes a few seconds to check things out, kind of like text messages. So I clicked on the notification and looked at the graph. What followed was interesting and eye opening! It turns out that on that night Amazon s East coast datacenter, US-East-1, had some problems. AWS API call latencies slowly increased. Eventually by about 8:40 PM API calls were so slow as to be practically unusable. Any applications on those servers relying on the AWS API were unusable. Below are two screen shots from the Grok mobile application showing the Hourly view and the Day view for that time period. Notice that Grok flagged unusual behavior at 8pm, 35 minutes before Amazon s API became completely unresponsive on the East Coast. To understand this better, here s a bit of information about this server. test02 is a test server running an instance of Grok. We have servers in multiple regions but this particular server sits in US-East-1 and was affected by the incident. Our servers make lots of outgoing API calls as is typical for AWS applications. The blue line shows CPU load on test02. As API calls slowed down, retries and lags increased and the CPU load started became a bit wonky. Eventually Cloudwatch became unresponsive and the data stopped coming in. The really cool thing is that the alert happened 35 minutes before that point. Luckily test02 is just a test server. We keep most of our production stuff in US-West so this didn t directly affect us. However I do know that plenty of US- East users were affected and could have benefited greatly from an early warning. It is useful to think about whether this could have been caught by some other mechanism. First, any threshold based alerting system would NOT have caught the anomaly. CPU load of 66% is not unusual at all for this server. In fact there are times when the CPU goes close to 100% when this server trains new models so that s out. A system looking at our service latencies would not have detected anything either our web server was actually perfectly responsive the entire time. An anomaly detection scheme that relies on averages and standard deviations would not have worked. The incident happened too fast, within just a few 5-minute samples. A statistical technique that made a decision that fast would lead to tons of false positives on noisy data (including normal usage when CPU jumps to 100%!). You can see in the hour view how fast Grok turned red Grok uses temporal sequences to detect unusual behavior. A more sophisticated training mechanism that relies on classifying known patterns also wouldn t have worked. I have never seen this behavior before and would not have been able to predict it. Isn t that the whole point though? We need a system that automatically detects the unknown unknowns. The above are actual snapshots from my smartphone for our server and this is an actual incident (I admit I dramatized the first paragraph let s blame marketing for that :-). For the record, below is a snapshot of the AWS status page. Amazon states that no instances were affected and this is true we can attest that our machines kept running fine. On the other hand, any code that relied on the AWS API was drastically affected by this incident. In general AWS does an amazing job of keeping their infrastructure up and running but occasional incidents do happen. These incidents are unpredictable and they are unavoidable. It is comforting to know that Grok can give me a heads up and some lead-time to investigate and figure out what to do. In a production context I would have had plenty of time to spin up servers in another region and redirect my traffic there. Subutai Ahmad VP Research All Blog Posts Subutai Ahmad 2014/04/04 VP Research Anomaly of the Week","title":"Anomaly of the Week"},{"path":"/blog/2014/04/22/caught-red-handed/","text":"Caught Red Handed Tue, Apr 22, 2014 BlogCaught Red Handed Jared Casner Director, Product Development NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. Like most engineering managers, I like to know when someone is manually touching one of our servers. That s especially true for production systems, but also applies to QA servers. So, imagine my chagrin when Grok caught me red handed, not just once, but twice this week! This first example was when I upgraded one of our QA servers to Grok 1.3 (shameless plug it s available now!) In this example, you can see a very slight increase in the number of bytes received by the server, which was flagged very quickly. At the same time, the CPU utilization starts to drop slightly, which Grok marked as yellow. Notice that Grok picked up the update on 2 metrics at the same time, both right as the process starts, before the metrics get into ranges that could be identified as abnormal by most statistical techniques! Having a leading indicator even by a few minutes that things are starting to behave atypically is a huge advantage! Luckily for us, this was a totally innocuous change. And, investigation was even easier because when I got the alert about the anomaly, I was still in the middle of the update. The second example from this week was when I decided doing some recovery testing would be a good idea. I manually stopped all of the services on the QA server and watched the CPU load drop rapidly again. This time, Grok picked up the change very rapidly. But, notice that the new pattern also stabilizes very quickly at ~20% CPU load, with the Grok anomaly score dropping back into the green quickly. Grok then flags an anomaly around 12 hours later when I turned the services back on and the CPU jumped back up to the ~85% mark. Now, if you re like me, you ll have noticed a 3rd anomaly in the chart on the left, right around 10PM. I drilled into that one and noticed that, sure enough, the pattern is just slightly different at 10PM than it is at 9PM. It s a visibly subtle difference, but important nonetheless. Stay tuned for our next Anomaly of the Week ! Jared Casner Director, Product Development All Blog Posts Jared Casner 2014/04/22 Director, Product Development Caught Red Handed","title":"Caught Red Handed"},{"path":"/blog/2014/07/15/detecting-anomalies-in-stock-volumes/","text":"Detecting Anomalies in Stock Volumes Tue, Jul 15, 2014 BlogDetecting Anomalies in Stock Volumes Viraj Sinha Summer Intern, Engineering In the film Pi, a mathematician by the name of Maximllian Cohen derives the mathematics for universal prediction pattern in stock data (using, as the movie s namesake may suggest, the number Pi). With his math, Max is able to predict the precise activity of the market, in real time. The movie takes a turn for the cerebral (and is worth a watch), but the idea of predicting stock data stuck with me. Rather than using Max s math, I decided to apply Grok and the Cortical Learning Algorithm to stock data: have the CLA learn patterns and alert me to anomalies. I decided to primarily monitor stock volume, which can be an interesting indicator of a share s performance. Usually, a drastic event in volume indicates a change in the recent trend of a given share: a volume spike signifies interest by investors (or trading algorithms), often related to buy orders when the price is significantly low, or sell orders when the price is high. By using Grok to monitor volume anomalies, I can get a notification on my phone when a given share is being traded in an unusual way. Trade volume often peaks towards the beginnings and ends of the day, as after- hours orders are filled in the mornings, or as close-price orders are filled in the evening. Since Grok actually learns the patterns rather than being a simple threshold-based system, it does very well learning patterns and filtering the signal from the noise. Here s a real life example from the ticker for 3D Systems Corporation (DDD). 3D Systems Corporation builds and sells 3D printers and scanners, as well as sells 3D printed parts to everyone from the automotive to the dental and healthcare industries. In the first image (taken directly from Google Finance), we can see a trade volume spike on July 1st just moments before a huge increase in price (and a continued increase in trade volume). In the second (taken from Grok), we see an anomaly detected with the volume spike! When this happened, I got a notification sent to my phone, telling me to check out DDD s anomalous behavior. I quickly got online and watched the action live, as the price skyrocketed and then dropped back down. If I d actually had DDD in my portfolio, I would ve known that the price spiked, and would ve seen it drop back down by the end of the day. It s very convenient to be told when a share is doing something like this, rather than having to watch multiple prices during the day. Interestingly, we don t see any anomalies after the first red peak on the anomaly chart. This is because Grok, by default, suppresses additional anomalies for an hour after an initial detection the red peak on the chart is synonymous with a detected anomaly. Since Grok fires off a cell phone notification every time it sees an anomaly, we decided we didn t want to spam the user with multiple notifications within a certain time period. If you look closely at the graph, you can even see the perfectly flat section for about 1 hour after the initial red anomaly. If we didn t have this suppression turned on, we d expect to see additional anomalies detected around 8:40 and 9:05 that day. I m writing this post a week after this event, and the press has had some time to catch up. There are a few speculative reasons for this price spike, including a change in management[1], the launch of a new 3d scanner for the iPad[2], and news of recent advancements in medical-grade 3D printing which will allow for antibiotic-infused implants[3]. This is pretty exciting news, all of which I likely wouldn t have noticed if it weren t for Grok. [1] http://www.marketnewscall.com/volume-buzzers-3d-systems-corporation-nyseddd-ezchip-semiconductor-ltd-nasdaqezch/1231261/ [2] http://www.gaininggreen.com/computer-peripherals-3d-systems-corporation-nyseddd-logitech-international-sa-nasdaqlogi-electronics-for-imaging-nasdaqefii-universal-display-corporation-nasdaqoled-transact-technolog/1239893/ [3] http://3dprint.com/7793/3d-print-antibiotics-implants/ Viraj Sinha Summer Intern, Engineering All Blog Posts Viraj Sinha 2014/07/15 Summer Intern, Engineering Detecting Anomalies in Stock Volumes","title":"Detecting Anomalies in Stock Volumes"},{"path":"/blog/2014/07/22/cleanup-on-asg-3/","text":"Cleanup on ASG 3 Tue, Jul 22, 2014 BlogCleanup on ASG 3 Joe Block Site Reliability Engineer NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. I was at the AWS summit in NYC, and when I got back to California, I saw a notification from Grok that our web server auto scaling group (ASG) was acting anomalously. At first I thought it was only because we were seeing heavier than usual traffic since we were mentioned in Information Week and VentureBeat, but when I checked it out in Grok s mobile app, I noticed a couple of odd and interesting things. First, I saw an odd pattern in the NetworkIn graph - instead of a flattish line with minor variation and different sized rough edged spikes I d expect from regular web requests, or a line trending upward as the web traffic went up from the media mentions, what I was seeing was a stable line with very high, very sharp spikes at regular intervals. On closer examination, the peak spikes were even more suspicious - they were all very nearly the same size. Secondly, Grok had also flagged the group s CPU metric, and when I looked at it, the graph was very atypical. This ASG normally has a CPU load that hovers around 20%, and what I was seeing was hovering around 40-45% with surges to 100%. The surges were not as sharply edged as the network spikes, but there were still surges in load. Finally, even though the CPU was staying above the level we d configured our ASG to add instances at, when I took a look at the ASG instance count it was still hovering around the lower bound of the ASG s size limit. After staring at the individual graphs on the phone for a bit, I pulled up the Grok web chart page so I could compare them to each other - sometimes I prefer using the web chart because it allows me to view more than one of an instance or ASG s underlying metric graphs raw data charts at once, and also because by viewing them on a 15 inch MacBook Pro screen instead of a phone, I can see a bigger picture of what is going on. Sure enough, once I expanded the CPU and NetworkIn underlying charts on my laptop I could see that the surges in CPU were lagging behind the spikes in network, and I immediately got an idea of what was going on, and a quick look at the ASG s scaling history and the logs on a freshly started web server instance confirmed my suspicions. Here s a little background about our web server back end auto scaling group. The Numenta web site itself is stored in a git repository and uses a combination of docpad, nodejs and some custom scripts to render the static pages of the site from various source assets. Each web server updates the local copy of the git repository every fifteen minutes, and if the master branch has changed, it renders the site and swaps the new rendered document directory tree into place. That s the normal process, and because we re using git we only have to download the changes in the source files since the last site update. What was happening in this case though, was that the site renders were failing on fresh instances. So the ASG would spin up a new instance, the new instance would have to download the entire git repository, it would attempt to run the build process and the build would fail. Then the health check script would run, see that the web server didn t have a valid document root, report the instance as unhealthy to the ASG, and the ASG would terminate the instance. Once the cool down expired, we d lather, rinse and repeat. If all the old instances had gotten terminated in the ASG, we d have had downtime on the website since new instances were failing to become healthy and get added to the load balancer. The reason the problem was only showing up on new instances was because the support script was just checking that a particular component was installed, not that it was a specific version. When the upstream source for that component updated to a new version, it wasn t compatible with our build process, so new instances would fail to build. The identically sized NetworkIn spikes were when a new instance started up and did the initial git clone of the website repository, and the wider CPU spikes were when the new instance would attempt to render the website s static assets. We resolved the issue in two ways. In the short term, we updated the build script so that it specified exact versions for all of its dependencies. This stopped the new instance churn right away. In the long term, we stopped rendering the site on the web servers - we had initially decided to build the static site on the web server to eliminate machine-generated files from the repository, but now we pre-render everything and check the static site into the repository. It can be served immediately after a git pull and the web servers don t have to do anything else when we update the web site content. Here s an example of the new, normal curves after all the fixes were put in place: I could have figured this out without Grok, but I would have had to look at every metric for the ASG, then scrubbed through them to find where the anomalous behavior began, then rummaged through the log files, but, and this is an important but, I wouldn t have started looking until the last good web server backend failed and I got an alert that the website was down. Thresholds on the CPU load or NetworkIn wouldn t have helped me - the spikes I saw were what I would have expected to see when a new instance was added to the ASG, what made them unusual was how rapidly the instances were getting added and dropped. Instead, Grok notified me when the anomalous behavior started, highlighted exactly which metrics were showing the strange behavior, and let me compare them to each other immediately so I could get good picture of the situation before I started looking in my logs, and before the website actually went offline. Joe Block Site Reliability Engineer All Blog Posts Joe Block 2014/07/22 Site Reliability Engineer Cleanup on ASG 3","title":"Cleanup on ASG 3"},{"path":"/blog/2014/08/11/summer-internships-and-extensibility-of-htm/","text":"Summer Internships and the Extensibility of HTM Mon, Aug 11, 2014 BlogSummer Internships and the Extensibility of HTM Nick DeFalco Marketing Intern I recently had a conversation with a friend where the subject of our summer internships came up. My friend is interning at a financial institution and she had great things to say about her company and the people she worked with. However, her one major complaint was that the work she did was very specialized and narrowly focused. She worried that if she ultimately decided to pursue a career outside of finance, the skills she had sharpened during her internship wouldn t be widely applicable. To me, this sounded like the opposite of what I felt about my time with Numenta. As more than one of my old bosses used to say, working in a startup is like building the airplane as you re heading down the runway. In a situation like this, roles are somewhat amorphous, projects are fast paced, and coworkers contribute wherever they can. Furthermore, the skills and mindset developed in this type of environment are relevant across a wide range of functions. As I think back on the conversation I had with my friend, I realize that the differences between her internship experience and my own also provide a strong metaphor for comparing the Hierarchical Temporal Memory (HTM) machine intelligence technologies we are developing at Numenta against the typical programmed tools we are all familiar with today. Almost all of the software we use today has been programmed to do one specific set of tasks. This enables each individual program to perform the jobs it was designed for extremely well, but limits the usefulness of each tool to a very limited range of use cases. That s why you only need one brain, but your smart phone would be pretty dumb if you only had one app. On the other hand, HTM machine intelligence like your brain comprises a single underlying processing method that is extensible across a wide range of applications. Over the course of this summer alone, we have used our underlying machine intelligence technology to deliver interesting new capabilities across a wide variety of potential applications and data sets. Here are a few of the applications that we have been working on this summer to demonstrate the extensibility of HTM: Rogue Behavior Detection Using the data generated by human actions to alert to abnormal employee actions and detect when computers or other devices are accessed by unauthorized users. Geospatial Tracking Using streaming GPS and speed data to automatically model location and travel patterns, then use this model to identify subsequent irregularities in speed, location and route pattern. Natural Language Processing Improving the ability of machines to understand the semantic meaning and context of natural language. Sensorimotor Learning and Prediction Actively exploring an environment to: 1. Predict the results of motor actions and control signals, and 2. Form stable and discriminative representations of each environment Just as the tools used during an internship only represent a few of the gadgets we each hold in our tool bags, the applications shown above only demonstrate a thin slice of the potential that HTM machine intelligence holds. As such, I m really excited to see how HTM will continue to grow over the next few years to deepen its capabilities and broaden the ways in which it impacts our world. Nick DeFalco Marketing Intern All Blog Posts Nick DeFalco 2014/08/11 Marketing Intern Summer Internships and the Extensibility of HTM","title":"Summer Internships and the Extensibility of HTM"},{"path":"/blog/2014/08/18/progress-at-numenta/","text":"Progress at Numenta Mon, Aug 18, 2014 BlogProgress at Numenta Donna Dubinsky CEO NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. You will notice some substantial changes in our web site this week. I d like to take a moment to explain what s going on. Late last year we shipped our first product, Grok for IT Analytics on AWS. Since then, we ve released several enhancements for the product, including the recent version 1.5 with a new web charting feature. Some customers using our product have told us that they have found problems in their AWS environments that other methods haven t caught, while others have found problems hours earlier than they would have otherwise. These results have demonstrated that our HTM (Hierarchical Temporal Memory) learning algorithms are performing as we had hoped. We are automatically learning the patterns in the streaming data of each individual server, and then finding when the input differs from that expected, thus detecting an anomaly. Other customers are also using Grok to analyze non-IT data using our custom metrics feature - with interesting results. We encourage you to explore this option and would love to hear about your results. While we will continue to evolve the Grok for IT Analytics product, we are equally excited about myriad opportunities to apply this technology to other domains. As a result, over the past few months we have turned our attention towards creating demonstration applications that show how to potentially apply our HTM technology to a variety of other problems. We have restructured our web site to better communicate the breadth of our technology. Detailed information on Grok for IT Analytics is still available, but now if you come to visit Numenta, you first will see information on Numenta technology, before diving deeper to learn more about Grok and other applications. As part of the evolution of our web site, we have created some new material that we hope you will read: - Whitepaper: HTM for Rogue Behavior - Whitepaper: HTM for Geospatial Tracking These whitepapers show how the same core technology that finds anomalies in Grok for IT also finds anomalies in other, very different, streams of data. In each case, our HTM learning algorithms are automatically modelling different types of streaming data, learning the patterns, predicting what should come next, and then highlighting inputs that differ from those predicted. In other words, our algorithms are doing what your brain does, day in and day out. We hope you ll enjoy our new look and refreshed content and look forward to your feedback. Donna Dubinsky CEO All Blog Posts Donna Dubinsky 2014/08/18 CEO Progress at Numenta","title":"Progress at Numenta"},{"path":"/blog/2014/08/29/grok-for-managing-aws-cost-anomalies/","text":"Grok for Managing AWS Cost Anomalies Fri, Aug 29, 2014 BlogGrok for Managing AWS Cost Anomalies Jared Weiss Engineering Intern NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. While the forefront issue in an engineer s mind might be that builds are consistently running and production servers aren t experiencing unexpected downtime, a business executive might have completely different concerns. As an experiment, I decided to address what I believed might be a primary concern of IT managers: ensuring that AWS costs are managed to budget and costs are minimized. My approach was to feed cost data to Grok to identify any anomalies in spending relative to the normal pattern of spend. Using Grok s custom metrics, I sampled and fed AWS burnrate statistics into Grok for regional burnrates as well as instance counts. Since AWS instances vary in pricing, spinning up one EC2 I2-8xlarge instance could be just as much of a problem as spinning up several T2-micro instances. Therefore, even though most anomalies would likely be caught by both metrics, I wanted to be sure that unexpected corner-case anomalies would be caught too. In fact, at the beginning of my experiment, the burnrate monitor was able to detect an anomaly in AWS s us-east-1 region. For ease-of-use, most of the servers we use reside in the us-west-2 region, however all of our testing for marketplace AMIs happens on us-east-1 servers. For that reason, early on August 4th, Grok detected an anomaly when our QA team began testing one of our marketplace candidates. Since Grok had learned the regular pattern of nightly AMI tests, when all of a sudden an instance was manually created, Grok quickly notified me. Grok Web UI showing Normal Pattern Grok Web UI showing anomaly due to launch of AMI tests In this case because I knew the QA team was starting a new cycle of testing, I was able to easily identify the cause of the anomaly. Nevertheless, it was useful that Grok identified the increased in instances and impact on costs. Had I not expected the anomaly, I would have been able to quickly find the source of the problem, whether it be a faulty testing script that forgets to delete automatically created instances on failure, or an accidentally changed limit on an auto-scaling group. In today s dynamic and virtualized IT environments, it s great to have this peace of mind that jumps in costs outside of normal patterns can be identified quickly. Not only can Grok tell an engineer that a server is operating normally, but it can also report to a senior manager that their company isn t incurring unexpected costs. In use cases with noisier data (such as burnrate for our us-west-2 region where most of our instances are located), the burnrate monitor still excels at detecting anomalous spending. Large, anomalous jumps in spending that could be attributed to a larger than usual instance being spun up or accidentally setting the minimum instance count of an auto-scaling group to 500 instead of 50 are quickly recognized, enabling the proper team member to rapidly address the issue. Rather than receiving an enormous (and unexpected) bill at the end of the month, the cost and likelihood of a serious AWS mistake is substantially mitigated. During my experiment Grok was able to identify an anomaly due to an error in the configuration of our auto-scaling group, causing it to grow unnecessarily large. Despite a more noisy usage pattern for this AWS region, Grok was able to identify it. Grok Web UI showing anomaly due to error in auto-scaling group configuration Grok can also learn new behaviors. When we began to spin up several more costly instances for testing, Grok first detected this behavior as anomalous, but as we continued testing on the larger instances, Grok taught itself the new pattern and stopped flagging the increased burnrates as anomalous. Especially with Amazon continually announcing new instance sizes and costs, unexpected changes to server burnrate are inevitable, and it s necessarily important to be able to learn the new burnrate patterns. Grok Web UI showing learning of new pattern Jared Weiss Engineering Intern All Blog Posts Jared Weiss 2014/08/29 Engineering Intern Grok for Managing AWS Cost Anomalies","title":"Grok for Managing AWS Cost Anomalies"},{"path":"/blog/2014/09/17/increasing-research-transparency/","text":"Increasing Research Transparency Wed, Sep 17, 2014 BlogIncreasing Research Transparency Subutai Ahmad VP Research I am pleased to tell you about a change we recently made to our research process. We have made our day to day experimental code public. As you may know, we already released our commercial HTM algorithm code to the NuPIC open source community in the form of the NuPIC project. We use that exact codebase in our product Grok. The NuPIC open source community and Numenta actively work together to continually maintain and improve this code base. Within Numenta we continue to evolve and expand HTM theory. Our goal is to create a complete cortical theory and codebase, including such topics as sensorimotor integration, attention, hierarchy, and others. Our research ideas are constantly in flux as we tweak and experiment. To support the research we have, up until today, maintained a separate internal codebase that sits on top of NuPIC. Interest in HTM has grown tremendously and we get many questions about our research. Over the last few months we have openly discussed fundamental ideas around sensorimotor inference, temporal pooling, hierarchy, etc. on the HTM Theory Forum. Numerous people in the NuPIC community have been actively engaged in deep theoretical discussions. Given this interest we wondered whether it would be possible to be more open about our work. What if we released our day-to-day research code to a public repository? There are potential downsides. Research code can be very rough - would people get confused? Would they become discouraged or even skeptical about the theory if what they see is not yet working? We might get many questions about it - would that slow us down? On the other hand, exposing our work-in- progress would give members of the community visibility as to our priorities, help them understand more deeply the theory, and create an opportunity to solicit their ideas and improvements. We floated the idea and discussed the tradeoffs with the NuPIC developer community. The feedback we received gave us the confidence to proceed. I m happy to share that we just created an experimental public nupic.research repository on GitHub. This directory is small right now, but active. The code includes our current prototypes and experiments around sensorimotor inference. I do want to emphasize one point; this is not code we push only after things are working well. This is code as we are working on it. We make regular pull requests and check-ins. We use GitHub to track our day to day tasks, and it contains our internal conversations about the code. It provides an almost real time view into the research being performed at Numenta. This change is an experiment in conducting research in the open. We don t know how it will turn out. If this idea works out well, over time the repository will grow to contain just about all our research code. If not, well, we ll just stop doing it. It s all in the spirit of research! P.S. There is some fine print. This code is all temporary and experimental. We can t make any guarantees about it. Currently we are not accepting pull requests, though this might change down the road. However you are free to copy and use it under the terms of the AGPL license*. Please see the README file on GitHub for more fine print and details. *This content has been updated to reflect our new AGPL license. Subutai Ahmad VP Research All Blog Posts Subutai Ahmad 2014/09/17 VP Research Increasing Research Transparency","title":"Increasing Research Transparency"},{"path":"/blog/2014/10/07/learning-through-active-exploration/","text":"Learning Through Active Exploration Tue, Oct 07, 2014 BlogLearning Through Active Exploration Yuwei Cui Research Intern When I first arrived at Silicon Valley for my internship, the entire environment looked new. It took me several weeks to get familiar with my new neighborhood. Interestingly, even with advanced GPS apps on my phone, the most effective way to learn a new environment is to walk on the street, memorizing landmarks, and making different turns at intersections. The GPS app could give me smart directions, but I could not really learn the world just by staring at the map. Knowledge comes from practice, and we always learn something through active exploration. Nevertheless, most artificial intelligence techniques adopt data intensive machine learning approaches. Algorithms are trained to find patterns by observing massive amounts of data passively, usually without generating any actions. At Numenta, we are working on a next-generation machine intelligence algorithm that learns complex patterns through active exploration. The stream of sensory inputs is actively generated by execution of a series of motor commands. We call this new learning paradigm sensorimotor learning and prediction, or SLAP. To understand how the algorithm works, let us first think of how our brain solves the same problem. We know that all our remarkable cognitive abilities, object recognition, scene interpretation, reasoning and prediction, starts from data streams collected by our sensors , such as retina at the back of eyes, tactile sensors under the skin and auditory sensors in the cochlea. Believe it or not, most of the inputs to the sensors are actually generated by ourselves, rather than by changes in the external world. Our eyes are constantly moving; our touch senses mostly arise from our own body movement, and the speech we generated is also picked up by our auditory nerves. After we learn a new environment, we are rarely surprised by the consequences of our own actions. I can predict exactly what I will see after each turn on my way to work now. This prediction is based on my current sensory input and the motor command I am going to execute. Moreover, despite dramatic changes of input to my sensors, my internal perception is stable. These two aspects reflect two component of the algorithm. We call the prediction step sensorimotor inference , and the process of building stable representations as temporal pooling . Jeff Hawkins described the basic ideas on the NuPIC mailing list. During my internship I implemented and worked on several SLAP experiments using synthetic datasets. In one experiment, we trained the SLAP algorithm to recognize a large number of synthetic images composed of squares . Each square is painted with different color and different images share the same set of colors. Two example images are shown below. A white diamond represents the portion of the image that lies on the fovea, and a black arrow represents the proposed motor command. The algorithm is allowed to explore each image through simulated eye-movements. At each step the image under the fovea and the motor command is fed to the algorithm. The first layer of the network learns to make predictions of the next sensory input. The algorithm also utilizes a reasonable assumption that if two things are close to each other in time (temporal proximity), they tend to originate from the same underlying cause, and thus should be grouped together. Neurons of the second layer pool over many neurons in the first layer, and form a stable representation that is unique to each pattern. During learning, stable representations will emerge despite changes to the input in the first layer. These stable representations indicate recognition of the larger image. The figure below shows example output from a trained system while the eyes are moving around two different images (10 iterations for each image). At each step, the sensory input is changing drastically. However, the overall output is a stable and unique representation for each image. This simple example illustrates a fundamental mechanism our brain uses to create stable representations from a changing world. The same mechanism can also be used for a large variety of problems where the sensor data is actively generated by the system, such as robot learning, vehicle control, and complex pattern recognition/detection problems. Note: Some of my implementation code is now available in the nupic.research github repository. Yuwei Cui Research Intern All Blog Posts Yuwei Cui 2014/10/07 Research Intern Learning Through Active Exploration","title":"Learning Through Active Exploration"},{"path":"/blog/2014/12/15/custom-burnrate-metric/","text":"Monitoring AWS EC2 Burnrate with Grok Mon, Dec 15, 2014 BlogMonitoring AWS EC2 Burnrate with Grok Joe Block Site Reliability Engineer NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. A few months ago, we mentioned that we re monitoring our AWS EC2 costs with Grok. We developed a simple script to monitor our burnrate and ensure that when our spend changed, we knew about it and could take action. Since we posted Grok For Managing AWS Cost Anomalies, we ve had requests for more details and for access to the script. Today we re happy to announce that the script is available on Github at https://github.com/groksolutions/grok-burnrate. You can run it as a standalone script or with Docker using the Dockerfile there or by pulling from the public Docker registry. Joe Block Site Reliability Engineer All Blog Posts Joe Block 2014/12/15 Site Reliability Engineer Monitoring AWS EC2 Burnrate with Grok","title":"Monitoring AWS EC2 Burnrate with Grok"},{"path":"/blog/2015/01/22/introducing-sparse-football-pool-ii-super-bowl-xlix/","text":"Introducing Sparse Football Pool II Thu, Jan 22, 2015 BlogIntroducing Sparse Football Pool II Numenta Subutai Ahmad & Ryan McCall Around this time of year the US goes crazy over the Super Bowl. So be it, but did you ever think the Super Bowl could help you understand how your brain works? Well, it can! Enter the Sparse Football Pool. Numenta s theory of the cortex, Hierarchical Temporal Memory, relies on the properties of Sparse Distributed Representations. SDRs are the fundamental way our brain represents information. The concepts behind SDR are deep and thought provoking. We get a lot of questions around this and were wondering how to explain it all in a fun simple way. We came up with a simple Super Bowl quiz with rules that closely mimic some operations in HTM. We hope the quiz will be fun and at the same time illustrate some deep principles behind SDRs. The rules are extremely simple. How exactly do they relate to SDRs? We ll explain it all when we post the winner after the game, but for now here are two tidbits: 1) computing overlap is a fundamental operation with SDRs, and 2) when there are 30 questions and you choose 11, there are 54,627,300 possible combinations of entries. The chance of getting all 11 correct is pretty small, but given how improbably the Seahawks won their game anything is possible! WIN AN AUTOGRAPHED COPY OF ON INTELLIGENCE We re offering some cool prizes (US citizens 18 and over only). The top 5 winners will receive a Numenta T-shirt and an autographed hardcover of On Intelligence. In addition the winner will receive a $100 gift certificate to Amazon, iTunes, or Google Play (their choice). THE THREE RULES 1. Answer TRUE or FALSE for each answer. 2. You cannot have more than 11 TRUE answers. If you enter more than 11 TRUE answers, we will take the first 11 only. 3. To figure out the winner, we will compute the overlap score between the actual answers and your answer. The person with the highest overlap score will win. COMPUTING OVERLAP SCORE The overlap score simply gives you one point for every answer where you answered TRUE and the correct answer was TRUE. For example, if the answer to question 3 is True and you answered True, you get a point. In all other cases you don t get a point for question 3. Note that since you can only put down 11 TRUE s, the maximum overlap score you can get is 11. In case of ties, the earlier entries will win. (Also, if you submit more than one entry, only the last entry will count.) AND NOW, THE QUESTIONS To enter, go to our online submission form. You will be asked to answer the following questions. They are repeated here for reference to help you plan out your answers ahead of time (responses will only be accepted through the online submission form). Note that all entries must be received by 12 PM Pacific Standard Time on January 31, 2015. - The New England Patriots will score first - The Seattle Seahawks will score first - There will be a lead change in the first half - Russell Wilson will throw for more than 250 yards - Tom Brady will throw for more than 300 yards - Russell Wilson will attempt more passes than Tom Brady - LeGarrette Blount will rush for more than 100 yards - Marshawn Lynch will rush for more than 120 yards - Jamie Collins will make the most tackles (solo plus assisted) in the game - Rob Gronkowski will score a touchdown - Rob Gronkowski will not score a touchdown - Russell Wilson will throw at least two interceptions - There will be a score in the final 2 minutes of the first half - The team leading at the end of the first half will lose the game - Halftime show performer Katy Perry will don more than one costume during her performance - Rihanna, Snoop Dogg, or Juicy J will join Katy Perry on stage during the halftime show - Kicker Steven Hauschka (Seahawks) will score more points than kicker Stephen Gostkowski (Patriots) - The New England Patriots will be penalized the most (in terms of yards) - The Seattle Seahawks will be penalized the most (in terms of yards) - There will be at least one lost fumble resulting in a change of possession in the game - Someone other than Russell Wilson or Tom Brady will throw a touchdown pass - There will be kickoff or a punt that is returned for a touchdown (by either side) - The game will have a Pick Six play where an interception is returned for a touchdown - There will be at least one successful coach s challenge that will overturn a ruling on the field made by the referees - There will be a score in the final 2 minutes of regulation - The combined score at the end of the game will be greater than 50 - The combined score at the end of the game will be less than or equal to 50 - The winner will win by 10 or more points - The Seattle Seahawks will claim their 2nd Superbowl Trophy! - The New England Patriots will claim their 4th Superbowl Trophy! Numenta Subutai Ahmad & Ryan McCall All Blog Posts Numenta 2015/01/22 Subutai Ahmad & Ryan McCall Introducing Sparse Football Pool II","title":"Introducing Sparse Football Pool II"},{"path":"/blog/2015/02/04/super-bowl-neuroscience-sparse-pool-ii-2015-results/","text":"Super Bowl Neuroscience: Sparse Football Pool 2015 Results Wed, Feb 04, 2015 BlogSuper Bowl Neuroscience: Sparse Football Pool 2015 Results Numenta Subutai Ahmad & Ryan McCall SUPER BOWL NEUROSCIENCE: SPARSE FOOTBALL POOL 2015 RESULTS This year s Super Bowl between the New England Patriots and the Seattle Seahawks was a cliffhanger. In fact, the twists and turns in the last few minutes had a significant effect on our result, with some of the answers determined in the last five minutes of the game. (To read the original blog post, click here). Congratulations to our winner Glen Speckert who, out of 95 contest entries, tied for the top score with 8 correct answers. The other top scorer was our own CEO, Donna Dubinsky, who also had a score of 8 (but is ineligible to win a prize sorry Donna!). So, how does the Sparse Football Pool relate to the brain, the HTM Learning Algorithms and intelligence? The remainder of this blog post will explain. HTM relies on Sparse Distributed Representations (SDRs), a form of information representation where you have a long numerical string with mainly 0 s and a few 1 s (the degree of sparsity is determined by how few 1 s). In fact, each entry to the pool was an SDR eleven 1 s and nineteen 0 s. SDRs are the fundamental way our brain represents information. At any point in time, most of the neurons in our brain are quiet and a small percentage of them are firing. We constructed the Sparse Football Pool to highlight some of the special properties of SDRs. Of course, in the brain the numbers are far larger and the situation is more complex, but we can illustrate the basic concepts using the Pool. NUMERICAL PROPERTIES OF SDRS Even though there are only a small number of 1 s, systems using SDRs can uniquely represent a massive number of patterns. Let s ask the following question: given that you could only select 11 True answers out of 30, how many unique entries are there? The answer is larger than you might guess: there are 54,627,300 possible unique entries (we know that sounds like a lot it s based on a concept called binomial coefficients). In Numenta s HTM systems, our patterns typically have 40 bits on out of 2,048. The number of unique patterns is an unimaginably large 2.37 x 10^84! What is the chance someone else would have exactly the same answer as you? Assuming everything is random, that s just the flip side of the above question: one in 54,627,300. What is the chance of someone getting a perfect score? Nine statements out of the 30 actually came True. Each contestant could select up to 11 statements to be True, so there was some room for error. Specifically, there are 9,405 answers that could get the maximum score of 9, so again, if everything was random, the chance of getting a perfect score is about 9,405/54,627,300, or about 1 in 5,808. (For more details on the math behind SDRs, see this talk.) What is a good score? The chance of getting a score of 8 is 1 in 322, and the chance of getting a 7 is 1 in 37. Now, here s a puzzler: we had less than 100 entries yet two people had a score of 8. How is this possible? The fact that a highly improbable event occurred tells us that something non-random happened, and it relates to the semantic properties, or the meanings, of SDRs. SEMANTIC PROPERTIES OF SDRS The world is not random, and neither were the statements. Certain statements could be grouped into similar semantic categories. If a contestant s entry was totally random, then it wouldn t matter. But, if a contestant had a point of view , this thinking would be evident in their entry/SDR. To be sure, the SDRs can represent very specific predictions. If you answered True to Statement 8 (Lynch will run for more than 120 yards), then you predicted Marshawn Lynch would do well in a very specific way. But SDRs also can represent more complex concepts. Suppose you answered True to statements 3, 12, 13, 14, 20, 21, 23, 25, and 26 (Statement Group 1 below). These statements are related in meaning; they all predict a wild and exciting game. If your point of view was that the Super Bowl would be wild and exciting rather than low scoring and boring, your SDR would reflect this meaning. In another example, if you answered True to statements 1, 5, 7, 9, 10, 19, 28, and 30 (Statement Group 2 below), you predicted New England was going to dominate Seattle. This SDR reflects another point of view on the game. So, SDRs can represent something specific but also can simultaneously convey complex high- level information. Put another way, the distributed part of SDRs enable the encoding of subtle information. Looking again at Group 1 below, you didn t need to answer True to all the statements for us to know that you thought the game would be exciting even 3 or 4 Trues from this list would convey your point of view. You conveyed more subtlety by choosing exactly which ones you answered as True. Even a partial answer tells us something about your thoughts; no particular answer is critical. This structure is analogous to the brain: a sparse subsampling of active neurons can represent lots of subtlety and complexity. Finally, SDRs can simultaneously represent multiple independent concepts. If you answered True to, say, five from the first set, and five from the second set, you believed both propositions the game was going to be exciting, but in the end the Patriots were going to beat the Seahawks. The ability to simultaneously represent independent concepts is another property of SDRs. It is particularly important when you are making predictions. The HTM algorithms and the cortex use this property to make simultaneous predictions about the future in a single fixed representation. How does this explanation answer the question as to why there were two winners, an extremely unlikely result? Both winners, Donna and Glen, guessed that New England would win in a high scoring, exciting game. They had a similar point of view, and they answered True or False to those statements that matched that point of view. Their guesses weren t perfect, but they weren t random. Indeed, if you responded to the statements randomly, you probably didn t do too well! We have touched on a few properties of SDRs, some of them subtle. You can represent semantic properties and concepts. You can represent both very specific and very subtle concepts. You can represent multiple concepts simultaneously, which can be used in prediction. The Sparse Football Pool, Numenta s HTM technology, and our brain rely on these same concepts. We hope the Pool helped you understand the power of SDRs and how our brains represent information. Most importantly, we hope you had fun with this unusual pool! Next time your spouse complains you are watching too much football, let them know you are actually involved in the greatest possible scientific quest: understanding human intelligence. STATEMENT GROUPS: GROUP 1 - OVERALL GAME EXCITEMENT - 3: There will be a lead change in the first half - 12: Russell Wilson will throw at least two interceptions - 13: There will be points scored in the final 2 minutes of the first half - 14: The team leading at the end of the first half will lose the game - 20: There will be at least one lost fumble resulting in a change of possession in the game - 21: Someone other than Russell Wilson or Tom Brady will throw a touchdown pass - 23: The game will have a Pick Six play where an interception is returned for a touchdown - 25: There will be points scored in the final 2 minutes of regulation - 26: The combined score at the end of the game will be greater than 50 GROUP 2 NEW ENGLAND DOMINATION - 1: The New England Patriots will score first - 5: Tom Brady will throw for more than 300 yards - 7: LeGarrette Blount will rush for more than 100 yards - 9: Jamie Collins will make the most tackles (solo plus assisted) in the game - 10: Rob Gronkowski will score a touchdown - 19: The Seattle Seahawks will be penalized the most (in terms of yards) - 28: The winning team will win by 10 or more points - 30: The New England Patriots will claim their 4th Superbowl Trophy! Numenta Subutai Ahmad & Ryan McCall All Blog Posts Numenta 2015/02/04 Subutai Ahmad & Ryan McCall Super Bowl Neuroscience: Sparse Football Pool 2015 Results","title":"Super Bowl Neuroscience: Sparse Football Pool 2015 Results"},{"path":"/blog/2015/06/02/nab-a-benchmark-for-streaming-anomaly-detection/","text":"NAB - A Benchmark for Streaming Anomaly Detection Tue, Jun 02, 2015 BlogNAB - A Benchmark for Streaming Anomaly Detection Alexander Lavin Software Engineer Numenta Anomaly Benchmark A Benchmark for Streaming Anomaly Detection Data is in ever-increasing supply as sensors inhabit more and more of our world. Examples abound from health data tracked by pacemakers and fitness wearables, to temperature sensors in aircraft engines and mobile phones. These sensors provide important information in real-time, streaming data. That is, time-series data, where there is a natural temporal ordering in the successive measurements made over a time interval. Take a look at Figure 1 below, an example of time-series data from a sensor. The plot shows scalar values over time for an unknown metric. Can you guess if the metric is blood glucose level for a diabetes patient, stock volume for a Fortune 500 company, or something else? It s difficult to tell, yet it s apparent the plot shows data anomalies, or deviations from the normal pattern. Figure 1 An example data file from the NAB corpus; data from monitoring the temperature of an internal component of a large, expensive, industrial machine. The three blue regions represent anomaly windows, and the purple region is the detector s probationary period. For details on these and more NAB components, please explore the NAB wiki[1]. Looking at the entire plot, these anomalies are easily recognized after-the-fact but identifying anomalies long after they occur isn t acceptable. Yet many anomaly detection methods run in batch mode, where the data is collected and processed after the fact. Real-time data processing, on the other hand, calls for continual input, process, and output of data. A real-world anomaly detector should be required to process streaming data, learn continuously, and make accurate detections as soon as possible. At Numenta we ve built a robust, real-time anomaly detector using Hierarchical Temporal Memory (HTM)[2]. Our Grok application is great demo of the algorithm in action on server metrics data[3]. Other real-time anomaly detectors are out there, namely at Yahoo and Twitter who both recently announced their activities in real-time anomaly detection[4][5]. But how can one truly discern whether or not these algorithms are up to the task of streaming anomaly detection? Sure HTM does great on detecting anomalies in Amazon Web Services metrics with Grok, but what about the other sensory domains? Enter the Numenta Anomaly Benchmark (NAB), an open-source benchmark we re developing for the evaluation of real-time anomaly detection algorithms. The NAB dataset contains streaming data samples, aiming to capture the difficulties of real-time anomaly detection, across varying real-world domains. A detector run on this dataset is subject to evaluation by the NAB scoring method. To score well on NAB, anomaly detection algorithms should: run in unsupervised mode, process real-time data, learn continuously, reliably detect anomalies, and detect them as early as possible. Detailed descriptions of all NAB components can be found in the NAB whitepaper posted in the wiki[1]. Figure 2 below shows the Numenta detector on the sample data file of Figure 1, where the algorithm accurately detected all three anomalies with no false positives. Figure 2 NAB results for the Numenta detector on a data file representing machine component temperature readings. The detections resulted in all three true positives, and no false positive nor false negatives. We re currently in a beta phase, working with a few select companies and researchers to improve both the benchmark dataset and the scoring methods, before submitting the benchmark for publication. Our aim during this phase is to collaborate with businesses that need real-time anomaly detection and researchers working on novel algorithms. Part of the value of the benchmark is a data set consisting of diverse sensory data streams with real labeled anomalies. As such we re particularly interested in real-world data files with actual anomalies to add to the dataset. Call For Participation! So far we ve received some great feedback, but there s still a ways to go. You can help. Please check out NAB[6] for yourself. Do you have data to contribute? Great, we d love to include it in the benchmark, as long as your data meets the following criteria: - Real-world, time-series data - Labeled or known anomalies - Minimum 1000 records per data file (more would be ideal) - Data records must be from a continuously streaming source in chronological order at roughly equal time intervals - from a continuously streaming source - in chronological order - at roughly equal time intervals - Scalar metric(s) If you have data you might be able to contribute, are interested in the benchmark, or have questions, please contact us at nab@numenta.org. No real-world anomaly detector is perfect, but which is best? Where do algorithms make good and poor detections? NAB will be able to answer these questions, providing the world of data analysis with a much-needed benchmark for this very important class of algorithms. References - [1] https://github.com/numenta/NAB/wiki - [2] http://numenta.com/assets/pdf/whitepapers/Numenta White Paper - Science of Anomaly Detection.pdf - [3] http://grokstream.com/ - [4] http://labs.yahoo.com/news/announcing-a-benchmark-dataset-for-time-series-anomaly-detection/ - [5] https://blog.twitter.com/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series - [6] https://github.com/numenta/NAB/ Alexander Lavin Software Engineer All Blog Posts Alexander Lavin 2015/06/02 Software Engineer NAB - A Benchmark for Streaming Anomaly Detection","title":"NAB - A Benchmark for Streaming Anomaly Detection"},{"path":"/blog/2015/07/01/winner-of-htm-contest-at-yale/","text":"Winner of HTM Contest at Yale Wed, Jul 01, 2015 BlogWinner of HTM Contest at Yale Donna Dubinsky CEO Winner of HTM Contest at Yale This past month, Numenta sponsored a contest at Yale University, in collaboration with the Yale Entrepreneurial Institute, for a prize to create an application using our HTM technology. We offered the winning team a $10,000 cash prize, along with a license structure that would enable them to create a company to commercialize the application. The contest was open to all Yale students, faculty and alumni. Why did we hold this contest at Yale? We wanted to test out the idea of an entrepreneur contest like this, and since I am on the board of trustees at Yale and am familiar with the Yale Entrepreneurial Institute, we decided this was a low friction way of conducting this experiment. And we feel the experiment was a success! We received multiple submissions for the prize with problems in such domains as managing hospital data, understanding patents and fixing inefficient event pricing. The winning venture is called Good Day Bad Day (GDBD). GDBD s proposal was created by Dr. Michael Choma, of the Yale Medical School, and Zhilong Cong, MS, a graduate student at Yale in biomedical engineering. Choma and Cong propose to take streaming data from wearable devices, such as the Apple Watch, and use it to improve management of chronic respiratory disease. We selected GDBD for several reasons. First, the data meets fundamental streaming requirements; there is a clear streaming data source a wearable sensor and the data stream has sufficient velocity. Second, it seems highly likely that there will be temporal patterns that can be found by the HTM algorithms. Finally, Choma and Cong as a team have both the medical knowledge as well as computer science skills to be able to create an application that meets the needs of patients and physicians. We congratulate GDBD on their win, and look forward to seeing how their application evolves. Read the Yale Entrepreneurial Institute press release. We will consider sponsoring similar contests at other universities or incubators. We have no doubt that HTM can be applied to a huge range of problems, so we find ourselves excited at the prospect of working with multiple teams who have the expertise and the excitement to build HTM applications. We are very open to working with early stage start-ups, and have a start-up friendly licensing structure. If you would like to connect with us to run a contest or to talk about a start-up idea, please email us at marketing@numenta.com. Donna Dubinsky CEO All Blog Posts Donna Dubinsky 2015/07/01 CEO Winner of HTM Contest at Yale","title":"Winner of HTM Contest at Yale"},{"path":"/blog/2015/08/15/numenta-licensing-update-agpl/","text":"Numenta Licensing Update and AGPLv3 Sat, Aug 15, 2015 BlogNumenta Licensing Update and AGPLv3 Donna Dubinsky CEO Numenta Licensing Update Today I d like to tell you about some changes and updates to our open source and commercial licensing strategy. First, effective today, we will be using the AGPL open source license instead of the GPL open source license for all of our open source software. When we made the decision to use the GPLv3 license several years ago, the GPL seemed like a good fit for our needs as we were trying to promote a community that shares their work, rather than going with a more permissive style license that allows individuals to keep enhancements private. The AGPL is in keeping with that spirit and makes clear that use in a SaaS implementation is also considered a distribution and thus must fully comply with the GPL. The proposed changes were discussed on our mailing lists and the NuPIC community is supportive of this change. Note that the AGPLv3 is explicitly designed to be the same as the GPLv3 with the additional of the SaaS clarification, and will not impact open source developers in any other way. Second, we have heard from potential customers that some companies have prohibitions against their engineers using either the GPL or the AGPL. Consequently, we have created a very simple Trial License. The Trial License confers no commercial rights, but allows research and experimentation with NuPIC software without being required to use an open source license. Finally, as you may know, we have a dual license strategy for NuPIC in that we offer commercial licenses in addition to our open source license. Recently, we have had an increase in requests for commercial licenses to the point where we would like to create a standard licensing program. We are in the process of documenting this program to be released in the next few weeks. We plan on having two types of license, one geared towards start-up companies formed specifically to create HTM applications (with no up-front payments and a delayed royalty stream), and the other for established companies. We hope these will cover the majority of cases but of course, we can create custom licenses as needed. I believe that these license changes will have a positive impact both for the NuPIC open source community as well as for potential commercial partners. Other than the SaaS change, there is no other change in the open source license such that researchers, students, and individual programmers can continue their work as before. Commercial participants can use our Trial License, and will soon be able to evaluate our new standard licenses. Thank you for your continued support. Links: - AGPLv3 License - Numenta Trial License - Numenta Commercial License Donna Dubinsky CEO All Blog Posts Donna Dubinsky 2015/08/15 CEO Numenta Licensing Update and AGPLv3","title":"Numenta Licensing Update and AGPLv3"},{"path":"/blog/2015/09/29/introducing-the-numenta-htm-challenge/","text":"Introducing the Numenta HTM Challenge Tue, Sep 29, 2015 BlogIntroducing the Numenta HTM Challenge Matthew Taylor Open Source Manager Numenta has held five hackathons over the past several years to engage our community of dedicated and passionate HTM enthusiasts. It s been a great time for lots of people involved. We ve grown together and created some really interesting things! The one consistent complaint I ve gotten from hackathon attendees is that there just wasn t enough time to complete their projects. In response to this feedback and our desire to incubate more complete HTM projects, we have completely changed the structure and format of our hackathons. Introducting the Numenta HTM Challenge! The Numenta HTM Challenge is an online contest open for submissions today and running until November 14th. Participants must come up with ideas for real-world applications of HTM technology and submit them for approval before starting work. This ensures the problem being solved is applicable to HTM, and that the data being analyzed is adequate for HTM. Once a project has been approved, hackers have until November 6th to work on it and submit a demo video for judging. Onsite Event Nov 14 This Challenge can be completed entirely online, but we encourage you to try to attend the Onsite Event that culminates the Challenge on November 14 in Redwood City, California. At this Onsite Event, all demonstration videos will be viewed by a judging panel and a live audience. Judges will get a chance to comment and ask questions to submission authors (either live or over the phone). At the end of the event, we ll announce the winners and cash prizes will be awarded! Sessions In addition to judging, there will also be at least two educational sessions by Numenta team members Subutai Ahmad and Jeff Hawkins. They will be talking about the history and evolution of HTM algorithms and some details about new algorithm development, respectively. Temporal Pooling (Jeff Hawkins) Temporal pooling is an important aspect of HTM theory. It refers to how representations get more stable as sensory data moves from region to region ascending the cortical hierarchy. It plays an important role in inference, feedback, and motor control. Our understanding of how temporal works has been refined a couple of times since the original HTM white paper was published. In this talk I will review the basic requirements of temporal pooling and introduce a new model for temporal pooling, one that is more robust that previous versions. I will also discuss how we think this new temporal pooling model is implemented in neurons in the neocortex. Temporal Memory of HTM: A Retrospective (Subutai Ahmad) Did you realize that the development of HTM algorithms at Numenta has been going on for over 10 years? Subutai (who has seen it all) will step you through the sequence of HTM developments, from our very first demos, algorithms and products, to our current research on cortical algorithms. Come and see what we have learned, and how our past informs our future. RSVP for the Onsite Event here You don t have to participate in the Challenge to attend the Onsite Event! Maybe you just want to come see the latest presentations from Numenta or watch the Challenge demonstration judging. That s great! We welcome you to mingle with us HTM enthusiasts. Community Meetup Nov 13 And as long as you ll be in the area, there is a Community Event being planned on the Friday before the Onsite Event. I hope you ll attend just to meet the rest of the HTM community. This event is run by the NuPIC community, for the NuPIC community. A schedule is in the works. RSVP for the Community Meetup here Help us build the future of Machine Intelligence! We believe that HTM is the future of machine intelligence. This is a great chance for you to get involved and help us move this important technology forward. I hope you ll consider being a part of this event in some way. Matthew Taylor Open Source Manager All Blog Posts Matthew Taylor 2015/09/29 Open Source Manager Introducing the Numenta HTM Challenge","title":"Introducing the Numenta HTM Challenge"},{"path":"/blog/2015/12/01/htm-challenge-2015-results/","text":"Numenta HTM Challenge 2015 Results Tue, Dec 01, 2015 BlogNumenta HTM Challenge 2015 Results Donna Dubinsky CEO Earlier this month, we ran a contest for our developer community to use our algorithms on real world problems. The contest, called the HTM Challenge, was conceived by Matt Taylor, our community flag-bearer, as a way to enable the community to invest more time in trying to build an application than they can in a weekend Hackathon. Overall, we were pleased with the result, with 14 entries submitted. Each entrant was required to make a short video demonstrating the application. You can see them all here: http://htmchallenge.devpost.com/submissions It s interesting to note that the #1 and #2 winners are both in the field of transportation, one detecting car traffic anomalies and the other relative to aviation anomalies, both using our geospatial encoder. To me, however, the most notable result of the contest was to realize the breadth of the type of applications that can be addressed with HTM. Although these were just demonstration programs, not ready for commercialization, they offer support to the notion of a generalized machine intelligence approach. Whether the application was predicting traffic, tracking heart monitors, understanding natural language, or generating music, the exact same algorithm is at play, just like in your brain. We often talk about how our biologically derived technology is extremely flexible and applicable to many different problems. It s nice to see this reinforced with the wide variety of submissions. Thank you to everyone who participated in this challenge. We look forward to seeing what future applications will be built on HTM. See photos from the event held in Redwood City here. Donna Dubinsky CEO All Blog Posts Donna Dubinsky 2015/12/01 CEO Numenta HTM Challenge 2015 Results","title":"Numenta HTM Challenge 2015 Results"},{"path":"/blog/2016/01/11/machine-intelligence-machine-learning-deep-learning-artificial-intelligence/","text":"What is Machine Intelligence vs. Machine Learning vs. Deep Learning vs. Artificial Intelligence (AI)? Mon, Jan 11, 2016 BlogWhat is Machine Intelligence vs. Machine Learning vs. Deep Learning vs. Artificial Intelligence (AI)? Numenta Jeff Hawkins & Donna Dubinsky We are frequently asked how we distinguish our technology from others. This task is made difficult by the fact that there is not an agreed vocabulary; everybody uses the above terms (and other associated terms) differently. In addition, the commonly understood meaning of some of these terms has evolved over time. What was meant by AI in 1960 is very different than what is meant today. In our view, there are three major approaches to building smart machines. Let s call these approaches Classic AI, Simple Neural Networks, and Biological Neural Networks. The rest of this blog post will describe and differentiate these approaches. At the end, we ll include an example as to how each approach might address the same problem. This analysis is intended for a business rather than technical audience, so we simplify somewhat and thus beg the indulgence of technical experts who might quibble with the details. Classic AI Approach The earliest approaches to AI were computer programs designed to solve problems that human brains performed easily, such as understanding text or recognizing objects in an image. Results of this work were disappointing and progress was slow. For many problems, researchers concluded that a computer had to have access to large amounts of knowledge in order to be smart . Thus they introduced expert systems , computer programs combined with rules provided by domain experts to solve problems, such as medical diagnoses, by asking a series of questions. If the disease was not properly diagnosed, the expert adds additional questions/rules to narrow the diagnosis. A Classic AI system is highly tuned for a specific problem. IBM s Watson could be viewed as a modern version of a Classic AI system. It focuses on creating a sophisticated knowledge base on a particular issue. Although Watson doesn t rely on encoded rules, it requires the close involvement of domain experts to provide data and evaluate its performance. Classic AI has solved some clearly defined problems but is limited by its inability to learn on its own and by the need to create specific solutions to individual problems. In this regard, in spite of it being called artificial intelligence, it has very little in common with general human intelligence. Simple Neural Network Approach Some early researchers explored the idea of neuron models for artificial intelligence. When the limits of Classic AI became clear, this notion picked up steam and with the addition of back propagation techniques, started proving useful. The resulting technology, artificial neural networks (ANNs), was created over 50 years ago when very little was known about how real neurons worked. Since then, neuroscientists have learned a great deal about neural anatomy and physiology, but the basic design of ANNs has changed very little. Therefore, despite the name neural networks, the design of ANNs has little in common with real neurons. Instead, the emphasis of ANNs moved from biological realism to the desire to learn from data without human supervision. Consequently, the big advantage of Simple Neural Networks over Classic AI is that they learn from data and don t require an expert to provide rules. Today ANNs are part of a broader category called machine learning which includes other mathematical and statistical techniques. Machine learning techniques, including ANNs, look at large bodies of data, extract statistics, and classify the results. ANNs have recently evolved into Deep Learning networks, whose advances have been enabled by access to fast computers and vast amounts of data for training. Deep Learning has successfully addressed many problems such as image classification, language translation and identifying spam in email. Although Simple Neural Network systems can solve many problems that were not solvable using Classic AI, they have limitations. For example, they don t work well when there is limited data for training, and they don t handle problems where the patterns in the data are constantly changing. Essentially, the Simple Neural Network approach is a sophisticated mathematical technique that finds patterns in large, static data sets. There is a deeper and more important issue beyond the current limitations of Classic AI and of Simple Neural Networks. In our view, both of these approaches are not on a path to achieve true machine intelligence; they don t provide a roadmap to get there, which brings us to the third approach. Biological Neural Network Approach Everyone agrees that the human brain is an intelligent system; in fact it is the only system everyone agrees is intelligent. We believe that by studying how the brain works we can learn what intelligence is and what properties of the brain are essential for any intelligent system. For example we know the brain represents information using sparse distributed representations (SDRs), which are essential for semantic generalization and creativity. We are confident that all truly intelligent machines will be based on SDRs. SDRs are not something that can be added to existing machine learning techniques; they are more like a foundation upon which everything else depends. Other essential attributes include that memory is primarily a sequences of patterns, that behavior is an essential part of all learning, and that learning must be continuous. In addition, we now know that biological neurons are far more sophisticated than the simple neurons used in the Simple Neural Network approach and the differences matter. We believe you can t get to machine intelligence by incrementally building upon the simple neuron approach, but instead must throw it away and start over with a more realistic biological approach. Numenta s technology, Hierarchical Temporal Memory (HTM), is the best example of the Biological Neural Network approach. Today, HTM systems are able to learn the structure of streaming data, make predictions and detect anomalies. They learn continuously from unlabeled data. By taking a robust biological approach, the brain gives us a roadmap of where to direct our work in the future, such as completing our understanding of behavior, attention and short term memory. This roadmap distinguishes HTM from other techniques and makes it the best candidate for creating intelligent machines. An Example Let s take a problem and think about how it might be addressed in the three different approaches. Again, we oversimplify a bit in order to distinguish the main differences of the three approaches. We have been asked to detect rogue behavior of an employee within an organization. For example, companies with confidential information want to know if people with internal access are abusing that information. A change in employee behavior might be totally legitimate the employee has changed roles, and now has new responsibilities or it could be a problem. Rogue behavior is difficult to identify. The Classic AI approach would address this problem with a series of rules. For example, let s consider an analyst who works with confidential customer data. The Classic AI system would need a human to figure out likely problem scenarios then program the system to look for those scenarios. This solution might flag any instance where the analyst has accessed the customer file more than 10 times in the month. As the Classic AI system is deployed, and false positives and false negatives are examined, the rules would be strengthened. The new rule might say that an analyst accessing customer data in the first few days of the month is not flagged, but it is for the remainder of the month. The Simple Neural Network approach would start with lots of historical data, namely a large database of known problem scenarios. The Simple Neuron Network system might figure out, for example, that abuse of this information only happens in the last week of the month. The system identifies such features and then classifies an individual as unusual or not unusual . Although it sounds similar to the Classic AI approach, in this case, the features are learned from the data, not from an expert. Both approaches have some problems. With the Classic AI solution you need to know what you are looking for. But criminals constantly change strategies to avoid detection and the rules don t adapt. The Simple Neural Network approach requires a lot of labeled data to be able to find common features, but this kind of data generally doesn t exist for unusual behavior. Both approaches are unsuitable for modeling individual behaviors and require the system to be retrained when new patterns arise. The Biological Neural Network approach would stream the data from each analyst (such as the details of the files routinely accessed, numbers of emails, numbers of postings, etc.) and would automatically build individual models of normal behavior for each person. The system would then predict what would be normal for each analyst and would flag anything abnormal. One could stream a lot of different metrics without knowing which will be important all the modeling is automated. The Biological Neural Network system does not need to know what it is looking for, can model each individual separately, and continuously learns as data changes. In summary, below are the characteristics of the three different approaches: Classic AI Simple Neural Network Biological Neural Network Examples Watson Deep Learning Hierarchical Temporal Memory (HTM) Associated terms Expert systems Artificial Neural Nets (ANN) Machine learning Machine intelligence Data sources Rules from experts Large datasets Data streams Training Programmed by experts Derived from labeled databases Derived from unlabeled data streams Outputs Answers to questions Classification Prediction Anomaly detection Classification Batch vs. continuous learning Batch Batch Continuous Need to know what you are looking for Yes Requires labeled data No Many individual models Hard Hard Easy Biological basis None Simple Realistic Provides roadmap to machine intelligence No No Yes Summary We return to the question of terminology that we started this post with. Our feeling is that the term artificial intelligence has been used in so many ways that it is now confusing. People use AI to refer to all three approaches described above, plus others, and therefore has become almost meaningless. The term machine learning is a more narrowly defined term for machines that learn from data, including simple neural models such as ANNs and Deep Learning. We use the term machine intelligence to refer to machines that learn but are aligned with the Biological Neural Network approach. Although there still is much work ahead of us, we believe the Biological Neural Network approach is the fastest and most direct path to truly intelligent machines. This blog entry was modified on Thu Mar 24 2016 to clarify the timing of neural network research. Numenta Jeff Hawkins & Donna Dubinsky All Blog Posts Numenta 2016/01/11 Jeff Hawkins & Donna Dubinsky What is Machine Intelligence vs. Machine Learning vs. Deep Learning vs. Artificial Intelligence (AI)?","title":"What is Machine Intelligence vs. Machine Learning vs. Deep Learning vs. Artificial Intelligence (AI)?"},{"path":"/blog/2016/01/14/and-the-award-goes-to/","text":"And the award goes to... Thu, Jan 14, 2016 BlogAnd the award goes to... Christy Maver Director of Marketing This morning, as Hollywood anxiously awaited to hear the nominees for this year s Academy Awards, another set of winners was recognized not for motion pictures, but for artificial intelligence. The Global Annual Achievement Awards for Artificial Intelligence were announced today by http://Awards.AI. Awards.AI is part of the Informed.AI Network, which provides a range of information resources for Artificial Intelligence and Machine Learning. The awards are voted on by its community and designed to celebrate the various achievements in developing new algorithms, products and services across a number of different categories and industries, as well as the work of startups and individuals whose focus on AI is advancing the field. There s no question that interest, activity and progress in the field of artificial intelligence, (or machine intelligence, as we would say here at Numenta) is increasing every day. The existence of these awards is a testament to the growing enthusiasm for this space. We were honored to see the community recognize our work, along with our strategic partner, Cortical.io, in several of the 10 categories of achievement in 2015: Award Winner AI Company of the Year Numenta AI Person of the Year Jeff Hawkins AI Application of the Year NuPIC AI Startup of the Year Cortical.io Our most recent newsletter shared what we thought to be highlights of our achievements in 2015. Cortical.io was recognized for developing a new approach for handling Big Text Data with highly efficient semantic fingerprints and the Cortical.io Retina, which is the first semantic engine able to process terabytes of unstructured text in real time, for any language or business domain. You can see the full list of winners at http://awards.ai/ or follow them on Twitter @Awards_AI. Most awards ceremonies include the seemingly never-ending I d like to thank speeches. Don t worry; no need to cue the orchestra here. I will simply say on behalf of Numenta, thanks to those who voted, and more importantly, thanks for following us and our work here. We appreciate the support, and it is great motivation as we set out to accomplish even more in 2016. Christy Maver Director of Marketing All Blog Posts Christy Maver 2016/01/14 Director of Marketing And the award goes to...","title":"And the award goes to..."},{"path":"/blog/2016/02/11/numenta-anomaly-benchmark-contest-ieee-wcci-2016/","text":"The NAB Competition 2016 Thu, Feb 11, 2016 BlogThe NAB Competition 2016 Taylor Wirfs Marketing Numenta Anomaly Benchmark (NAB) Competition IEEE WCCI (World Congress on Computational Intelligence) 2016 We are excited to announce the Numenta Anomaly Benchmark (NAB) Competition! Last year, we released NAB, the first ever open-source benchmark for evaluating real-time anomaly detection algorithms. This year, we want to further expand NAB by including more real-world datasets and benchmarked algorithms, through a fun competition - with cash prizes. The contest will be held in conjunction with the IEEE WCCI 2016 on July 25 29 in Vancouver, Canada. The competition offers two submission categories: Algorithms and Datasets. Want to see how your anomaly detection algorithm performs? Have a dataset with labeled anomalies? Then this contest is for you. Entries can be submitted to either category, or both. All entries should be sent to nab@numenta.org. Example entry of satellite data with labeled anomalies. See more examples. Entry Categories Algorithms Category We are looking for algorithms that detect anomalies in streaming data. Entries in this category must submit the following: - Detailed description of the algorithm and NAB results - Code to run the algorithm and re-create the results (GitHub link OK) - List of contributors and their contact information We will evaluate your algorithm by running your code on NAB v1.0. Results will be added to the NAB repository scoreboard, following the conference. Datasets Category We are looking for real-world, time-series datasets with labeled anomalies. Entries in this category must submit the following: - Data file(s) in CSV format - Anomaly labels, with timestamps at which the anomalies start - Detailed description of the data and anomalies - List of contributors and their contact information We will evaluate the dataset on the following characteristics: types of anomalies, relevance to real applications, quality, difficulty for algorithms, quantity of data (more files in your set, the better), and feasibility for detection. Viable datasets will be added to the next version of NAB, shortly after the competition ends. Prizes $$ All work and no play is no fun. We will be awarding up to $10,000 in cash prizes for your contributions to NAB. Rules and Eligibility For a complete list of rules and contest eligibility, visit: http://numenta.org/nab/. Deadline and Questions Submissions are due by July 1, 2016. We encourage you to ask questions, and submit entries ASAP so we can ensure they meet all the requirements. Contact us with any questions at nab@numenta.org. Ready to get started? Check out these resources: - NAB GitHub Repository - NAB Technical Paper - Evaluating Real-Time Anomaly Detection: The Numenta Benchmark Video presentation given by VP Research, Subutai Ahmad at MLConf (Nov. 2015) - Example Algorithms and Dataset Entries Taylor Wirfs Marketing All Blog Posts Taylor Wirfs 2016/02/11 Marketing The NAB Competition 2016","title":"The NAB Competition 2016"},{"path":"/blog/2016/02/18/real-time-insights-from-a-random-walk-htm-for-stocks-hits-the-iphone/","text":"Real-time Insights from a Random Walk: HTM for Stocks Hits the iPhone Thu, Feb 18, 2016 BlogReal-time Insights from a Random Walk: HTM for Stocks Hits the iPhone Christy Maver Director of Marketing While Numenta may not be in the business of selling traditional products, we are in the business of making our technology pervasive. To that end, we build sample applications that demonstrate the value of HTM, and we make the code available in our open source project. But while anyone can read about our technology and applications, experiencing them requires some serious computer science skills. That changed this month when we launched an iPhone version of our HTM for Stocks app. Android users can still access the app here. Now, all it takes to experience HTM is your cell phone. HTM can be applied in a variety of use cases, but we chose to focus this application on the stock market because you don t have to be an algorithms or investment expert to understand it. HTM for Stocks monitors financial and social data (specifically stock price, stock volume and Twitter volume) for a couple hundred stocks and alerts you in real-time when a significant anomaly is occurring. To illustrate the benefits of this application, think about how you would find securities anomalies without it. You d start with the list of 200 companies you want to monitor and you d have three data streams for each: the stock price, the stock volume and the Twitter volume. Rather than try to create 600 individual models and learn patterns in each one, you might set global thresholds like, Notify me when any stock price moves more than 1 standard deviation away from its moving average of the last 60 days. You would catch some anomalies this way, but you would miss the more subtle temporal anomalies. A couple recent examples demonstrate how HTM for Stocks finds these types of anomalies: Example #1 On February 17, HTM for Stocks found a purely temporal anomaly in the stock volume of FCX (Freeport-McMoRan). It is normal for stock volume to spike at the beginning and end of a trading day, with the data often resembling a U shape. However, it s very rare for a stock s volume to spike twice in a short time frame. HTM for Stocks catches this anomaly, where other detection methods like thresholding would not. Interestingly, HTM for Stocks identifies temporal anomalies in the Twitter volume just before the stock volume anomaly. The Twitter volume data not only indicates that something unusual is happening with this stock, it also serves as root cause analysis. You can view the underlying Twitter data by tapping on it to reveal the tweets. This allows you to get qualitative insights and see what people are saying about the company s stock. In this case, many of the tweets were advising shareholders to sell this particular stock if it go to a certain price. Example #2 On February 4, HTM for Stocks picked up an unusually high volume of Twitter activity for Conoco Phillips before the market opened. The company had announced a large decrease in dividends. This was followed by anomalous stock volume movement where again we see a double spike at the beginning of market hours. We also see multiple Twitter volume anomalies throughout the day. Much like the previous example, these anomalies are temporal in nature, and would not necessarily be caught using a global alert or thresholding technique. HTM for Stocks demonstrates the value of combining multiple metrics. If you were only monitoring any one of these 3 streams (stock price, volume and Twitter volume), you might miss some important anomalies. But if two or three data streams are displaying unusual behavior at the same time, something truly significant is happening. Numenta has no plans to turn this into a commercial application, but it s easy to see how someone could. The amount of data we are faced with in a single day continues to grow while the amount of hours in a day never will. The underlying technology is not specific to stocks but can be applied to many different streaming applications. The ability to do anomaly detection in streaming analytics with large, noisy data streams offer real-time insights and a competitive advantage. I hope you ll download HTM for Stocks and give it a try. Let us know what anomalies you find by contacting feedback@numenta.com or leave a comment below. Christy Maver Director of Marketing All Blog Posts Christy Maver 2016/02/18 Director of Marketing Real-time Insights from a Random Walk: HTM for Stocks Hits the iPhone","title":"Real-time Insights from a Random Walk: HTM for Stocks Hits the iPhone"},{"path":"/blog/2016/03/30/numenta-at-computational-and-systems-neuroscience-conference/","text":"Numenta at the Computational and Systems Neuroscience Conference (COSYNE) Wed, Mar 30, 2016 BlogNumenta at the Computational and Systems Neuroscience Conference (COSYNE) Yuwei Cui Research Engineer Earlier this month, I attended the annual Computational and Systems Neuroscience meeting (Cosyne) in Salt Lake City. Cosyne is a peer reviewed scientific conference that brings experimental and theoretical neuroscientists together to exchange data and ideas. Why does a machine intelligence company attend a neuroscience meeting? Numenta s approach to machine intelligence starts with a deep understanding of how the neocortex learns. We use the brain as a blueprint. The HTM theory is not only inspired by neuroscience concepts, but also constrained by detailed neuroscience findings. Neuroscientists, using many new tools, have made tremendous advancements in understanding the physiology and connectivity of the brain. We would like to see whether the latest experimental evidences could fit into the HTM theory. If not, how should we revise the theory to be consistent with the experimental observations? From neuroscience findings to machine intelligence This year we presented a poster on a theory of sequence memory in the neocortex. The ability to recognize and memorize regular temporal patterns from sensory input streams is critical for almost all cortical functions. The topic of neural representations of time and sequence in the cortex was very popular at Cosyne this year, as you can see in the program guide. Our work is unique, as it is not only built on concrete experimental findings from neuroscience and makes a number of experimentally testable predictions, but also achieves compelling performance on real-world sequence learning tasks. Neurons in the neocortex receive thousands of inputs on their highly elaborated dendritic trees. Unlike most artificial neural network models individual dendritic branches act as active pattern detectors: co-activation of a number of synapses leads to a dendritic spike that can depolarize the cell body for hundreds of milliseconds. This phenomenon of active dendrites has been known for a long time among neuroscientists. A number of presentations at Cosyne modeled the biophysical mechanism underlying dendritic spikes. Nevertheless, the function of dendritic spikes remains unclear and it is not incorporated in most neural network models. Left: A pyramidal neuron in the cortex (Spruston 2008, Nat Rev Neurosci). Right: Researchers stimulated individual synapses optically and measured voltage responses at the soma. Simultaneous stimulation of enough synapses (8 in this case) caused a large and sustained depolarization at the cell body (Major et al., 2013, Annu Rev Neurosci). The HTM sequence memory model utilizes the active dendrites of cortical neurons to learn sequences from data streams. Temporal sequences are learned via growth of new synapses and are represented with sparse distributed representations. Predictions of future inputs are made through the generation of dendritic spikes. The resulting model gives rise to a powerful sequence memory, which not only achieves comparable performance to state-of-the-art machine learning algorithms, but also exhibits many desirable attributes for real-world sequence learning with streaming data. HTM sequence memory model makes accurate 2.5 hour ahead-predictions of taxi demand in the New York City. Interactions with other neuroscientists Our work attracted wide interest among neuroscientists. Several experimental neuroscientists were very excited to learn about the important functional role of the long observed phenomena of dendritic spikes. Some even expressed interest in running more specific experiments to test the learning mechanisms used in HTM. We also benefited by discussing with other neuroscientists. For example, by talking with researchers that build detailed biophysical models of active dendrites, we now have a better idea of how HTM would work on a detailed biophysical level. I found quite a few other presentations at Cosyne that were related to HTM. Prof. Michael Berry s group from Princeton University recorded a large population of neurons in the primary visual cortex during the presentation of image sequences. The observed behavior of the real neural population matches many aspects of the HTM sequence memory model. Prof. Jose Carmena from UC Berkeley presented a novel paradigm for brain-machine interface where subjects continuously learn to control a small set of neurons. Interestingly, the performance over time looks quite similar to that of the HTM model on a continuous learning task. These studies, and many others, give us valuable insights on the development of future HTM algorithms. We would like to keep collaborating with the neuroscience community. We believe doing so would tremendously speed up our progress on machine intelligence. I encourage you to take a look at our poster and the accompanying paper. Please also check out this recently published Frontiers Neural Circuit paper to learn about the HTM theory. Let me know what you think of it by contacting ycui@numenta.com and join the discussion of HTM in the NuPIC community. Numenta Cosyne Poster. Click to enlarge. Yuwei Cui Research Engineer All Blog Posts Yuwei Cui 2016/03/30 Research Engineer Numenta at the Computational and Systems Neuroscience Conference (COSYNE)","title":"Numenta at the Computational and Systems Neuroscience Conference (COSYNE)"},{"path":"/blog/2016/06/16/can-neuroscientists-understand-the-brain/","text":"Can Neuroscientists Understand the Brain? Thu, Jun 16, 2016 BlogCan Neuroscientists Understand the Brain? Subutai Ahmad VP of Research Eric Jonas and Konrad Kording just released a provocative paper, Could a neuroscientist understand a microprocessor? [1] In their paper, they ask whether current neuroscience techniques could discover the operations of a simple microprocessor[2]. Their reasoning is as follows. The field of neuroscience is trying to understand the computational properties of the brain. If we think current neuroscience techniques are sufficient to understand something as complex as the brain, surely they will be able to handle a small microprocessor. If, on the other hand, current techniques are insufficient to understand even this simple CPU, it raises serious questions about the current approaches in the field. True, the brain is not a silicon processor but there are similarities (they list several in the paper). So let s apply these techniques to this simpler computational system as a litmus test. Their methodology includes applying an array of traditional techniques such as lesioning, examining statistics of bit patterns, analyzing tuning properties of transistors, dimensionality reduction, etc. They studied the microprocessor in vivo while playing a variety of video games (you can tell they had a lot of fun with this project!) They were able to discover that transistors exhibited very low pairwise correlations but were not actually independent (very similar to behavior of neurons[3]). They showed strong spatiotemporal structure in the activity of various processor components. The resulting plots and charts look remarkably similar to those in neuroscience papers. Yet these techniques did not uncover the true computational nature of the microprocessor nor its functional structure. Of course, in this process what they are really asking is Could a neuroscientist understand the brain ?[4] Their conclusion: an unequivocal NO . We all know that correlation does not imply causation . Current statistical techniques report all sorts of correlations, but little regarding true underlying structure. What does it mean to understand the brain? So what does it really mean to understand the brain? Unfortunately the paper does not answer this question. They do make vague comments that the field should understand how the output relates to the inputs , and that it should reward \"those who innovate methodologically.\" These statements are unsatisfactory at best. I propose a much stronger answer. As a computer scientist, I believe the only way to be certain you understand something is to build it. Write the program for it. We don t need to create an exact replica, just a system that demonstrates the important properties. This methodology is harder but demands that you uncover underlying structure and function. Let me give an analogy using a different paradigm. Suppose cars didn t exist. Humans somehow get access to a luxury Mercedes sedan and the race is on to understand how it works. Let s consider two alternative approaches. The first approach involves calculating a number of statistical measures and building predictive models. These models might accurately predict the car s gas mileage under different conditions, such as going uphill vs downhill. They might be able to plot precise acceleration profiles under different loads. They would know exactly how long it takes the air conditioning to cool the car in different climates. Scientists would publish thousands of peer-reviewed papers with all sorts of equations and charts proving the accuracy of these models. But would they really understand how the car works? The second approach involves using the car to deduce fundamental mechanisms such as a power source, transmission, and steering. It would focus on the function of these subsystems, and less on details such as the strength of bolts or the efficiency of water pumps. To test our theories of function we would build a much simpler machine from scratch, perhaps something like a Ford Model T[5]. This car would have a super simple engine and hand cranked starter. The controls might be awkward, the tires bad, and the seats uncomfortable. It would definitely have no air conditioning. It might not even be as fast as a horse! But, you could actually drive this car. Because we understand how our simple car works, over time we can improve it and eventually build vehicles even better than the Mercedes prototype. What is our approach? At Numenta we are using this second approach to understanding the brain. We are building the Model T equivalent of the neocortex. We use neuroscience discoveries and details to deduce the fundamental components of intelligence. For example, we know that the neocortex learns a predictive model of the world. It learns continuously without supervision. We know that behavior and sensory inference are not separate processes, but are intimately integrated such that learning cannot be achieved without behavior. Our theories are constrained by and consistent with a great many neurosciences details, but our software simulations only capture the functional properties of the brain and not all the details. We are often asked, How do you decide what neuroscience details to include in your simulations and which to leave out? The answer is we include neuroscience details when they are essential for function. When we hit stumbling blocks we return to experimental neuroscience to provide clues and hard constraints on how to solve problems. Our simulations also provide insights into the structure of cortex[6][7]. Compared to the brain, our software is at an early stage and primitive, like a Model T. But, you can actually take it for a spin, see how it performs, and then know what areas need improvement. Can we understand the brain? We have made excellent progress with our approach. If we stay focused on large-scale functional theories and building systems based on those theories, the answer to this question is an unequivocal YES ! Footnotes and Citations [1] Jonas, E., and Kording, K. (2016). Could a neuroscientist understand a microprocessor? Cold Spring Harbor Labs Journals bioRxiv doi:10.1101/055624. http://biorxiv.org/content/early/2016/05/26/055624.abstract [2] Specifically Motorola 6507, similar to what was used in the Apple I and Atari video game consoles 40 years ago. [3] Schneidman, E., Berry, M. J., Segev, R., and Bialek, W. (2006). Weak pairwise correlations imply strongly correlated network states in a neural population. Nature 440, 1007 12. doi:10.1038/nature04701. [4] Note that the paper specifically targets computational neuroscience techniques, not experimental neuroscience. The amount of experimental data in neuroscience has been exploding exponentially, but without good theoretical guidance uncovering value is like finding a needle in a haystack. [5] https://en.wikipedia.org/wiki/Ford_Model_T [6] Hawkins, J., and Ahmad, S. (2016). Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex. Front. Neural Circuits 10. doi:10.3389/fncir.2016.00023. http://journal.frontiersin.org/article/10.3389/fncir.2016.00023/full [7] Ahmad, S., and Hawkins, J. (2016). How do neurons operate on sparse distributed representations? A mathematical theory of sparsity, neurons and active dendrites. arXiv:1601.00720 [q bio.NC]. Available at: http://arxiv.org/abs/1601.00720. Subutai Ahmad VP of Research All Blog Posts Subutai Ahmad 2016/06/16 VP of Research Can Neuroscientists Understand the Brain?","title":"Can Neuroscientists Understand the Brain?"},{"path":"/blog/2016/08/04/revisiting-a-1986-essay-on-brain-theory/","text":"Revisiting a 1986 Essay on Brain Theory Thu, Aug 04, 2016 BlogRevisiting a 1986 Essay on Brain Theory Jeff Hawkins Co-Founder This week I received an email from a gentleman in Japan. He was creating materials for a course and asked permission to include an extensive passage I had written. What surprised me about his request was that the passage was not from a paper I wrote at Numenta, nor from my time at the Redwood Neuroscience Institute, nor was it from my book On Intelligence. It was from an essay I d written over 30 years ago when I was a graduate student at UC Berkeley. In January 1986 I gave up my career at a hot computer start-up company to become a full-time graduate student. I wanted to study how the brain works and this seemed my best option. When I arrived at Berkeley I was eager to take every neuroscience course they offered and to dive into my research. It didn t take long for me to become dismayed. I was told I had to take courses that were uninteresting to me, such as a foreign language and organic chemistry lab, and worse, I might not be able to study brain theory at all. I met with the chairman of the graduate group of neurobiology, Dr. Frank Werblin, to get his advice. He suggested that I write a paper on what I wanted to accomplish as a PhD student. So that s what I did in the spring of 1986. During that time I had the epiphany that the neocortex builds a predictive model of the world. Every part of the neocortex is continuously predicting what input it is going to receive. This is not the only thing the neocortex does but it is a tangible problem. If I could decipher how neurons learn to make predictions of changing inputs it would expose core principles underlying everything the neocortex does. The paper that I ultimately wrote made two arguments. First, I argued that it was possible to understand how the neocortex works, that it could be done in a matter of years, not centuries. I was surprised to learn that almost all neuroscientists and funding agencies disagreed. Second, I proposed that my research would initially focus on how neural tissue learns predictive models. Dr. Werblin read my paper and we sat down for lunch to discuss it. He was kind and supportive of my overall goal but he said the reality was that I could not work on brain theory for my PhD thesis. He explained that it was not possible to get funding for the kind of theoretical studies I wanted to do and because of this there were no faculty members at Berkeley, nor anywhere else, that I could work with. Being a theoretical neuroscientist was not an option at that time. The title of my paper was An Investigation of Adaptive Behavior towards a Theory of Neocortical Function*. It was from this paper that the gentleman from Japan wanted an excerpt. I had not read this paper in many years so I sat down to read it again this week. There are of course things that I would write differently today, and our neuroscience knowledge has advanced significantly, but many of the ideas and aspirations I had back then I still hold today. Thirty years later we have made significant progress in neocortical theory and I remain confident we can complete a comprehensive theory of the neocortex in the next few years. My enthusiasm and optimism have not changed, nor has my approach to the problem. If you are interested in a historical perspective underlying Numenta s goals you might enjoy reading my paper from thirty years ago. Understanding how the brain works is recognized by many as one of the most important scientific endeavors of all time and, I believe, worthy of a lifetime of effort. * There are a few typographical errors in the document, these came from scanning the original printed version many years ago. Jeff Hawkins Co-Founder All Blog Posts Jeff Hawkins 2016/08/04 Co-Founder Revisiting a 1986 Essay on Brain Theory","title":"Revisiting a 1986 Essay on Brain Theory"},{"path":"/blog/2016/08/10/numenta-anomaly-benchmark-nab-competition-2016-winners/","text":"NAB Competition 2016 Winners Wed, Aug 10, 2016 BlogNAB Competition 2016 Winners Zuha Agha Algorithms Intern The wait is over! We are proud to announce the winners of the 2016 Numenta Anomaly Benchmark (NAB) Competition, held in conjunction with IEEE World Congress on Computational Intelligence. The competition, which ran from February through July this year, comes to a close after an exciting round of submissions. This was the first ever publicly held contest for NAB. When NAB was introduced last year, its mission was to address the need for a standardized and publicly accessible benchmark for performance evaluation of real-time anomaly detection. NAB s open source repository includes over 50 labeled data streams from a wide range of real-world sources that capture the traits crucial for testing anomaly detection in streaming data. In addition, NAB contains a collection of popular anomaly detection algorithms and a unique scoring scheme that enables effective comparison of different detection methods against each other. In an effort to take our mission of expanding NAB even further, we launched the inaugural NAB Competition where participants can showcase their understanding of real-time anomaly detection by contributing suitable datasets or algorithms, and get a chance to win exciting cash prizes in return. Overall, the competition was well received by the research community and attracted submissions not only from the U.S but across the globe, including India and Russia. After careful consideration, we decided on the following list of winners for the two competition categories: Dataset Category Winners Prize Name #1 Samya Bagchi #2 BK Ramesh Algorithms Category Winners Prize Name(s) #1 Mikhail Smirnov #2 Felix Andrews #3 Vladislav Ishimtsev & Evgeny Burnaev All winning entries demonstrated creativity and a good sense of the problem definition. In the dataset category, the entry bagging first prize provided labeled anomalies for real patient blood pressure data, a very important domain for streaming analytics. The second prize was awarded to a dataset retrieved from a car engine motor system with annotated anomalies for voltage and current metrics. Here are some interesting examples of anomalies from our winning datasets, shown with red dots. The graph above shows a patient s blood pressure readings every 5 milliseconds as the pressure drops steadily from diastole to systole. Every small oscillatory pattern represents a heartbeat. The first anomaly indicates pressure noise and the second anomaly indicates an irregular heartbeat, given by subtle temporal pattern changes. This graph shows current sensor data of a motor engine. The first anomaly is an increase in maximum amplitude of a cycle, followed by another anomaly that shows a lag in starting the engine and the last anomaly resulting in engine failure. In the algorithms category, winning submissions also achieved very impressive scores on the benchmark. The entry securing first place worked with a novel contextual encoding scheme, followed closely in second place by a modified Hierarchical Temporal Memory algorithm, and third place by a k-nearest neighbor context based approach. All of these datasets and algorithms are valuable contributions to NAB, helping accelerate our efforts to grow this benchmark and improve its usefulness for all researchers. Winning entries are to be officially included in an upcoming version release of NAB, and the algorithm scores will be displayed on the NAB leaderboard. We would like to extend our heartiest congratulations to all of our winners on their achievement! We are also thankful to all participants for their commendable effort and enthusiasm. The NAB competition hopes to return next year, but until then we continue to welcome all relevant contributions at our open-source code base https://github.com/numenta/NAB. For any questions or comments on NAB, you can post at https://discourse.numenta.org/c/nupic/nab. Zuha Agha is spending her summer as an Algorithms Intern at Numenta. She is a student of PhD Computer Science at University of Pittsburgh. Her interests lie at the crossroads of Machine Learning, Artificial Intelligence and Computer Vision. In her free time, she loves reading and learning new skills. Zuha Agha Algorithms Intern All Blog Posts Zuha Agha 2016/08/10 Algorithms Intern NAB Competition 2016 Winners","title":"NAB Competition 2016 Winners"},{"path":"/blog/2016/08/18/an-insiders-look-interview-with-yang-lan-and-jeff-hawkins/","text":"An Insider’s Look: Interview with Yang Lan and Jeff Hawkins Thu, Aug 18, 2016 BlogAn Insider s Look: Interview with Yang Lan and Jeff Hawkins Taylor Wirfs Marketing In the two years I ve been at Numenta, I ve seen the field of AI grow to become a focal point of technology news. During this same time, I ve also witnessed the interest in our work continues to grow. So it didn t come as a surprise when I learned a Chinese TV crew wanted to film an interview with our co-founder, Jeff Hawkins, at our office. But it did come as a surprise to hear that the interview was with Yang Lan, a prominent broadcast journalist and figure who has been referred to as the Oprah of China. She hosts several TV talk shows, is the cofounder and chairperson of Sun Media Group and Sun Culture Foundation, and was listed by Forbes as one of the top 100 most powerful women. The interview with Jeff is to be featured as part of Yang Lan s upcoming documentary series on Artificial Intelligence. Yang Lan and her team travelled across the globe to interview knowledgeable researchers, technologists and leaders on their opinions and findings. The documentary series is set to air in China at the end of this year and will be seen by upwards of a billion people; there will be an English version afterwards as well. We ll update this blog when the interview becomes available, with instructions on how to access it. The View Behind the Scenes The film and production crew of 11 (yes eleven!) people arrived at our office in Redwood City, CA; a bit early for the 8:30 a.m. appointment and quickly took over our office. A coordinator based on the west coast had visited Numenta a week prior to the interview, to discuss details and scout the office for filming locations. The team chose to set up two chairs in the middle of the office, with a view of a neuron mural from neuroscientist Santiago Ramon y Cajal, on our wall in the background. We have a small team at Numenta, around 15 employees plus a few interns that join us every summer, so our office is small. Thursday is a no-meeting day, when many employees choose to work from home. This worked well to accommodate the large film crew, as the staff members who were present were displaced from their desks to various locations around the office. This photo only shows half of the production crew. Other members were busy in one of our conference rooms. Yang Lan arrived once the cameras were setup, and was greeted by our eager staff and her production crew. After a few introductions, sound checks and lighting adjustments, the cameras began rolling. Her first few questions focused on Jeff s background and how he arrived at Numenta s mission today - reverse-engineering the neocortex. Jeff referenced his prior work as computers were fun to work on, but my real passion was brains. He described solving brains as a difficult problem, but also as one of the most important problems in the world. The next series of questions from Yang Lan evoked a more lively discussion. It was clear that she knew Numenta s approach was different than traditional machine learning methods, but she wanted Jeff to explain why. He went into detail on why Numenta is studying the neocortex as a blueprint for machine intelligence. Jeff defined intelligence and highlighted one of the crucial processes involved when learning a model of the world: the brain works on time-based data. He also addressed the fears from those concerned with the creation of intelligent machines, a highly debated topic in artificial intelligence. Yang Lan interviews Jeff Hawkins at our office. The interview went smoothly, with the exception of an interruption from a deliveryman at our door. After the interview, Jeff showed Yang Lan several of our example applications and visualizations, to help her audience visualize our technology. A Numenta employee, who was working remotely, signed on to our tele-presence robot (made by Double Robotics) and introduced himself while navigating the robot through the office for Yang Lan and her film crew. Between set-up, the interview, b-roll footage and takedown, the production team spent four hours at our office, but by the afternoon, the office had returned to its norm. Seeing the effort that occurs behind the scenes of a documentary film interview was impressive. The real highlight though was witnessing the live, uncut version of an interview with Yang Lan. We don t know what the final piece will look like and how the producers plan to include Numenta, but it was exciting to be a part of this documentary series. Taylor Wirfs Marketing All Blog Posts Taylor Wirfs 2016/08/18 Marketing An Insider’s Look: Interview with Yang Lan and Jeff Hawkins","title":"An Insider’s Look: Interview with Yang Lan and Jeff Hawkins"},{"path":"/blog/2016/09/02/why-did-we-completely-change-our-website-design-the-story-behind-our-new-look/","text":"Why Did We Completely Change Our Website Design? The Story Behind Our New Look Fri, Sep 02, 2016 BlogWhy Did We Completely Change Our Website Design? The Story Behind Our New Look Christy Maver Director of Marketing If you ve been to numenta.com before you may notice that something looks a little or perhaps more than a little different. After months of behind the scenes remodeling, we ve launched our newly designed website. A website redesign is not an uncommon endeavor. In fact I ve been part of at least one redesign at every company where I have worked. Sometimes they re driven by welcome trends, like responsive design. Can you remember a time when you didn t look at a website on your phone and expect the same experience you get on your laptop? Other times they re driven by passing fads blinking marquees, background music and continuous carousels come to mind. Our redesign came out of a frustration and observation by Numenta co-founder, Jeff Hawkins. He found many websites frustrating to use and observed that he almost always first went to Wikipedia to learn about a company. According to Jeff, Websites have become so burdened with graphics, messages, and clever navigation that it can be challenging finding the information you want. I was struck by this one day when I couldn t find something on our own website! I also realized that Wikipedia had become my default first step when researching a new company. It was almost always faster and easier to get answers to my questions from a Wikipedia entry than from the company s own website. That was a sign that website designs have become broken. A discussion on Wikipedia ensued. Why does it work? For one thing, it does not contain the flowery marketing language and images woven through most websites. It presents just the facts or at least the facts according to the collective community. Just as importantly, it strips out the navigation complexities common to many sites. It gives you all of the information related to a topic on one page and presents it in a consistent format. From that discussion, an experiment was born. Could we take some of these principles and apply them to a corporate site? Could we tell Numenta s story in a way that lets the end user quickly find what they are looking for, whether it s a first-time visitor, someone interested in partnering with us, or a professor looking for a specific paper she once saw to use in her coursework? Could we present the information in a clear and concise manner that works quickly and efficiently on mobile and full screen devices? The newly designed numenta.com is our attempt to do just that. Our goal with this site is to educate people about Numenta and our approach to machine intelligence. For those who want a comprehensive view of Numenta, they can walk through each section in order, start to finish. For those who are looking for something in particular we hope they can find it quickly under one of the top-level headings. We believe the new site will allow us to engage with more people more efficiently. You ll notice that in this new design there is just one page with the content organized in a set of expandable categories, similar to how Wikipedia organizes content. You ll also find pointers to our companion site, numenta.org. Numenta.com focuses on the business side of Numenta. Numenta.org contains more technical information, including education about our Hierarchical Temporal Memory (HTM) technology, and how to get started with HTM in open source. I invite you to take a drive through the site. Whether it s your first or fiftieth time there, hopefully you ll learn something about Numenta that you didn t know before. Drop us a line and let us know what you think. Christy Maver Director of Marketing All Blog Posts Christy Maver 2016/09/02 Director of Marketing Why Did We Completely Change Our Website Design? The Story Behind Our New Look","title":"Why Did We Completely Change Our Website Design? The Story Behind Our New Look"},{"path":"/blog/2016/09/23/how-htm-studio-came-to-life/","text":"How HTM Studio Came to Life Fri, Sep 23, 2016 BlogHow HTM Studio Came to Life Numenta Marion Le Borgne & Taylor Wirfs It s been a few months since we first launched HTM Studio and things have calmed down from a development perspective. I sat down with Marion Le Borgne, project manager and lead engineer for HTM Studio, to get her thoughts on the process and efforts it took to build the application. Before we get into the nitty-gritty of software development, can you tell us a little more about yourself and role at Numenta? I am a Senior Software Engineer at Numenta and Project Manager for HTM Studio. I started my career as a Business Analyst at Partech Ventures in Europe and then joined CloudWeaver (acquired by F5 networks) as a Data Scientist. After attending a Hackathon organized by the Numenta OS community in 2014, I was hooked by the mission of the company. I started working at Numenta in 2015. In the same year, I co-founded NeuroTechX, an international non-profit for neurotechnology. Why did you build HTM Studio? HTM Studio was built in response to the many inquiries about our technology from users who wanted to use HTM algorithms, but lacked the technical skill needed to experiment with our open source code. We decided to build an app that would accomplish exactly that: allow users to try HTM algorithms on their own data in minutes, without prior coding experience or a knowledge of HTM algorithms. What was the development process like? Research and Product Design My initial research helped me develop the first set of features in HTM Studio. I started researching existing tools to understand how people packaged other streaming analytics offerings. I also reviewed past proof of concepts to learn what had and had not worked for Numenta. During my research, it became clear that HTM Studio needed to be a desktop app to address data privacy concerns. After that, I created a first round of wireframes for the general flow of the app. A couple of feedback sessions later, the wireframes started looking like today s HTM Studio. Architecting the Application Next, we began to greenfield the app and lay out the architecture. This leads me to the unique technical stack in HTM Studio. We wanted to build a desktop app that leveraged modern web technologies, so that HTM Studio was responsive and beautiful. We chose Github Electron, a framework that lets you write cross-platform desktop applications using JavaScript, HTML and CSS. We packaged Python with NuPIC, so it could run within HTM Studio. This allowed users with no programming knowledge to use NuPIC without having to install it separately. Testing the Machine Learning Algorithm We developed a method to simplify the process of finding the best HTM parameters called param finder . Historically we used a complex method called swarming, but the new param finder skips this step and quickly finds the optimal parameters. Then, we spent about a month on the accuracy of the algorithm results. It was important that the app (and especially the new param finder) provided accurate results on various datasets. We added compatibility tests with NAB to test the results. Testing the UX Once we had these three elements (Electron, portable NuPIC and param finder) in place, we started UX testing. The goal was to gather feedback from a variety of users with different datasets and use cases, to fine tune the app and ensure HTM Studio was easy to use. We launched the private beta in May, and went through a lot of QA testing and bug hunting. A few weeks later, we were finally able to launch the public release. Was there anything that surprised you during development? We had a couple setbacks that were mainly on the technical side. First, packaging NuPIC (the Python bindings and C libraries) along with a portable Python distribution was a project in itself. We wanted to ensure that users who did not have NuPIC or Python could run HTM Studio. Second, we wanted to incorporate dynamically updating charts to demonstrate the continuous learning that occurs in the HTM algorithms. It took us a while to reach a point where chart navigation was smooth and responsive. How was the launch experience? The launch went well. I had numerous 1:1 sessions with private beta users to get feedback on the app before the final launch, so there weren t any last minute surprises. The feedback from these sessions was very valuable. We learned about various use cases, data formats and how users intended to use HTM Studio. These 1:1 sessions confirmed two things: the target audience for HTM Studio and which features should be added or simplified. What s your favorite feature and why do you think it s useful? The param finder is a great feature. It allows you to get up and running with HTM technology in a couple of minutes, without having to worry about setting any parameters. I especially like that this feature is coupled with the advanced settings feature. That way, if you are familiar with HTM theory, you can have more control over the machine learning algorithm. HTM Studio automatically determines the best parameters for your dataset. Users familiar with HTM can tweak their parameters in advanced settings. If you had an infinite amount of resources available, what would you include in a future version? Predictions. I think this would be a really great addition to HTM Studio, which is currently geared towards anomaly detection. Any last thoughts? Shaping and building this app was a really collaborative process, with a lot of feedback from the Numenta team and private beta testers. Collaboration was required between research, engineering and product teams, and I enjoyed this aspect of the project the most. HTM Studio is built on years of research that made the HTM algorithms what they are today. It s great to see that HTM algorithms are now accessible to anyone. Numenta Marion Le Borgne & Taylor Wirfs All Blog Posts Numenta 2016/09/23 Marion Le Borgne & Taylor Wirfs How HTM Studio Came to Life","title":"How HTM Studio Came to Life"},{"path":"/brain-science/","text":"Brain Science Brain Science Reverse engineering the neocortex to figure out how the brain works is a problem that many people think cannot be solved. We disagree. Solving any scientific challenge is possible when you match empirical evidence with theory. Our team of researchers are constantly reading neuroscience papers and studies that focus on various aspects of the brain. While there is no shortage of neuroscientists that specialize in particular areas, Numenta takes the unique approach of looking across these studies and putting the pieces together to make a working theory of the neocortex. We call this theory Hierarchical Temporal Memory, (HTM), a framework for both biological and machine intelligence. This framework applies to everything the neocortex does from vision to language to motor and more. Nothing is task-specific. Everything operates on the same universal algorithms. Next: Machine Intelligence Technology ","title":"Brain Science"},{"path":"/business-strategy-and-ip/","text":"Business Strategy &amp; IP Business Strategy & IP Numenta s business strategy and approach to intellectual property (IP) is to create an active research community as well as to enable strong commercial opportunities. To that end, we follow these general principles: 1. Transparency . We openly publish our scientific findings, software, intellectual property, and business strategy. There are no hidden agendas. 2. Scientific Use . Anyone can freely use our software and intellectual property for non-commercial purposes. 3. Commercial Deployment . Our software can be used for free under an AGPL license. If the AGPL license is not a good fit, we offer low cost licenses that enable commercial use and create a sustainable business opportunity for Numenta. 1. Transparency We have enabled a community of researchers and developers working on HTM technology in the NuPIC open source community at http://numenta.org . We post all of our application and algorithm code in NuPIC as well as our research updates as they occur. We publish our work in peer-reviewed journals and submit pre-publication manuscripts to arXiv. We also speak at a variety of forums, such as machine learning, data science, neuroscience, and application-specific events. Other than confidential information relating to partner relationships, products or data, we work as much in the open as possible. Given the uniqueness of our work and our early focus on temporal data, we have been issued over thirty U.S. and international patents. The list of issued U.S. patents can be found here. In addition, we have international patents filed that are not included in this list. We believe these patents cover some of the foundational principles of machine intelligence. 2. Scientific Use Our software, along with its associated IP, is available at http://numenta.org under the AGPLv3 license at no cost. Scientists, researchers, and students are able to use our technology by agreeing to the terms of this open source license. For those researchers who are unable to use the AGPLv3 license, we have created a separate, no-cost, non-commercial, trial license. For those scientists and researchers who want to use our intellectual property without our software, or whose work may be covered by our patents, we make a clear statement of non-assertion: as long as your work is for non-commercial use, we will not assert our patents.3. Commercial Deployment In our terminology, commercial use means using the technology or patents to create a product or service that is sold, licensed, hosted, or offered to customers or business partners as standalone functionality or as part of another product, whether for a fee or not. In addition, commercial use includes deploying the technology or patents internally to be used in any business process. For example, if you use our technology or patents internally to monitor performance of your IT servers, even if you don t offer it to others, we view this as commercial use. Commercial partners are welcome to use our software under the terms of the AGPLv3 license. For those who want to distribute derivative software and do not want to accept these terms, we have a commercial license available , which may change as we develop our business. For those who do not want to license our software but want to license our patents, we will offer a patent-only license. Our intention is to offer low-cost ways for partners to commercialize this technology. We believe that a broad-based strategy is compelling for a technology that is likely to be widely deployed in time. Please contact us at sales@numenta.com if you are interested in this license. Summary of Numenta LicensesSoftware (includes IP)Patents OnlyScientists, Researchers, or any Non-commercial useAGPLv3 or trial license (both no cost)Non-assert statement for non-commercial purposesCommercial useUse internally only: AGPLv3 (no cost)Able to offer to others under the terms of the AGPLv3, including making source code available: AGPLv3 (no cost)Prefer to keep code proprietary: Commercial license (fee)Patent license (under development fee TBD)Numenta Licensing FAQ I operate a business. Why wouldn t I use the free AGPL version for my product?You are welcome to do so under the terms of that license. AGPL is a copyleft license. It requires that if you distribute or make available your software (either directly or through a SaaS model), you must also distribute the source code under the AGPL license. For some companies and some situations, that is an acceptable requirement. However, companies who want to keep the resulting code proprietary will prefer a commercial license.If I do not intend to distribute or make available as a SaaS implementation any derivative software, then it seems to me that I can use the AGPL version internally without any additional license, even if it is for a commercial purpose. For example, I run a hedge fund and I figured out how to use NuPIC to advantage, but I don t distribute the software or results, nor do I make it available to others. Is this correct?Generally you may use the software and patents for internal use under the AGPL. Note, however, if you do not use our open-source software (and thus do not fall under the AGPL), you WOULD need a license for our IP. For example, say you do your own, very specific version of HTM for your hedge fund. Once you deploy that within your company for any productive purpose (as opposed to research), you would need an IP license from us because you are not under the AGPL.I m a researcher who uses different machine learning techniques. I m trying to add capabilities that are similar to Numenta, i.e. using temporal data streams in a hierarchy, but I m not using your software. What are my obligations relative to Numenta? For researchers who are doing work that is covered by Numenta patents, we have promised to not assert our patents for any non-commercial use including publications, teaching, and experimentation. We do ask that you provide appropriate citations of our work. Make sure to visit our current repository of research papers. If you are a corporate researcher who is applying this technology to commercial use, then you will need to evaluate the Numenta patent portfolio to see if our patents cover your work. If so, you should contact us to explore a patent license. Next: Anomaly Detection Benchmark ","title":"Business Strategy &amp; IP"},{"path":"/careers-and-team/careers/internship-program/","text":"Internship Program Wed, Jan 01, 2014 CareersInternship Program Numenta Careers IMPORTANT NOTE: Numenta is unable to consider internship applications from international students unless they are currently enrolled in a US University, are US Citizens, or hold a Green Card. We have filled our technical intern positions for Summer 2016, and are no longer accepting applications. We do have one open intern position for Fall-Winter 2016, so you can submit an application if this time period is of interest. We will start accepting applications for Summer 2017 on October 1, 2016. Numenta s technical interns will get exposure to all aspects of HTM learning algorithms and our streaming analytics platform. The commitment is for 3 to 4 months, full time. We have internship positions in the following areas: Algorithms Internships What you can expect to learn: - The challenges of deploying complex machine learning algorithms in a production environment - Deep understanding of our open source machine learning algorithms Desired qualifications: - Experience with machine learning or pattern recognition algorithms - Strong experience with conducting machine learning experiments. This includes writing and evaluating machine learning algorithms - Excellent programming skills in either Python (preferred), Java or C++ - Enrolled in undergraduate or graduate studies in CS, EE or related disciplines - Preference given to candidates who have working knowledge of NuPIC or have contributed to the NuPIC community - Experience with data analytics Software Engineering Internships Our innovative real time streaming data prediction service runs locally and in the cloud, and includes both web and mobile applications. A developer API allows customers to integrate the service directly into their business. There are many interesting problems related to data analytics, visualization, architecting web based API s, and running complex algorithms reliably and quickly. As a Software Engineering intern, you will be exposed to all of these exciting areas. What you can expect to learn: - Improved understanding of data science - Improved understanding of modern software engineering practices - Working with professional development teams and experienced industry veterans Desired qualifications: - Excellent programming skills in at least one language, preferably Java, iPython or C++ - Enrolled in undergraduate or graduate studies in CS, EE or related disciplines - Experience with the latest web development technologies (HTML 5, JavaScript, CSS 3, JSON, REST, etc.) - Good understanding of cloud systems - Experience with machine learning or data analytics - Experience with NuPIC How to Apply Qualified applicants should send the following: - Cover letter describing their specific interest in Numenta. Please include any relevant experience with NuPIC. - Resume, including list of relevant course work. - Period of the internship (e.g.: summer, January-March, etc.) - Which area of internship you would like to be considered for. - Please email resume and cover letter to interns@numenta.com. Numenta is an equal opportunity employer supporting workforce diversity. APPLY NOW Numenta Careers All Careers Posts Numenta 2014/01/01 Careers Internship Program","title":"Internship Program"},{"path":"/careers-and-team/careers/research-internship/","text":"Research Internship Fri, Jan 22, 2016 CareersResearch Internship Numenta Careers IMPORTANT NOTE: Numenta is unable to consider internship applications from international applicants unless they currently enrolled in a US University, are US Citizens, or hold a Green Card or are NAFTA (Mexican or Canadian) citizens. About Opening The Research Group at Numenta is looking for outstanding PhD students or other research scientists for internship opportunities during the Fall - Winter 2016/2017 time frame (note that we have filled our Summer 2016 positions and are no longer accepting applications for this time period). We are looking for candidates with expertise in Machine Learning, Computational Neuroscience and/or Natural Language Processing. Preference given to candidates with experience in one or more of the following areas: sequence learning, natural language processing, neuron modeling, and computational models of cortex. The commitment is for 3 to 4 months full time (longer appointments up to one year may be possible). Numenta s research interns will get exposure to all aspects of Hierarchical Temporal Memory (HTM) learning algorithms, participate in leading edge research in computational neuroscience, and get full clearance to publish their work. What you can expect to learn and how you might contribute - The challenges of designing and implementing detailed models of cortical function that can be applied to real-world problems - Gain experience solving hard problems in domains such as natural language processing, streaming analytics, and/or sensorimotor inference - Participate in designing functional models of Layers 2/3, 4, 5, and 6, thalamocortical circuits, feedback circuits, and sensorimotor processing - Learn how to contribute to a top open source project, and improve your software engineering skills - Obtain a detailed understanding of Hierarchical Temporal Memory Desired qualifications - Currently enrolled in a MS or PhD program, or a recent graduate, or equivalent research experience - Strong research background in machine learning or machine intelligence - Strong research background in computational neuroscience - Excellent algorithmic problem solving skills, and the ability to implement solutions in Python, C/C++, Java, etc. - Established track record of publications in leading peer reviewed conferences and journals - Working knowledge of HTM algorithms a plus - Excellent written and verbal communication skills, and the ability to work in a team oriented environment - A belief that the best way to build intelligent machines is to understand the cortex How To Apply Qualified applicants should send the following: - Cover letter describing their specific interest in Numenta. - Resume, including list of relevant course work. - Period of the internship (typically 3 to 4 months fulltime.) - Please email resume and cover letter to interns@numenta.com. Numenta is an equal opportunity employer supporting workforce diversity. APPLY NOW Numenta Careers All Careers Posts Numenta 2016/01/22 Careers Research Internship","title":"Research Internship"},{"path":"/careers-and-team/","text":"Careers &amp; Team Careers & TeamCareers Company culture is important to us, so why not join a startup that feels like a family? We may be busy cracking the code on machine intelligence, but we ve got a work-hard, play-hard attitude. Our kitchen is stocked with salty and sweet snacks, and on Wednesdays we enjoy catered lunches from a variety of local restaurants. At the heart of the peninsula, our downtown Redwood City location is a short walk from the Caltrain station. Outside the office, we blow off steam with company events, happy hours and other fun activities. In the past, we ve cheered on the SF Giants, baked pies at Pie Ranch in Pescadero, and do-si-doed through the night.Current Openings - Research Internship - Internship ProgramManagement Team - Donna DubinskyCEO & Co-FounderDonna first partnered with Jeff Hawkins at Palm, Inc. in 1992, where she served as president and CEO. She held this position throughout Palm's acquisition by U.S Robotics and subsequently 3Com Corporation. In 1998, Donna and Jeff co-founded Handspring, creator of the category-defining Treo smartphone. Handspring merged with Palm in 2003, and Donna continued to serve on Palm's board until 2009. Previously, Donna spent 10 years at Apple Inc. in a multitude of sales, sales support, and logistics functions both at Apple and at Claris, an Apple software subsidiary.Donna earned a B.A. from Yale University, and an M.B.A. from Harvard Business School. She is currently on the board of Yale University. - Jeff HawkinsCo-FounderJeff is an engineer, serial entrepreneur, scientist, inventor and author. His life-long interest in neuroscience and theories of the neocortex has driven his passion for building a technology based on neocortical theory. Previously, he founded two mobile computing companies, Palm and Handspring, and is the architect of many computing products such as the PalmPilot and Treo smartphone. In 2002, he founded the Redwood Neuroscience Institute, a scientific institute focused on understanding how the neocortex processes information. The institute is currently located at U.C. Berkeley. In 2004 Jeff wrote the book, On Intelligence, which outlines Hierarchical Temporal Memory (HTM) and describes progress on understanding the neocortex.Jeff earned his B.S. in Electrical Engineering from Cornell University in 1979. He was elected to the National Academy of Engineering in 2003. - Subutai AhmadVP of ResearchSubutai brings experience across real time systems, computer vision and learning to Numenta. He has previously served as VP Engineering at YesVideo, Inc. where he helped grow the company from a three-person start-up to a leader in automated digital media authoring. In 1997, Subutai co- founded ePlanet Interactive, a spin-off from Interval Research. ePlanet developed the IntelPlay Me2Cam, the first computer vision product developed for consumers. He has served as a key researcher at Interval Research.Subutai holds a B.S. in Computer Science from Cornell University, and a Ph.D in Computer Science from the University of Illinois at Urbana-Champaign. While pursuing his Ph.D, Subutai completed a thesis on computational neuroscience models of visual attention. - Celeste BaranskiVP of EngineeringCeleste has vast experience in high tech engineering, design and management. Previously, Celeste was SVP Engineering & Operations at Panasas, a Big Data storage provider. She was CEO and Co-Founder of Vitamin D, one of the first developers to use the NuPIC platform. Celeste also served in VP Engineering roles at Palm and at Handspring, where she led the companies engineering efforts for handheld computers and smartphones. Celeste has built effective engineering teams, starting from a few to over 500 and has delivered numerous successful and award-winning products.Celeste holds both a B.S. and M.S. in electrical engineering from Stanford University.Board of Directors - Ed ColliganFormer President & CEO, Palm, Inc.Ed has been a part of the core team of five Silicon Valley start-ups. Ed s first big success was Radius, Inc. where he was instrumental in building products and the brand. After Radius, Ed was the first vice president of marketing for Palm where he helped develop the original Palm Pilot, the Palm brand and Palm's product strategy. He moved on from Palm to found Handspring where Ed and his partners created the forbearer of all future smartphones; the Handspring Treo. Ed drove the transaction that reunited Palm and Handspring into a single Palm again. He established relationships with wireless carriers globally and drove Palm's annual smartphone business to more than $2 billion. As the CEO of Palm, Ed spearheaded the transformation that created the WebOS platform and Palm Pre line of smartphones.Ed now spends his time investing in and mentoring entrepreneurs. Ed is a board member of Numenta, Inc., Active Mind Technology, and POPS Worldwide, and is an investor and on the board of advisors of six other start-up companies. Ed holds a B.S. from the University of Oregon. - Donna DubinskyCEO & Co-FounderDonna first partnered with Jeff Hawkins at Palm, Inc. in 1992, where she served as president and CEO. She held this position throughout Palm's acquisition by U.S Robotics and subsequently 3Com Corporation. In 1998, Donna and Jeff co-founded Handspring, creator of the category-defining Treo smartphone. Handspring merged with Palm in 2003, and Donna continued to serve on Palm's board until 2009. Previously, Donna spent 10 years at Apple Inc. in a multitude of sales, sales support, and logistics functions both at Apple and at Claris, an Apple software subsidiary.Donna earned a B.A. from Yale University, and an M.B.A. from Harvard Business School. She is currently on the board of Yale University. - Mike FarmwaldGeneral Partner, Skymoon VenturesMike Farmwald is a successful serial entrepreneur. He has founded many companies with breakthrough technologies including FTL, a super computing company that merged with MIPs, Epigram, which was acquired by Broadcom, Rambus and Matrix Semiconductor, a creator of 3D integrated circuits.Mike currently sits on the board of Rambus (NASDAQ: RMBS). He is participating on the Numenta board as an individual, rather than as a representative of Skymoon Ventures. Mike holds a B.S. degree in Mathematics from Purdue University and a Ph.D. in Computer Science from Stanford University. - Jeff HawkinsCo-FounderJeff is an engineer, serial entrepreneur, scientist, inventor and author. His life-long interest in neuroscience and theories of the neocortex has driven his passion for building a technology based on neocortical theory. Previously, he founded two mobile computing companies, Palm and Handspring, and is the architect of many computing products such as the PalmPilot and Treo smartphone. In 2002, he founded the Redwood Neuroscience Institute, a scientific institute focused on understanding how the neocortex processes information. The institute is currently located at U.C. Berkeley. In 2004 Jeff wrote the book, On Intelligence, which outlines Hierarchical Temporal Memory (HTM) and describes progress on understanding the neocortex.Jeff earned his B.S. in Electrical Engineering from Cornell University in 1979. He was elected to the National Academy of Engineering in 2003. - Harry SaalChairman, Retrotope, Inc.In 2002, Dr. Harry J. Saal was chosen by the US Department of Justice to lead the Technical Committee charged with monitoring and enforcing the Microsoft Antitrust case, and he served as Chairman of the Committee through the May 2011 expiration of the Judgment.Harry founded Nestar Systems, a pioneer in local area network systems, in 1978. In 1986, Harry became the founder and CEO of Network General Corporation, the first company wholly dedicated to the area of network diagnostics. From 1993 through 1995, Harry served as founding CEO and President of Smart Valley, Inc., a non-profit organization chartered to create a regional electronic community based on an advanced information infrastructure and the collective ability to use it.Harry is active in philanthropy and community affairs, and serves on the board of the American Institute of Mathematics, among others. Harry holds a B.A., M.A. and Ph.D. in Physics from Columbia University.Next: Contact ","title":"Careers &amp; Team"},{"path":"/contact/","text":"Contact Contact Want to get in contact with us? Send us a message by filling out this form or use the appropriate email.First NameLast NameJob TitleCompanyEmailPhoneHow can we help? SendProduct Support:support@numenta.comPress Contact:press@numenta.comLicensing Inquiries:sales@numenta.comOfficePhone650-369-8282Fax650-369-8283Address 791 Middlefield Road Redwood City, CA 94063 MapGoogle Maps Link - Reception is on the second floor on the left - Street parking is available on surrounding streets - The Jefferson Avenue Garage is the nearest parking structureFollow Next: Back to Home ","title":"Contact"},{"path":"/events/2014/03/26/amazon-web-services-summit-sf/","text":"AWS Summit San Francisco Wed, Mar 26, 2014 EventsAWS Summit San Francisco Numenta Event WhenWed, Mar 26, 2014WhereMoscone Center Booth 100San Francisco, CA USAWebEvent Website Numenta Event All Events Posts Numenta 2014/03/26 Event AWS Summit San Francisco  ","title":"AWS Summit San Francisco"},{"path":"/events/2014/05/03/nupic-spring-2014-hackathon/","text":"NuPIC Spring 2014 Hackathon Sat, May 03, 2014 EventsNuPIC Spring 2014 Hackathon Matthew Taylor Open Source Manager WhenSat, May 03, 2014 Sun, May 04, 2014WherePinger, Inc.San Jose, CA USAWebEvent Website Matthew Taylor Open Source Manager All Events Posts Matthew Taylor 2014/05/03 Open Source Manager NuPIC Spring 2014 Hackathon  ","title":"NuPIC Spring 2014 Hackathon"},{"path":"/events/2014/05/05/grok-for-it-analytics-at-monitorama/","text":"Monitorama Mon, May 05, 2014 EventsMonitorama Numenta Event WhenMon, May 05, 2014 Wed, May 07, 2014WhereGerding Theater at the ArmoryPortland, OR USAWebEvent Website Numenta Event All Events Posts Numenta 2014/05/05 Event Monitorama  ","title":"Monitorama"},{"path":"/events/2014/07/09/amazon-web-services-summit-ny/","text":"AWS Summit New York Wed, Jul 09, 2014 EventsAWS Summit New York Numenta Event WhenWed, Jul 09, 2014 Thu, Jul 10, 2014WhereJavits CenterNew York, NY USAWebEvent Website Numenta Event All Events Posts Numenta 2014/07/09 Event AWS Summit New York  ","title":"AWS Summit New York"},{"path":"/events/2014/08/20/cognitive-computing-forum/","text":"Cognitive Computing Forum Wed, Aug 20, 2014 EventsCognitive Computing Forum Subutai Ahmad VP Research WhenWed, Aug 20, 2014 3:10 PMWhereSainte Claire HotelSan Jose, CA USAWebEvent WebsiteTopicUnderstanding Cortical Principles and Building Intelligent MachinesSpeakingSubutai AhmadVideo: Subutai Ahmad VP Research All Events Posts Subutai Ahmad 2014/08/20 VP Research Cognitive Computing Forum  ","title":"Cognitive Computing Forum"},{"path":"/events/2014/10/02/brainscales-neuromorphic-computing-conference/","text":"Frontiers in Neuromorphic Computing Conference Thu, Oct 02, 2014 EventsFrontiers in Neuromorphic Computing Conference Jeff Hawkins Co-founder WhenThu, Oct 02, 2014WhereKirchhoff Institute for PhysicsHeidelberg, Baden-W rttemberg GermanyWebEvent WebsiteTopicModeling Cortical LayersSpeakingJeff Hawkins Jeff Hawkins Co-founder All Events Posts Jeff Hawkins 2014/10/02 Co-founder Frontiers in Neuromorphic Computing Conference  ","title":"Frontiers in Neuromorphic Computing Conference"},{"path":"/events/2014/10/15/advanced-aws-meetup/","text":"Advanced AWS Meetup Lightning Talk Wed, Oct 15, 2014 EventsAdvanced AWS Meetup Lightning Talk Scott Purdy Engineering Manager WhenWed, Oct 15, 2014WhereAirBnBSan Francisco, CA USATopicBuilding an Anomaly Service for AWSSpeakingScott Purdy Scott Purdy Engineering Manager All Events Posts Scott Purdy 2014/10/15 Engineering Manager Advanced AWS Meetup Lightning Talk  ","title":"Advanced AWS Meetup Lightning Talk"},{"path":"/events/2014/10/17/numenta-training-workshop/","text":"Numenta Training Workshop Fri, Oct 17, 2014 EventsNumenta Training Workshop Numenta Event WhenFri, Oct 17, 2014WhereNumentaRedwood City, CA USAWebEvent Website Numenta is offering a half-day technical workshop to provide training for developers or potential customers/partners interested in our technology. Workshop sessions will review Numenta theory, technology, and applications and provide an overview for how to get started on your own projects using Numenta technology. The majority of content will be technical in nature and is intended for a developer/technical audience. Training curriculum will be followed by a networking reception. Who should attend? Developers/technically-minded people interested in Numenta technology. A substantial portion of our content will focus on introducing the basics of our technology. Workshop Videos Principles of Hierarchical Temporal Memory (HTM): Foundations of Machine Intelligence Jeff Hawkins, Co-Founder Q & A Session Applications of Hierarchical Temporal Memory (HTM) Chetan Surpur, Software Engineer Getting Started With Numenta Technology Celeste Baranski, VP Engineering Matt Taylor, Open Source Community Flag-Bearer Sparse Distributed Representations: Our Brain s Data Structure Subutai Ahmad, VP Research Numenta Event All Events Posts Numenta 2014/10/17 Event Numenta Training Workshop  ","title":"Numenta Training Workshop"},{"path":"/events/2014/10/18/nupic-fall-2014-hackathon/","text":"NuPIC Fall 2014 Hackathon Sat, Oct 18, 2014 EventsNuPIC Fall 2014 Hackathon Matthew Taylor Open Source Manager WhenSat, Oct 18, 2014 10:00 AM Sun, Oct 19, 2014 6:00 PMWherePinger IncSan Jose, CA USAWebEvent WebsitePlease RSVP! - http://www.meetup.com/numenta/events/202402962/ Matthew Taylor Open Source Manager All Events Posts Matthew Taylor 2014/10/18 Open Source Manager NuPIC Fall 2014 Hackathon  ","title":"NuPIC Fall 2014 Hackathon"},{"path":"/events/2014/10/30/ibm-research-cognitive-systems-colloquium/","text":"IBM Research Cognitive Systems Colloquium Thu, Oct 30, 2014 EventsIBM Research Cognitive Systems Colloquium Jeff Hawkins Co-Founder WhenThu, Oct 30, 2014WhereT.J. Watson Research CenterYorktown Heights, NY USATopicWhat the Brain Can Tell Us About the Future of ComputingSpeakingJeff HawkinsEvent Video Interview Video with Jeff Hawkins Jeff Hawkins Co-Founder All Events Posts Jeff Hawkins 2014/10/30 Co-Founder IBM Research Cognitive Systems Colloquium  ","title":"IBM Research Cognitive Systems Colloquium"},{"path":"/events/2014/11/11/AWS-reInvent/","text":"AWS re:Invent Tue, Nov 11, 2014 EventsAWS re:Invent Numenta Event WhenTue, Nov 11, 2014 Thu, Nov 13, 2014WhereThe Venetian, Booth 648Las Vegas, NV USAWebEvent Website Numenta Event All Events Posts Numenta 2014/11/11 Event AWS re:Invent  ","title":"AWS re:Invent"},{"path":"/events/2014/12/04/sv-forum-ihuman-the-future-of-minds-and-machines/","text":"SV Forum iHuman - The Future of Minds and Machines Thu, Dec 04, 2014 EventsSV Forum iHuman - The Future of Minds and Machines Jeff Hawkins Co-Founder WhenThu, Dec 04, 2014 2:00 PM 7:30 PMWhereHero City at Draper UniversitySan Mateo, CA USAWebEvent WebsiteSpeakingJeff HawkinsVideo Jeff Hawkins Co-Founder All Events Posts Jeff Hawkins 2014/12/04 Co-Founder SV Forum iHuman - The Future of Minds and Machines  ","title":"SV Forum iHuman - The Future of Minds and Machines"},{"path":"/events/2015/02/17/strata-hadoop-world/","text":"Strata + Hadoop World 2015 Tue, Feb 17, 2015 EventsStrata + Hadoop World 2015 Subutai Ahmad VP Research WhenTue, Feb 17, 2015 Fri, Feb 20, 2015WhereSan Jose Convention CenterSan Jose, CA USAWebEvent WebsiteTopicStreaming Analytics - It s Not The Same GameSpeakingSubutai AhmadStreaming Analytics: It s Not The Same Game Talk Abstract We are witnessing an explosion of sensors and machine generated data. Every server, every building, and every device generates a continuous stream of information that is ever changing and potentially valuable. The existing big data paradigm requires storing data for batch analysis, and extensive modeling by a human expert, prior to deployment. This is incredibly inefficient and cannot scale. Instead there is a growing need to rapidly create adaptive models that accept streaming data sources and can take instant action. In this talk I will describe a new paradigm for streaming data algorithms, based on recent neuroscience findings and on the computational properties of the neocortex. These systems are highly automated, adapt to changing statistics, and naturally deal with temporal data streams. They require no batch training and custom models can be deployed on the fly. Many of the core ideas have been implemented in the open source project NuPIC, and validated in commercial applications. Given the massive increase in the number of data sources, a general-purpose automated approach is the only scalable way to effectively analyze and act on continuously streaming information. Slides - Streaming Analytics: It s Not The Same Game from Numenta. Streaming Analytics: It's Not the Same Game from Numenta Subutai Ahmad VP Research All Events Posts Subutai Ahmad 2015/02/17 VP Research Strata + Hadoop World 2015  ","title":"Strata + Hadoop World 2015"},{"path":"/events/2015/02/23/sandia-national-labs-neuro-computational-workshop-2015/","text":"Sandia National Laboratories Neuro-Inspired Computational Elements Workshop 2015 Mon, Feb 23, 2015 EventsSandia National Laboratories Neuro-Inspired Computational Elements Workshop 2015 Jeff Hawkins Co-Founder WhenMon, Feb 23, 2015 Wed, Feb 25, 2015WhereHyatt Regency TamayaSanta Ana Pueblo, NM USAWebEvent WebsiteSpeakingJeff HawkinsSandia National Laboratories Beyond von Neumann/Turing Architecture and Moore s Law Limits Conventional, stored program architecture systems are designed for algorithmic and exact calculations. However, the problems with highest impact involve large, noisy, incomplete, natural data sets that do not lend themselves to convenient solutions by current systems. Our task is to build upon the convergence cresting waves among neuroscience, microelectronics and computational systems to develop a new architecture designed to handle these natural data sets. Neuro-Inspired Computational Elements Workshop 2015 Videos - Reverse Engineering the Neocortex (49:00), Jeff Hawkins, Numenta. - IBM Cortical Learning Center (33:18), Winfried Wilcke, IBM CLC. Jeff Hawkins Co-Founder All Events Posts Jeff Hawkins 2015/02/23 Co-Founder Sandia National Laboratories Neuro-Inspired Computational Elements Workshop 2015  ","title":"Sandia National Laboratories Neuro-Inspired Computational Elements Workshop 2015"},{"path":"/events/2015/03/05/cosyne-computational-systems-neuroscience-2015/","text":"Computational and Systems Neuroscience (Cosyne) 2015 Thu, Mar 05, 2015 EventsComputational and Systems Neuroscience (Cosyne) 2015 Subutai Ahmad VP Research WhenThu, Mar 05, 2015 Sun, Mar 08, 2015WhereHilton Salt Lake City CenterSalt Lake City, UT USAWebEvent WebsiteTopicMaintaining Stable Perception During Active ExplorationAuthorsYuwei Cui, Subutai Ahmad, Chetan Surpur, and Jeff HawkinsAbstract Maintaining Stable Perception During Active Exploration Our sensory input changes dramatically as the result of our own behavior, including eye movements, head turns, and body movements. Despite these rapid sensory changes, our perception of the world is amazingly stable, and we can reliably discriminate between different patterns. This suggests that we learn stable but distinct representations through active exploration. There is reason to believe that efference copy, an internal copy of the motor signal, is critical for such sensorimotor learning. However the exact brain mechanisms underlying these computations remain unknown. In this study, we propose a computational model of sensorimotor learning and prediction. Sparse distributed representations of visual scenes are built up incrementally by pooling together predictable temporal transitions during exploration. To enable accurate predictions during active exploration, we modified the Hierarchical Temporal Memory sequence-learning algorithm to use both sensory inputs and efference copy signals. To enable forming stable representations of scenes, we implemented a novel temporal pooling learning rule that allows downstream neurons to form connections with upstream neurons that are predicting correctly. The overall model is unsupervised and the architecture is consistent with several important aspects of thalamocortical circuits. We tested the algorithm on a set of simulated environments, as well as a robotics test bed. In both cases the model achieves two desired properties: 1) prediction of future sensory inputs during behavior, and 2) emergence of stable and distinct representations for learned patterns. After learning, the sparse activity of cells in downstream regions is stable despite sensor movements, while different images lead to distinct representations. These results demonstrate how efference copy can be used in sensory cortex to make predictions during behavior. We propose temporal pooling as a novel computational principle for forming invariant representations during unsupervised learning and active exploration. Subutai Ahmad VP Research All Events Posts Subutai Ahmad 2015/03/05 VP Research Computational and Systems Neuroscience (Cosyne) 2015  ","title":"Computational and Systems Neuroscience (Cosyne) 2015"},{"path":"/events/2015/03/17/what-the-brain-says-about-machine-intelligence-nyc-meetup/","text":"What the Brain Says About Machine Intelligence NYC Meetup Tue, Mar 17, 2015 EventsWhat the Brain Says About Machine Intelligence NYC Meetup Jeff Hawkins Co-Founder WhenTue, Mar 17, 2015 7:00 PM 9:00 PMWhereCornell TechNew York, NY USAWebEvent WebsiteTopicWhat the Brain Says About Machine IntelligenceSpeakingJeff HawkinsSummary Come hear Jeff Hawkins speak about the machine intelligence work being done at Numenta in NYC. This Meetup is an hour-long presentation by Jeff at 7PM, followed by another hour of networking and socialization. Anyone is welcome to attend, but you must RSVP. Anyone showing up at the door without an RSVP will be turned away. Abstract The neocortex is the only example we have of a cognitive system. I will argue that understanding the principles of how the neocortex works and then building machines that work on those principles is the only way to build intelligent machines. I will describe the progress we are making in understanding how the neocortex works and demonstrate how we are turning that knowledge into useful technology and products. Biography Jeff Hawkins is an engineer, serial entrepreneur, scientist, inventor, and author. He was a founder of two mobile computing companies, Palm and Handspring, and was the architect of many computing products such as the PalmPilot and Treo smartphone. Throughout his life Jeff has also had a deep interest in neuroscience and theories of the neocortex. In 2002 he founded the Redwood Neuroscience Institute, a scientific institute focused on understanding how the neocortex processes information. The institute is now located at U.C. Berkeley. In 2004 he wrote the book On Intelligence, which describes progress on understanding the neocortex. In 2005 he co-founded Numenta, a startup company building a technology based on neocortical theory. It is his hope that Numenta will play a catalytic role in the emerging field of machine intelligence. Jeff Hawkins earned his B.S. in electrical engineering from Cornell University in 1979. He was elected to the National Academy of Engineering in 2003. About Numenta Numenta, Inc. was formed in 2005 to develop biologically-inspired machine intelligence technology for both commercial and scientific use. What is NuPIC? NuPIC, the Numenta Platform for Intelligent Computing, comprises a set of open source learning algorithms that were first described in a white paper published by Numenta in 2009. The learning algorithms faithfully capture how layers of neurons in the neocortex learn. The white paper has been translated into seven languages by volunteers and has generated considerable interest among developers and research scientists. Jeff Hawkins Co-Founder All Events Posts Jeff Hawkins 2015/03/17 Co-Founder What the Brain Says About Machine Intelligence NYC Meetup  ","title":"What the Brain Says About Machine Intelligence NYC Meetup"},{"path":"/events/2015/05/30/nupic-spring-2015-hackathon/","text":"NuPIC Spring 2015 Hackathon NYC Sat, May 30, 2015 EventsNuPIC Spring 2015 Hackathon NYC Matthew Taylor Open Source Manager WhenSat, May 30, 2015 10:00 AM Sun, May 31, 2015 8:00 PMWhereCornell TechNew York City, NY USAWebEvent WebsitePlease RSVP on our Meetup.com page - http://www.meetup.com/numenta/events/220422020/ More Info - NuPIC Event Page: http://numenta.org/events/hackathon/2015/may/ Matthew Taylor Open Source Manager All Events Posts Matthew Taylor 2015/05/30 Open Source Manager NuPIC Spring 2015 Hackathon NYC  ","title":"NuPIC Spring 2015 Hackathon NYC"},{"path":"/events/2015/06/01/orange-institute-14-silicon-valley-redefining-business-again/","text":"Orange Institute 14 How Silicon Valley is Redefining Business Again Mon, Jun 01, 2015 EventsOrange Institute 14 How Silicon Valley is Redefining Business Again Donna Dubinsky CEO, Co-Founder WhenMon, Jun 01, 2015 Thu, Jun 04, 2015WhereSilicon Valley, CA USAWebEvent WebsiteSpeakingDonna Dubinsky Disruption is the new norm. Many of us have watched the Digital Economy remake the IT and tech world, from mainframes to mobile phones. At Orange Institute, we are convinced that this time it s fundamentally different: Digital is transforming everything, not just the Tech world. Entertainment is always the first to feel Technology s shock. It continues to be the test-bed today. But for the first time - as never before - all industries are impacted. Orange Institute s Silicon Valley session explores how technology is restructuring industries and the companies within, and helping them adapt to changing customer behaviors. From the drive toward network virtualization, virtual reality, mobile payments, and Cloud technology, to new device and consumtion patterns, the scale of these incursions is explosive. Topics included in this session (preliminary): - Corporate interaction with Startups - Machine learning / Deep Learning - Self-driving Cars, Robots, and Smart Homes - The Full Stack: Silicon Valley s secret formula for Disruption - Studio System to Ecosystem: Hollywood confronts the YouTube Effect - Regulating Disruption: How Silicon Valley challenges the rules - Neuroscience meets Computer Science - The Virtual Reality Rollout Donna Dubinsky CEO, Co-Founder All Events Posts Donna Dubinsky 2015/06/01 CEO, Co-Founder Orange Institute 14 How Silicon Valley is Redefining Business Again  ","title":"Orange Institute 14 How Silicon Valley is Redefining Business Again"},{"path":"/events/2015/08/18/dataversity-smart-data-conference-san-jose-2015/","text":"Dataversity Smart Data Conference San Jose 2015 Tue, Aug 18, 2015 EventsDataversity Smart Data Conference San Jose 2015 Subutai Ahmad VP Research WhenTue, Aug 18, 2015 Thu, Aug 20, 2015WhereSan Jose Convention CenterSan Jose, CA USAWebEvent WebsiteTopicHow Cognitive Computing Will Drive the Future of AnalyticsSpeakingSubutai Ahmad A conference about Cognitive Computing, Internet of Things, and other current hot topics in Silicon Valley. Register with our discount code: NUMENTA. Opening Keynote Come see Subutai Ahmad, VP of Research for Numenta, speak on how cognitive computing will drive the future of analytics. - Wednesday, August 19, 2015 - 09:00 AM - 09:30 AM - Level: Business/Strategic Topic We are witnessing an explosion of sensors and machine generated data. Every server, every building, and every device generates a continuous stream of information that is ever changing and potentially valuable. The existing big data paradigm requires storing data for batch analysis, and extensive modeling by a human expert, prior to deployment. This is incredibly inefficient and cannot scale. Instead there is a growing need to rapidly create adaptive models that accept streaming data sources and can take instant action. In this talk I will describe a new paradigm for streaming data algorithms, based on recent neuroscience findings and on the computational properties of the neocortex. These systems are highly automated, adapt to changing statistics, and naturally deal with temporal data streams. They require no batch training and custom models can be deployed on the fly. Many of the core ideas have been implemented in the open source project NuPIC, and validated in commercial applications. Given the massive increase in the number of data sources, a general-purpose automated approach is the only scalable way to effectively analyze and act on continuously streaming information. About the Speaker Subutai Ahmad is the VP of Research at Numenta, a company focused on Machine Intelligence. Our technology, Hierarchical Temporal Memory (HTM), is a detailed computational framework based on principles of the brain. Our HTM learning algorithms are available through the NuPIC open source community and are embedded in our commercial streaming analytics applications. Subutai s experience includes computational neuroscience, machine learning, computer vision and building real time commercial systems. He has previously served as VP Engineering at YesVideo where he helped grow the company from a three-person start-up to a leader in automated digital media authoring. In 1997, Subutai co-founded ePlanet Interactive, a spin-off from Interval Research. ePlanet developed the IntelPlay Me2Cam, the first computer vision product developed for consumers. Subutai holds a B.S. in Computer Science from Cornell, and a Ph.D in Computer Science from the University of Illinois at Urbana-Champaign. Meet Numenta The Numenta team would love to meet you, answer any questions about our HTM technology, discuss cognitive computing, and show you around our intelligent applications. Open Hours: - Tue Aug 18: 4:00pm - 6:30pm - Wed Aug 19: 2:15pm - 8:00pm Application Demos - Grok - HTM for Stocks - Rogue Behavior detection: Whitepaper (PDF), Source Code - GPS tracking: Whitepaper (PDF), Source Code - NuPIC Subutai Ahmad VP Research All Events Posts Subutai Ahmad 2015/08/18 VP Research Dataversity Smart Data Conference San Jose 2015  ","title":"Dataversity Smart Data Conference San Jose 2015"},{"path":"/events/2015/10/01/berkeley-symposium-on-energy-efficient-electronic-systems/","text":"Fourth Berkeley Symposium on Energy Efficient Electronic Systems Thu, Oct 01, 2015 EventsFourth Berkeley Symposium on Energy Efficient Electronic Systems Jeff Hawkins Co-Founder WhenThu, Oct 01, 2015 Fri, Oct 02, 2015WhereSutardja Dai Hall @ UC BerkeleyBerkeley, CA USAWebEvent WebsiteSpeakingJeff Hawkins The technical program consists of invited and contributed papers. Complementing the oral presentation sessions is a poster session. The 2015 Organizing Committee is soliciting contributed papers on advances in the following areas that will contribute to radical reduction in power consumption: - Ultra Low Voltage Nanoelectronics - Milli-Volt Nanomechanical Logic - Ultra-Low Energy Spintronics Optical Chip Scale Interconnects - Low Voltage CMOS Circuits and Architectures - Energy Efficient Computing Systems The Symposium The Berkeley Symposium on Energy Efficient Electronic Systems brings together researchers from around the world who are working on breakthrough improvements in energy efficiency for information processing systems. The goal is to foster closer cooperation and collaborations among the researchers working in this domain of technology. Established in 2009, it is a forum for speakers, from academia, industry, and government laboratories, to share their perspectives, and discuss issues and approaches, enabling the attendees to better understand this area from both above and below them on the food chain. We have a grand scope in mind, extending from new low-power nanoelectronic devices, through circuit design, chip-scale architecture, short-range interconnects, long-range interconnect, networks, software, storage systems, servers, data centers and supercomputers. IEEE Electron Device Society became a technical co-sponsor in 2013. Jeff Hawkins Co-Founder All Events Posts Jeff Hawkins 2015/10/01 Co-Founder Fourth Berkeley Symposium on Energy Efficient Electronic Systems  ","title":"Fourth Berkeley Symposium on Energy Efficient Electronic Systems"},{"path":"/events/2015/10/07/gsv-labs-pioneer-summit/","text":"GSVlabs Pioneer Summit 2015 Wed, Oct 07, 2015 EventsGSVlabs Pioneer Summit 2015 Jeff Hawkins Co-Founder WhenWed, Oct 07, 2015 Fri, Oct 09, 2015WhereGSVlabsRedwood City, CA USAWebEvent WebsiteSpeakingJeff Hawkins We are convening the leading venture and growth companies from around the world, highly curated by the GSV TEAM, to gather in Silicon Valley. We don t want incremental ideas. Our main mission is to help accelerate entrepreneurs efforts to make a significant impact on industries and societies. In the spirit of Davos and TED, we want to explore the ideas that will transform and improve the world, yet focus on tangible companies that entrepreneurs are building through blood, sweat and tears. Our goal is not to be the biggest summit, but to be the most impactful. We bring together the key people driving growth in the Global Silicon Valley. The Pioneers at our Summit believe that we can build companies that are transformative, global and inclusive. Jeff Hawkins Co-Founder All Events Posts Jeff Hawkins 2015/10/07 Co-Founder GSVlabs Pioneer Summit 2015  ","title":"GSVlabs Pioneer Summit 2015"},{"path":"/events/2015/10/22/compute-midwest-imagine-the-future-2015/","text":"Compute Midwest 2015 - Imagine the Future Thu, Oct 22, 2015 EventsCompute Midwest 2015 - Imagine the Future Jeff Hawkins Co-Founder WhenThu, Oct 22, 2015 Fri, Oct 23, 2015WhereMunicipal ArenaKansas City, MO USAWebEvent WebsiteTopicThe Future of Machine IntelligenceSpeakingJeff HawkinsImagine The Future Get inspired: learn about what s next in technology - straight from tech leaders, startup founders & visionaries. Hear the stories of innovators who are building companies that change our life, our work & our business. Connect with 500+ forward thinking tech minds, exchange/build new ideas & gather takeaways that can move your career/company forward! Jeff Hawkins Co-Founder All Events Posts Jeff Hawkins 2015/10/22 Co-Founder Compute Midwest 2015 - Imagine the Future  ","title":"Compute Midwest 2015 - Imagine the Future"},{"path":"/events/2015/11/01/hhmi-janelia-emerging-tools-for-whole-brain-functional-data/","text":"HHMI Janelia Emerging Tools for Acquisition and Interpretation of Whole-Brain Functional Data Sun, Nov 01, 2015 EventsHHMI Janelia Emerging Tools for Acquisition and Interpretation of Whole-Brain Functional Data Subutai Ahmad VP Research WhenSun, Nov 01, 2015 Wed, Nov 04, 2015WhereHHMI Janelia Research CampusAshburn, VA USAWebEvent WebsiteInvited ParticipantSubutai Ahmad In the last few years, optical techniques have emerged that allow near-simultaneous acquisition of neuronal activity at the whole-brain level and with single-cell resolution for small model organisms. Given the enormous density of interconnectivity of neurons in the brain, these techniques bear great potential for advancing our understanding of how the information underlying behavior is represented and processed by neuronal networks in a dynamic fashion and at the whole-brain level. At the same time, these new tools have transitioned neuroscience into the field of Big Data , where terabytes of data are produced per microscope and day. It is expected that major breakthroughs in coming years will result from making sense of these data sets. This calls for the application of advanced machine learning, statistics tools and mathematical modeling as well as an IT infrastructure capable of handling such data sets efficiently. This meeting will bring together experts and pioneers in these fields to identify synergies and new opportunities and to discuss the main challenges moving forward. Subutai Ahmad VP Research All Events Posts Subutai Ahmad 2015/11/01 VP Research HHMI Janelia Emerging Tools for Acquisition and Interpretation of Whole-Brain Functional Data  ","title":"HHMI Janelia Emerging Tools for Acquisition and Interpretation of Whole-Brain Functional Data"},{"path":"/events/2015/11/13/ml-conf-machine-learning-conference-san-francisco/","text":"MLConf Machine Learning Conference San Francisco 2015 Fri, Nov 13, 2015 EventsMLConf Machine Learning Conference San Francisco 2015 Subutai Ahmad VP Research WhenFri, Nov 13, 2015WhereJulia Morgan BallroomSan Francisco, CA USAWebEvent WebsiteTopicReal-time Anomaly Detection for Real-time Data NeedsSpeakingSubutai AhmadTHE MACHINE LEARNING CONFERENCE MLconf gathers communities to discuss the recent research and application of Algorithms, Tools, and Platforms to solve the hard problems that exist within organizing and analyzing massive and noisy data sets. Subutai Ahmad VP Research All Events Posts Subutai Ahmad 2015/11/13 VP Research MLConf Machine Learning Conference San Francisco 2015  ","title":"MLConf Machine Learning Conference San Francisco 2015"},{"path":"/events/2015/11/13/numenta-htm-challenge-community-meetup/","text":"Numenta HTM Challenge Community Meetup Fri, Nov 13, 2015 EventsNumenta HTM Challenge Community Meetup Matthew Taylor Open Source Flag-Bearer WhenFri, Nov 13, 2015 3:00 PM 9:00 PMWhereNumentaRedwood City, CA USAWebEvent WebsiteTopicNumenta HTM Challenge Community MeetupNumenta HTM Challenge Community Meetup This is an event organized by the NuPIC community to accompany the Numenta HTM Challenge Onsite. If you are coming to the Challenge and want to meet members of the NuPIC community the night before, please RSVP. Matthew Taylor Open Source Flag-Bearer All Events Posts Matthew Taylor 2015/11/13 Open Source Flag-Bearer Numenta HTM Challenge Community Meetup  ","title":"Numenta HTM Challenge Community Meetup"},{"path":"/events/2015/11/14/numenta-htm-challenge-onsite/","text":"Numenta HTM Challenge Onsite Sat, Nov 14, 2015 EventsNumenta HTM Challenge Onsite Matthew Taylor Open Source Flag-Bearer WhenSat, Nov 14, 2015 10:00 AM 8:00 PMWhereSan Mateo County History MuseumRedwood City, CA USAWebEvent WebsiteTopicNumenta HTM Challenge OnsiteNumenta HTM Challenge Onsite The Numenta HTM Challenge is an online coding contest encouraging the creation of Hierarchical Temporal Memory applications. Matthew Taylor Open Source Flag-Bearer All Events Posts Matthew Taylor 2015/11/14 Open Source Flag-Bearer Numenta HTM Challenge Onsite  ","title":"Numenta HTM Challenge Onsite"},{"path":"/events/2015/12/09/14th-ieee-international-conference-on-machine-learning-icmla/","text":"14th IEEE International Conference on Machine Learning and Applications (ICMLA) Wed, Dec 09, 2015 Events14th IEEE International Conference on Machine Learning and Applications (ICMLA) Alexander Lavin Engineer WhenWed, Dec 09, 2015 Fri, Dec 11, 2015WhereMiami, FL USAWebEvent WebsiteTopicEvaluating Realtime Anomaly Detection Algorithms the Numenta Anomaly BenchmarkSpeakingAlexander LavinIEEE ICMLA 15 14th International Conference on Machine Learning and Applications The 14th International Conference on Machine Learning and Applications (IEEE ICMLA 15) will be held in Miami, Florida, USA, December, 2015. The aim of the conference is to bring researchers working in the areas of machine learning and applications together. The conference will cover both theoretical and experimental research results. Submission of machine learning papers describing machine learning applications in fields like medicine, biology, industry, manufacturing, security, education, virtual environments, game playing and problem solving is strongly encouraged. Conference content will be submitted for inclusion into IEEE Xplore as well as other Abstracting and Indexing (A&I) databases. Alexander Lavin Engineer All Events Posts Alexander Lavin 2015/12/09 Engineer 14th IEEE International Conference on Machine Learning and Applications (ICMLA)  ","title":"14th IEEE International Conference on Machine Learning and Applications (ICMLA)"},{"path":"/events/2016/02/25/cosyne-computational-and-systems-neuroscience-meeting-2016/","text":"COSYNE 2016 Computational and Systems Neuroscience Meeting Thu, Feb 25, 2016 EventsCOSYNE 2016 Computational and Systems Neuroscience Meeting Numenta Research Team WhenThu, Feb 25, 2016 Sun, Feb 28, 2016WhereMarriott DowntownSalt Lake City, UT USAWebEvent WebsiteTopicA Theory of Sequence Memory in the NeocortexPoster PresentationJeff Hawkins, Subutai Ahmad, Yuwei Cui, and Scott PurdyAbstract A Theory of Sequence Memory in the Neocortex Neocortical neurons have thousands of excitatory synapses. It is a mystery how neurons integrate the input from so many synapses and what kind of large-scale network behavior this enables. It has been previously proposed that non-linear properties of dendrites enable neurons to recognize multiple patterns. In this paper we extend this idea by showing that a neuron with several thousand synapses arranged along active dendrites can learn to accurately and robustly recognize hundreds of unique patterns of cellular activity, even in the presence of large amounts of noise and pattern variation. We then propose a neuron model where some of the patterns recognized by a neuron lead to action potentials and define the classic receptive field of the neuron, whereas the majority of the patterns recognized by a neuron act as predictions by slightly depolarizing the neuron without immediately generating an action potential. We then present a network model based on neurons with these properties and show that the network learns a robust model of time-based sequences. Given the similarity of excitatory neurons throughout the neocortex and the importance of sequence memory in inference and behavior, we propose that this form of sequence memory is a universal property of neocortical tissue. We further propose that cellular layers in the neocortex implement variations of the same sequence memory algorithm to achieve different aspects of inference and behavior. The neuron and network models we introduce are robust over a wide range of parameters as long as the network uses a sparse distributed code of cellular activations. The sequence capacity of the network scales linearly with the number of synapses on each neuron. Thus neurons need thousands of synapses to learn the many temporal patterns in sensory stimuli and motor sequences. Related links: - More Resources - PDF Whitepaper About Cosyne The annual Cosyne meeting provides an inclusive forum for the exchange of experimental and theoretical/computational approaches to problems in systems neuroscience. To encourage interdisciplinary interactions, the main meeting is arranged in a single track. A set of invited talks are selected by the Executive Committee and Organizing Committee, and additional talks and posters are selected by the Program Committee, based on submitted abstracts. Cosyne topics include (but are not limited to): neural coding, natural scene statistics, dendritic computation, neural basis of persistent activity, nonlinear receptive field mapping, representations of time and sequence, reward systems, decision-making, synaptic plasticity, map formation and plasticity, population coding, attention, and computation with spiking networks. Participants include pure experimentalists, pure theorists, and everything in between. Numenta Research Team All Events Posts Numenta 2016/02/25 Research Team COSYNE 2016 Computational and Systems Neuroscience Meeting  ","title":"COSYNE 2016 Computational and Systems Neuroscience Meeting"},{"path":"/events/2016/03/07/global-big-data-conference-2016/","text":"Global Big Data Conference 2016 Mon, Mar 07, 2016 EventsGlobal Big Data Conference 2016 Alexander Lavin Research Engineer WhenMon, Mar 07, 2016 Wed, Mar 09, 2016WhereSanta Clara Convention CenterSanta Clara, CA USAWebEvent WebsiteTopicGlobal Big Data Conference 2016SpeakingAlexander Lavin Global Big Data Conference s vendor agnostic Global Data Science Conference is held on March 7th, March 8th & March 9th, 2016 on all industry verticals. The Conference allows practitioners to discuss data science through effective use of various data management techniques. Large amount of data created by various mobile platforms, social media interactions, e-commerce transactions, and IoT provide an opportunity for businesses to effectively tailor their services by effective use of data analytics. Proper use of data science can be a major competitive advantage for any business considering vast amount of data being generated. Data Science is an emerging field that allows businesses to effectively mine historical data and better understand consumer behavior. This type of scientific data management approach is critical for any business to successfully launch its products and better serve its existing markets. Alexander Lavin Research Engineer All Events Posts Alexander Lavin 2016/03/07 Research Engineer Global Big Data Conference 2016  ","title":"Global Big Data Conference 2016"},{"path":"/events/2016/03/07/neuro-inspired-elements-workshop-nice-2016/","text":"Neuro-Inspired Computational Elements (NICE) Workshop 2016 Mon, Mar 07, 2016 EventsNeuro-Inspired Computational Elements (NICE) Workshop 2016 Jeff Hawkins Co-Founder WhenMon, Mar 07, 2016 Wed, Mar 09, 2016WhereClark Kerr Campus, UC BerkeleyBerkeley, CA USAWebEvent WebsiteSpeakingJeff HawkinsWorkshop focus Conventional, stored program architecture systems are designed for algorithmic and exact calculations. However, the problems with highest impact involve large, noisy, incomplete, natural data sets that do not lend themselves to convenient solutions by current systems. Our task is to build upon the convergence among neuroscience, microelectronics and computational systems to develop a new architecture designed to handle these natural data sets. The applications and clarification of the value proposition for new neuro-inspired, neuromorphic systems are critical focal points of this workshop. Themes Neuroscience: Sensory information processing in cells and circuits, mechanisms of plasticity, learning and development. Theory: Theoretical principles of brain information processing, sparse coding, stochastic computing, the role of spikes, Bayesian computing. Algorithms: Computational synthesis of brain information processing, deep learning. Platforms/Hardware: Massively parallel neuromorphic hardware architectures, application of commodity systems, novel digital, analog and mixed-signal architectures, application of novel devices. Applications: Robotics, spatio-temporal pattern detection, causal relations in big data, prediction, approximate computing. Jeff Hawkins Co-Founder All Events Posts Jeff Hawkins 2016/03/07 Co-Founder Neuro-Inspired Computational Elements (NICE) Workshop 2016  ","title":"Neuro-Inspired Computational Elements (NICE) Workshop 2016"},{"path":"/events/2016/03/14/numenta-htm-bay-area-meetup-santa-clara/","text":"HTM Bay Area Meetup in Santa Clara Mon, Mar 14, 2016 EventsHTM Bay Area Meetup in Santa Clara Numenta Matt Taylor & Christy Maver WhenMon, Mar 14, 2016 6:30 PM 9:30 PMWhereTrustly @ 4500 Great America PkwySanta Clara, CA USAWebEvent WebsiteTopicHTM Bay Area MeetupSpeakingMatthew Taylor & Christy Maver Please join Numenta speakers Matt Taylor (Open-Source Community Manager) and Christy Maver (Director of Marketing) for this HTM Bay Area Community Meetup. Event located at the Trustly offices in Santa Clara, CA. Meet HTM hackers, AI researchers, Entrepreneurs and enthusiast working in the field of Artificial Intelligence. A brief agenda is listed below. Like before we have a special focus on HTM projects and talks. Make sure you are signing up for a lightning talk if you plan to present. Slots are limited, make sure you sign up fast. Numenta Matt Taylor & Christy Maver All Events Posts Numenta 2016/03/14 Matt Taylor & Christy Maver HTM Bay Area Meetup in Santa Clara  ","title":"HTM Bay Area Meetup in Santa Clara"},{"path":"/events/2016/03/17/numenta-htm-workshop-berkeley-institute-for-data-science/","text":"Numenta HTM Workshop at Berkeley Institute for Data Science Thu, Mar 17, 2016 EventsNumenta HTM Workshop at Berkeley Institute for Data Science Numenta Event WhenThu, Mar 17, 2016 6:00 PM 8:00 PMWhere190 Doe Memorial Library, UC BerkeleyBerkeley, CA USAWebEvent WebsiteTopicIntroductory Workshop - Numenta's Hierarchical Temporal Memory (HTM)SpeakingNumenta EngineeringDescription This event will introduce the Numenta platform and give students the opportunity to learn about cutting-edge research. Members of the Numenta engineering team will host a workshop on using their platform and its impact. Numenta Event All Events Posts Numenta 2016/03/17 Event Numenta HTM Workshop at Berkeley Institute for Data Science  ","title":"Numenta HTM Workshop at Berkeley Institute for Data Science"},{"path":"/events/2016/03/29/strata-hadoop-world-big-data-conference-2016/","text":"Strata + Hadoop World 2016: O’Reilly Big Data Conference Tue, Mar 29, 2016 EventsStrata + Hadoop World 2016: O Reilly Big Data Conference Numenta Event WhenTue, Mar 29, 2016 Thu, Mar 31, 2016WhereSan Jose Convention Center, Booth #540San Jose, CA USAWebEvent Website Sponsored by Numenta. See us at Booth #540. Event Details Big data means big business. Learn to survive and thrive in a data-driven world. Make big data work. We ve assembled the world s best data scientists, analysts, and executives from innovative companies of all sizes to share deep, hard-won knowledge. Compelling data case studies, proven best practices, effective new analytic approaches, and core skills will give you insight around: - Data-driven business - Data innovations - Data science & advanced analytics - Enterprise adoption - Hadoop use cases - Hadoop internals & development - IoT & real-time - Law, ethics, governance - Security - Spark & beyond - Visualization & user experience Numenta Event All Events Posts Numenta 2016/03/29 Event Strata + Hadoop World 2016: O’Reilly Big Data Conference  ","title":"Strata + Hadoop World 2016: O’Reilly Big Data Conference"},{"path":"/events/2016/04/07/ai-meetup-hierarchical-temporal-memory-san-francisco/","text":"AI Meetup - Hierarchical Temporal Memory Thu, Apr 07, 2016 EventsAI Meetup - Hierarchical Temporal Memory Yuwei Cui Research Engineer WhenThu, Apr 07, 2016 6:30 PM 7:30 PMWhere404 Bryant StreetSan Francisco, CA USAWebEvent WebsiteSpeakingYuwei CuiEvent Details Hosted by San Francisco Artificial Intelligence Meetup. On April 7th, we are proudly having Yuwei Cui, Ph.D., and Research Engineer at Numenta who will present us the heart of company s technology - Hierarchical Temporal Memory. HTM is a detailed computational theory of the neocortex. At the core of HTM are time-based learning algorithms that store and recall spatial and temporal patterns. HTM is well suited to a wide variety of problems; particularly those involve streaming data and time-based patterns. The current HTM systems are able to learn the structure of streaming data, make predictions and detect anomalies. It is distinguished from other techniques in its ability to learn continuously in a fully unsupervised manner. HTM has been tested and implemented in software, all of which is developed with best practices and is suitable for deploying in commercial applications. The core learning algorithms are fully documented and available in an open source project called NuPIC. Yuwei Cui Research Engineer All Events Posts Yuwei Cui 2016/04/07 Research Engineer AI Meetup - Hierarchical Temporal Memory  ","title":"AI Meetup - Hierarchical Temporal Memory"},{"path":"/events/2016/04/09/connected-car-hackathon-oakland-ca/","text":"Connected Car Hackathon Sat, Apr 09, 2016 EventsConnected Car Hackathon Matthew Taylor Open Source Manager WhenSat, Apr 09, 2016 Sun, Apr 10, 2016WhereJoseph P. Bort MetroCenter AuditoriumOakland, CA USAWebEvent WebsiteTopicUsing HTM with GPS DataSpeakingMatthew TaylorEvent Details Numenta is a Gold Sponsor of this hackathon that seeks to bring together programmers, developers, artists, technologists, data analysts, environmental stewards, travel behavior experts, commuters, and others who are interested in using technology to address our region s transportation challenges in order to transform how we get around the Bay Area. Participants will have the opportunity to use data sets coming from connected cars to build apps and tools that encourage smarter driving, safer driving, and maybe even encourage travelers to consider alternate travel options. Matt Taylor will give a breakout presentation and be on hand to help hackers use HTM with their GPS data. Matthew Taylor Open Source Manager All Events Posts Matthew Taylor 2016/04/09 Open Source Manager Connected Car Hackathon  ","title":"Connected Car Hackathon"},{"path":"/events/2016/04/23/ted-x-cornell-tech/","text":"TEDx Cornell Tech Sat, Apr 23, 2016 EventsTEDx Cornell Tech Alexander Lavin Research Engineer WhenSat, Apr 23, 2016 10:00 AM 4:00 PMWhereInfor, 641 Avenue of the AmericasNew York City, NY USAWebEvent WebsiteTopicTEDx Cornell TechSpeakingAlexander LavinEvent Details TEDx events are TED-like conferences organized and conducted by local communities, where speakers present on ideas that challenge audiences to change the way they think. Our event is organized around our NYC-based Cornell Tech community. Cornell Tech is a revolutionary new technology focused campus of Cornell University, located in New York City. Alexander Lavin Research Engineer All Events Posts Alexander Lavin 2016/04/23 Research Engineer TEDx Cornell Tech  ","title":"TEDx Cornell Tech"},{"path":"/events/2016/04/26/numenta-webinar/","text":"Webinar: Machine Intelligence with Streaming Data Tue, Apr 26, 2016 EventsWebinar: Machine Intelligence with Streaming Data Numenta Christy Maver & Scott Purdy WhenTue, Apr 26, 2016 9:00 AM 10:00 AMWhereOnlineWebEvent WebsiteTopicMachine Intelligence with Streaming Data. A new approach for anomaly detection and time-based learning.WebinarChristy Maver & Scott Purdy Machine Intelligence with Streaming Data. A new approach for anomaly detection and time-based learning. About the Webinar Across every industry, we are seeing an exponential increase in the availability of streaming, time-series data. The real-time detection of anomalies has significant practical application. Finding anomalies in such data can be very difficult, given the need to process data in real time, and learn while simultaneously making predictions. With the increasing variety of streaming data sources, automated deployment without manual parameter tuning is also becoming important. Numenta s online sequence memory algorithm, called Hierarchical Temporal Memory (HTM), has been used to detect anomalies in IT monitoring, human behavior, the stock market, geospatial data, and more. This webinar will introduce this novel technique, demonstrate its broad applicability, and cover performance details from a published benchmark designed for real-time anomaly detection. Numenta Christy Maver & Scott Purdy All Events Posts Numenta 2016/04/26 Christy Maver & Scott Purdy Webinar: Machine Intelligence with Streaming Data  ","title":"Webinar: Machine Intelligence with Streaming Data"},{"path":"/events/2016/05/12/neuro-tech-x-meetup-featuring-jeff-hawkins/","text":"NeuroTechX meetup featuring Jeff Hawkins Thu, May 12, 2016 EventsNeuroTechX meetup featuring Jeff Hawkins Jeff Hawkins Co-Founder WhenThu, May 12, 2016 6:30 PM 8:00 PMWhereIndiegogoSan Francisco, CA USAWebEvent WebsiteTopicWhat is Intelligence, that a Machine Might Have Some?SpeakingJeff HawkinsEvent Details On May 12, NeuroTechX and Indiegogo are proud to host Jeff Hawkins, co-founder of Numenta, who will give a talk titled, What is Intelligence, that a Machine Might Have Some? There s no question that Artificial Intelligence (AI) is hotter than ever. Yet as interest continues to grow, so do the number of interpretations of AI itself. Numenta s approach lays the groundwork for the new era of Machine Intelligence. Led by Hawkins, the company s mission is to reverse engineer the neocortex to build intelligent machines. This approach, which is not just biologically inspired, but biologically constrained, is based on the understanding that the brain is the only example we have of an intelligent system. What is Intelligence, that a Machine Might Have Some? While there s more work to be done, Numenta has made great progress toward a computational theory of the neocortex called HTM. At the core of HTM are time-based learning algorithms that store and recall spatial and temporal patterns. It is distinguished from other techniques in its ability to learn continuously in a fully unsupervised manner. In this talk, Jeff will raise important questions about the implications of this work: what is the legacy that we should be aiming for? What is intelligence itself? What should we do to try to build intelligent machines? What might these machines look like in the future and what will they do? He ll cover the biological components of intelligence, the functional components of intelligence and the diversity of intelligence machines. Don t miss the chance to hear Jeff speak on this fascinating topic. Jeff Hawkins Co-Founder All Events Posts Jeff Hawkins 2016/05/12 Co-Founder NeuroTechX meetup featuring Jeff Hawkins  ","title":"NeuroTechX meetup featuring Jeff Hawkins"},{"path":"/events/2016/05/19/ai-by-the-bay/","text":"AI by the Bay Thu, May 19, 2016 EventsAI by the Bay Subutai Ahmad VP Research WhenThu, May 19, 2016 2:10 PM 2:50 PMWhereGalvanize SOMASan Francisco, CA USAWebEvent WebsiteTopicDetecting Anomalies in Streaming Data - Real-time Algorithms for Real-world applicationsSpeakingSubutai Ahmad Detecting Anomalies in Streaming Data - Real-time Algorithms for Real-world applications Abstract There s no question that we are seeing an increase in the availability of streaming, time-series data. Largely driven by the rise of the Internet of Things (IoT) and connected real-time data sources, we now have an enormous number of applications with sensors that produce important data that changes over time. This data presents a challenge and opportunity for businesses across every industry. How do they handle the onslaught of streaming data? How can they exploit it to make decisions in real-time? One way is to detect, in real time, when something unusual occurs. Early anomaly detection in streaming data has significant implications, yet can be very difficult to execute. It requires detectors to process data in real-time, not batches, and learn while simultaneously making predictions. In this talk, we ll look at algorithms designed for such data and analyze the components that lead to optimal performance. We ll also discuss a new benchmark with a labeled, real-world data set, designed to provide a controlled and repeatable environment of open-source tools to test and measure anomaly detection algorithms on streaming data. How do we score in a way that rewards algorithms that detect all anomalies as soon as possible, triggers no false alarms, works with real-world time-series data across a variety of domains, and automatically adapts to changing statistics? Event Details AI By the Bay is a new conference applying scalable Machine Learning to batch and streaming data. Text and speech channels such as social media, sensors and other Internet of Things devices are generating more of these streams every day. These streams can be understood semantically, correlated, and used for real-time modeling of interactions crucially relevant to your business. We ll apply the same scientific rigor and uncompromising software engineering presented at Text By the Bay 2015 to the AI and IoT domains, and connect them through open-source systems, applications, and community. Subutai Ahmad VP Research All Events Posts Subutai Ahmad 2016/05/19 VP Research AI by the Bay  ","title":"AI by the Bay"},{"path":"/events/2016/05/19/business-analytics-innovation-summit-chicago-2016/","text":"Business Analytics Innovation Summit Chicago 2016 Thu, May 19, 2016 EventsBusiness Analytics Innovation Summit Chicago 2016 Christy Maver Director of Marketing WhenThu, May 19, 2016 Fri, May 20, 2016WhereInterContinental Chicago Magnificent MileChicago, IL USAWebEvent WebsiteSpeakingChristy Maver Smart Business Insights for Smarter Business Decisions Event Details The Business Analytics Innovation Summit provides a platform to share unique insight into the innovations that are driving success in the worlds leading organizations. - 25+ Industry thought leaders take the stage - Case studies, challenges, successes, lessons & more - Solutions & Services to fit your business analytics needs - Ample Networking opportunities, over 20 hours of networking provided - 150+ Analytics professionals in attendance - A range of industries representing their analytics stories Christy Maver Director of Marketing All Events Posts Christy Maver 2016/05/19 Director of Marketing Business Analytics Innovation Summit Chicago 2016  ","title":"Business Analytics Innovation Summit Chicago 2016"},{"path":"/events/2016/05/25/ai-startups-conference/","text":"AI Startups Conference Wed, May 25, 2016 EventsAI Startups Conference Celeste Baranski VP Engineering WhenWed, May 25, 2016 12:10 PM 12:35 PMWhereRackspaceSan Francisco, CA USAWebEvent WebsiteTopicReverse-Engineering the NeocortexSpeakingCeleste BaranskiEvent Details Conference open from 9:00am - 5:00pm (PST) Celeste Baranski VP Engineering All Events Posts Celeste Baranski 2016/05/25 VP Engineering AI Startups Conference  ","title":"AI Startups Conference"},{"path":"/events/2016/06/01/orange-county-meetup-deriving-machine-intelligence-from-neuroscience/","text":"OC Meetup - Deriving Machine Intelligence from Neuroscience Wed, Jun 01, 2016 EventsOC Meetup - Deriving Machine Intelligence from Neuroscience Alexander Lavin Research Engineer WhenWed, Jun 01, 2016 7:00 PM 8:00 PMWhereOC Deep Learning, HTM, ANN, NLP & AI MeetupIrvine, CA USAWebEvent WebsiteTopicDeriving Machine Intelligence from NeuroscienceSpeakingAlexander LavinHosted by: OC Deep Learning, HTM, ANN, NLP & AI Meetup. Alex will be presenting via webinar and his company Numenta who s a leader in this new era of machine intelligence is kind enough to be sending us some materials and giveaways so we will be able to share in some first hand data coming from this exciting field of Hierarchical Temporal Memory (HTM) which is detailed computational theory based on the neocortex. This will be an interactive webinar for those that can not make it in person. See event page to sign-up to attend in person, or via webinar. Alexander Lavin Research Engineer All Events Posts Alexander Lavin 2016/06/01 Research Engineer OC Meetup - Deriving Machine Intelligence from Neuroscience  ","title":"OC Meetup - Deriving Machine Intelligence from Neuroscience"},{"path":"/events/2016/06/18/dendritic-anatomy-molecules-and-function-heraklion-crete/","text":"Dendritic Anatomy, Molecules and Function Sat, Jun 18, 2016 EventsDendritic Anatomy, Molecules and Function Yuwei Cui Research Engineer WhenSat, Jun 18, 2016 Tue, Jun 21, 2016WhereThe Foundation for Research and Technology-Hellas (FORTH)Heraklion, Crete GreeceWebEvent WebsiteSpeakingYuwei CuiEvent Details Spotlight on molecules, structure, and function Dendrites are thin processes extending from the cell bodies of multiple neuron types. Since the majority of synaptic connections take place on dendrites, they provide the primary substrate for inter-neuronal communication. In addition to their role as conducting cables, the dendrites of many neuron types contain a rich repertoire of ionic mechanisms that allow them to perform all sorts of nonlinear computations. As a result, dendrites have been suggested to play a key role in information processing in brain and may even serve as independent processing units. This Workshop brings together scientific leaders from around the world to present their work on molecular, biophysical, anatomical and/or functional studies in dendrites, aiming to further our understanding of how these beautiful structures contribute to different brain functions. With the backdrop of an informal yet spectacular setting on the Greek island of Crete, the meeting has been carefully planned to not only satisfy our scientific curiosity but also foster discussion and encourage interaction between attendees well beyond the traditional presentations. In this spirit, the workshop will also provide soft skills sessions for all participants. Yuwei Cui Research Engineer All Events Posts Yuwei Cui 2016/06/18 Research Engineer Dendritic Anatomy, Molecules and Function  ","title":"Dendritic Anatomy, Molecules and Function"},{"path":"/events/2016/06/22/areadne-2016-research-in-encoding-and-decoding-of-neural-ensembles/","text":"Areadne 2016 - Research in Encoding And Decoding of Neural Ensembles Wed, Jun 22, 2016 EventsAreadne 2016 - Research in Encoding And Decoding of Neural Ensembles Yuwei Cui Research Engineer WhenWed, Jun 22, 2016 Sun, Jun 26, 2016WhereNomikos Conference CentreFira, Santorini GreeceWebEvent WebsiteSpeakingYuwei CuiEvent Details There are three major goals of the AREADNE Conferences. First and foremost, the meetings are intended to gather global scientific leaders who work on neural ensembles and create a touch-point for a widely disparate and hybrid field. Second, with a spectacular setting on Santorini, the conferences have been carefully planned to foster discussion and interaction between attendees to encourage the establishment of lasting professional relationships. Third, these meetings continue our efforts to promote systems neuroscience in Greece through creating a world-class forum for cutting-edge research. Yuwei Cui Research Engineer All Events Posts Yuwei Cui 2016/06/22 Research Engineer Areadne 2016 - Research in Encoding And Decoding of Neural Ensembles  ","title":"Areadne 2016 - Research in Encoding And Decoding of Neural Ensembles"},{"path":"/events/2016/07/01/the-playfair-ai-summit-2016/","text":"Playfair AI Summit 2016 Fri, Jul 01, 2016 EventsPlayfair AI Summit 2016 Subutai Ahmad VP of Research WhenFri, Jul 01, 2016 1:15 PM 1:40 PMWhereLondon, United Kingdom EnglandWebEvent WebsiteTopicHierarchical Temporal Memory, a theoretical framework for both biological and machine intelligenceSpeakingSubutai AhmadAbout the Event Artificial intelligence is transforming our world. FAST. In its second edition, the Playfair AI Summit 2016 will explore the frontiers of AI research and how these technologies are leveraged by companies to extend the functionality of products and services, as well as enable entirely new ones altogether. It s overwhelmingly clear that AI is transforming our personal and professional lives, as well as the operations of businesses worldwide. AI also has profound implications for the future fabric and functioning of society. Keeping with last year s tradition, the Playfair AI Summit 2016 will showcase the brightest academic and entrepreneurial leaders in engineering, research, product development from the most exciting technology companies and Universities. Conversations will be led by the industry s most respected journalists and thinkers. Subutai Ahmad VP of Research All Events Posts Subutai Ahmad 2016/07/01 VP of Research Playfair AI Summit 2016  ","title":"Playfair AI Summit 2016"},{"path":"/events/2016/07/13/data-science-summit/","text":"Data Science Summit US 2016 Wed, Jul 13, 2016 EventsData Science Summit US 2016 Subutai Ahmad Numenta Event WhenWed, Jul 13, 2016 2:30 PM 2:55 PMWhereFairmont HotelSan Francisco, CA USAWebEvent WebsiteTopicUnderstanding Cortical Principles and Building Intelligent MachinesSpeakingSubutai AhmadTopic At Numenta we aim to understand the computational principles underlying the neocortex, and build intelligent machines based on those principles. At its most basic level the neocortex takes in a stream of sensory data, builds a sensorimotor model of the world and outputs a stream of motor actions. Recent advances in neuroscience and neural imaging techniques have led to an explosion of data and information regarding these functions. In this talk I will describe a number of cortical principles and how, as computer scientists, we can translate them into working systems. The core ideas have been validated in commercial streaming analytics applications, and an optimized implementation is available in our open source project called NuPIC. Although we still have much work to do, this work forms a foundation for building biologically inspired intelligent machines. About The Data Science Summit is packed with industry experts, authors, researchers and business leaders, delivering concrete examples of data science and machine learning in action. Hear best practices, war stories, vital dos and don ts and precisely how innovators are deploying machine learning solutions in industry, and the business impact they deliver. Highlights - 2 days & 3 tracks with 60 talks and tutorials, and a startup showcase. - Hands-on trainings: gain practical skills using the best tools in the industry. - Hear war stories from business leaders at Capital One, Cloudera, Deepart, Google, Kaggle, Pandora, Quora, Salesforce, StichFix, Tableau and more. - Discover amazing machine learning advances from professors at Carnegie Mellon, Stanford, UC Berkeley & University of Washington. - Book signings by scikit-learn s Andreas Mueller & Pedro Domingos, author of The Master Algorithm . - 1400 fellow data scientists, developers and business leaders for networking. Subutai Ahmad Numenta Event All Events Posts Subutai Ahmad 2016/07/13 Numenta Event Data Science Summit US 2016  ","title":"Data Science Summit US 2016"},{"path":"/events/2016/07/24/numenta-anomaly-benchmark-competition-at-ieee-wcci-2016/","text":"IEEE WCCI 2016 - Numenta Anomaly Benchmark Competition Sun, Jul 24, 2016 EventsIEEE WCCI 2016 - Numenta Anomaly Benchmark Competition Numenta Event WhenSun, Jul 24, 2016 Fri, Jul 29, 2016WhereIEEE WCCI 2016Vancouver, British Columbia CanadaWebEvent WebsiteTopicNumenta Anomaly Benchmark Competition for Real-time Anomaly Detection @ IEEE WCCI 2016 Numenta Anomaly Benchmark Competition for Real-Time Anomaly Detection at IEEE WCCI 2016 (World Congress on Computational Intelligence). About Competition Do you have an algorithm that detects anomalies in streaming data? Or a dataset of real-world, time-series data with labeled anomalies? If so, you re encouraged to enter the Numenta Anomaly Benchmark (NAB) Competition. About Conference IEEE WCCI has traditionally been the largest technical event in the field of computational intelligence, hosting three separate prestigious conferences (IJCNN, FUZZ-IEEE, IEEE CEC) under one roof. Over the years the event has provided a platform for highly acclaimed intellectuals from all over the world to discuss and present their research findings on computational intelligence. The organizing committee will put in place a rich and varied technical program which is designed to engage participants in cross-fertilization of ideas among the three big areas in computational intelligence. The event will also offer a series of social functions, such as welcome reception, conference banquet etc., which will serve as a good channel to establish new connections and foster everlasting friendship among fellow counterparts. Numenta Event All Events Posts Numenta 2016/07/24 Event IEEE WCCI 2016 - Numenta Anomaly Benchmark Competition  ","title":"IEEE WCCI 2016 - Numenta Anomaly Benchmark Competition"},{"path":"/events/2016/07/26/ieee-wcci-2016/","text":"IEEE WCCI 2016 Tue, Jul 26, 2016 EventsIEEE WCCI 2016 Yuwei Cui Research Engineer WhenTue, Jul 26, 2016 8:00 AM 10:00 AMWhereIEEE WCCI 2016Vancouver, British Columbia CanadaWebEvent WebsiteTopicA comparative study of HTM and other neural network models for online sequence learning with streaming dataSpeakingYuwei CuiAbout Talk This talk is part of the International Joint Conference on Neural Networks (IJCNN 2016). Special Session TA-4: Online Real-Time Learning Strategies for Large Data Streams, located in room 215. Conference Schedule: http://www.wcci2016.org/document/ijcnn2016_5new.pdf About Conference IEEE WCCI has traditionally been the largest technical event in the field of computational intelligence, hosting three separate prestigious conferences (IJCNN, FUZZ-IEEE, IEEE CEC) under one roof. Over the years the event has provided a platform for highly acclaimed intellectuals from all over the world to discuss and present their research findings on computational intelligence. The organizing committee will put in place a rich and varied technical program which is designed to engage participants in cross-fertilization of ideas among the three big areas in computational intelligence. The event will also offer a series of social functions, such as welcome reception, conference banquet etc., which will serve as a good channel to establish new connections and foster everlasting friendship among fellow counterparts. Yuwei Cui Research Engineer All Events Posts Yuwei Cui 2016/07/26 Research Engineer IEEE WCCI 2016  ","title":"IEEE WCCI 2016"},{"path":"/events/2016/08/02/sf-data-science-meetup/","text":"SF Data Science Meetup Tue, Aug 02, 2016 EventsSF Data Science Meetup Alexander Lavin Research Engineer WhenTue, Aug 02, 2016 6:00 PM 9:00 PMWhereGalvanize @ 44 Tehama StreetSan Francisco, CA USAWebEvent WebsiteTopicPredictive Analytics with Numenta Machine IntelligenceSpeakingAlexander LavinTalk Abstract Predictive Analytics with Numenta Machine Intelligence As sensors integrate with our daily lives, driven largely by the internet of things (IoT), there is demand for streaming analytics algorithms to provide insight from this data. Factories, farms, homes, people, and more are being outfitted with sensors that produce streaming data, but traditional batch-processing analytics methods don t suffice. Algorithms must be able to learn and predict online, in real-time. They also must continuously learn and adapt to changing statistics of the environment while simultaneously making predictions. At Numenta we ve developed Hierarchical Temporal Memory (HTM), a theory of neocortex implemented in software for machine learning applications. HTM runs online and unsupervised, performing anomaly detection, prediction, and classification on streaming data. HTM can run on wide variety of data streams, from IT server metrics to GPS coordinates. In this talk, Alex will discuss HTM in the context of predictive analytics, presenting real-world use cases. Schedule - 6:00pm - Doors open & food/drinks - 6:50pm - Announcements - 7:00pm - Talks Start - 8:30pm - Networking Alexander Lavin Research Engineer All Events Posts Alexander Lavin 2016/08/02 Research Engineer SF Data Science Meetup  ","title":"SF Data Science Meetup"},{"path":"/events/2016/08/08/machine-intelligence-with-htm-a-new-approach-to-time-based-learning/","text":"Machine Intelligence with HTM - A New Approach to Time-Based Learning Mon, Aug 08, 2016 EventsMachine Intelligence with HTM - A New Approach to Time-Based Learning Numenta HTM Community WhenMon, Aug 08, 2016 6:00 PM 9:00 PMWhereH2O.ai HeadquartersMountain View, CA USAWebEvent WebsiteTopicHTM Bay Area MeetupEvent Details Updated: Aug 04, 2016, 5:00pm PST Welcome to the 3rd community-hosted HTM (Hierarchical Temporal Memory) Meetup. Meet HTM hackers, AI researchers, Entrepreneurs and enthusiasts working in the field of Artificial Intelligence. See below for a brief agenda. As always we have a special focus on lightning talks where you get to talk about your latest work. Sign up for a lightning talk if you plan to present. (Slots are limited, make sure you sign up fast). Agenda - 6:00 - 7:00: Welcome, Sign In and Networking - 7:00 - 7:10: About our Host (A message from our host for the day) - 7:10 - 7:20: State of HTM Open Source (Matt Taylor, HTM Community Manager @ Numenta) - 7:20 - 7:30: Message from Numenta (Christy Maver, Director of Marketing @ Numenta) - 7:30 - 7:40: Current HTM Theory thought process (TBD) - 7:40 - 9:00: Lightning Talks and Demos Lightning Talks and Demos - Two Extensions to HTM Engine - Ryan Mccall: an overview of HTM engine, describe the changes, and demo how to use them. - HTM SCHOOL LIVE (SDRs and Spatial Pooling) - Matt Taylor: Matt has been creating several YouTube videos about HTMs. He will talk in detail about Sparse Distributed Representations and Spatial Pooling. - Computational properties of the HTM spatial pooler - Yuwei Cui (Research Engineer @ Numenta): Talk about the HTM spatial pooler and update on state of current research. - A Comparison of Popular AI Technologies - Chandan Maruthi: We have often been asked for a comparison of different algorithms used in AI. Chandan will cover some of the key aspects of traditional AI methods, including HTM s. To sign-up for a demo/lighting talk email: chandan.maruthi@gmail.com. What is HTM? Hierarchical Temporal Memory (HTM) is an online machine learning model developed by Numenta, Inc. that models some of the structural and algorithmic properties of the neocortex. HTM is a biomimetic model based on the memory-prediction theory of brain function described by Jeff Hawkins in his book, On Intelligence. HTM is a method for discovering and inferring the high-level causes of observed input patterns and sequences, thus building an increasingly complex model of the world. More information about HTMs: http://numenta.com/technology-overivew/ Numenta HTM Community All Events Posts Numenta 2016/08/08 HTM Community Machine Intelligence with HTM - A New Approach to Time-Based Learning  ","title":"Machine Intelligence with HTM - A New Approach to Time-Based Learning"},{"path":"/events/2016/09/21/bernstein-conference-2016/","text":"Bernstein Conference 2016 Wed, Sep 21, 2016 EventsBernstein Conference 2016 Subutai Ahmad VP Research WhenWed, Sep 21, 2016 Fri, Sep 23, 2016WhereHumboldt UniversityBerlin, Berlin GermanyWebEvent WebsiteTopicWhy Do Neurons Have Thousands of Synapses? A Theory of Sequence Memory in NeocortexSpeakingSubutai AhmadAbout Conference The Bernstein Conference is the Bernstein Network s central forum that has developed over time into the largest annual Computational Neuroscience conference in Europe, attracting an international audience from across the world. It is organized by members of the Bernstein Network at annually changing locations and offers a broad overview over the topics of Computational Neuroscience and Neurotechnology. The next conference will take place in Berlin. About Talk Why Do Neurons Have Thousands of Synapses? A Theory of Sequence Memory in Neocortex. - Presenter: Subutai Ahmad, VP Research @ Numenta - Authors: Subutai Ahmad, Jeff Hawkins, Yuwei Cui - Research Paper: http://journal.frontiersin.org/article/10.3389/fncir.2016.00023/full Subutai Ahmad VP Research All Events Posts Subutai Ahmad 2016/09/21 VP Research Bernstein Conference 2016  ","title":"Bernstein Conference 2016"},{"path":"/events/2016/09/25/ai-with-the-best/","text":"AI with the Best Sun, Sep 25, 2016 EventsAI with the Best Matthew Taylor HTM Community Leader WhenSun, Sep 25, 2016 12:40 PM 1:40 PMWhereOnlineWebEvent WebsiteTopicHierarchical Temporal Memory: Computing Like the BrainSpeakingMatthew TaylorTalk Abstract Hierarchical Temporal Memory: Computing Like the Brain Most of today s AI technologies are extensions of ANN models that were envisioned twenty years ago. While they have some amazing capabilities, they are not truly intelligent. To attain truly intelligent machines, our approach is to understand the only thing we can all agree is intelligent today: the human brain. HTM is an AI technology that is biologically-constrained. All major algorithms at work in an HTM system were uncovered by years of intensive neuroscience research. In this presentation, I ll describe the major mechanism of HTM at a high level, and lay a path towards the future of truly intelligent machines. Matthew Taylor HTM Community Leader All Events Posts Matthew Taylor 2016/09/25 HTM Community Leader AI with the Best  ","title":"AI with the Best"},{"path":"/events/2016/11/11/mlconf-machine-learning-conference-san-francisco-2016/","text":"MLconf 2016 Machine Learning Conference San Francisco Fri, Nov 11, 2016 EventsMLconf 2016 Machine Learning Conference San Francisco Numenta Research Team WhenFri, Nov 11, 2016WhereHotel NikkoSan Francisco, CA USAWebEvent WebsiteAbout the MLconf The Machine Learning Conference (MLconf) began in 2012, as a partnership with Carnegie Mellon University s GraphLab team, to gather the thought leaders in Machine Learning, specifically Graph Databases. In 2013, MLconf became a separate event, devoted to the Machine Learning and Data Science community in San Francisco, agnostic of any tool, platform or company. MLconf events host speakers from various industries, research and universities to discuss recent research and application of Machine Learning methodologies and practices. In 2014, MLconf entered NYC and Atlanta, as well as San Francisco. In 2015, MLconf will host conferences in NYC, Atlanta, Seattle and San Francisco, with plans to enter additional US cities in 2016, and the UK. MLconf gathers communities to discuss the recent research and application of Algorithms, Tools, and Platforms to solve the hard problems that exist within organizing and analyzing massive and noisy data sets. Numenta Research Team All Events Posts Numenta 2016/11/11 Research Team MLconf 2016 Machine Learning Conference San Francisco  ","title":"MLconf 2016 Machine Learning Conference San Francisco"},{"path":"/htm-for-stocks/","text":"HTM for Stocks HTM for StocksFind anomalies in publicly traded stocks using trading and Twitter data. HTM for Stocks is an example HTM application that continually monitors hundreds of publicly traded companies and alerts you if something unusual is happening to any of them. HTM for Stocks uses HTM machine intelligence algorithms to model stock price, stock volume, and Twitter data related to 200 of the largest publicly traded companies. Companies monitored include Apple, Google, Amazon, and Starbucks. HTM for Stocks is a mobile application that runs on both iOS and Android-based phones. HTM for Stocks is an example application and is available for free. We invite you to register to give feedback or send us an email. Numenta has made the source code for HTM for Stocks available alongside the NuPIC open source project to encourage others to create new and derivative products. Contact us with questions or interest. Review the source code.FeaturesTime-based Pattern Detection Automatically analyzes time-based patterns on a company by company basis to identify anomalies. The HTM algorithm ensures that reported anomalies are rare (avoiding false positives), and that real anomalies can be detected, even if humans can t see them (avoiding false negatives).Most Anomalous Companies Highlighted Companies are listed in order of most anomalous in the past 24 hours so everything the user wants to see is usually visible on one page.Continuous Learning Learns with each data point and adapts to changes over time.Root-cause analysis Displays tweets around the same time as anomalies so you can easily see what people are saying and why something unusual is happening.Notifications Sends alerts when anomalies occur on your favorite companies.iOS and Android Mobile App Presents output in a friendly, mobile user interface.How Does It Work?Ingests real-time stock and Twitter data For each monitored company, data is collected every five minutes for stock price, stock volume and Twitter volume. Actual data charts can be viewed in the application.Models build automatically Models are automatically built and refined for each data stream. No data scientists are required!Anomalies are based on deviation from recent performance Each company is different. HTM models report anomalies when current behavior deviates from recent behavior.Sample Use Cases CEO wants to be alerted about unusual activity with competitors. Sales Rep monitors companies in her territory to harvest new information for sales calls. Marketing Executive aims to understand product announcement chatter. Financial market followers track companies of interest, noting when anomalies occur.Get App and RegisteriOS (version 8.0 or higher)Android phone (version 4.1 or higher) We value your participation and encourage you to register and provide feedback. This is optional registration so we can contact you for future discussion.NameEmailPhone Submit ","title":"HTM for Stocks"},{"path":"/htm-studio/date-time-formats/","text":"HTM Studio - Supported Date/Time Formats HTM Studio - Supported Date/Time Formats The following document gives details on the supported date/time formats which HTM Studio can input. This file is auto-generated and will be updated periodically. Back to HTM Studio UNIX HTM Studio supports UNIX timestamps in seconds and milliseconds. If you are using a UNIX timestamp, you must have a header row in your data file. The header of the column with date/time needs to contain either the word date or \"time\". Last Generated: Thu Jun 23 2016 09:07:21 GMT-0700 Source ISO 8601 Format Example YYYY-MM-DDTHH:mm:ss.SSSZ 2016-06-23T09:07:21.205-07:00 YYYY-MM-DDTHH:mm:ss.SSZ 2016-06-23T09:07:21.20-07:00 YYYY-MM-DDTHH:mm:ss.SZ 2016-06-23T09:07:21.2-07:00 YYYY-MM-DDTHH:mm:ss.SSS 2016-06-23T09:07:21.205 YYYY-MM-DDTHH:mm:ss.SS 2016-06-23T09:07:21.20 YYYY-MM-DDTHH:mm:ss.S 2016-06-23T09:07:21.2 YYYY-MM-DDTHH:mm:ssZ 2016-06-23T09:07:21-07:00 YYYY-MM-DDTHH:mm:ss 2016-06-23T09:07:21 YYYY-MM-DDTHH:mmZ 2016-06-23T09:07-07:00 YYYY-MM-DDTHH:mm 2016-06-23T09:07 YYYY-MM-DDTHHZ 2016-06-23T09-07:00 YYYY-MM-DDTHH 2016-06-23T09 Variation of ISO 8601 Format Example YYYY/MM/DDTHH:mm:ss.SSSZ 2016/06/23T09:07:21.205-07:00 YYYY/MM/DDTHH:mm:ss.SSZ 2016/06/23T09:07:21.20-07:00 YYYY/MM/DDTHH:mm:ss.SZ 2016/06/23T09:07:21.2-07:00 YYYY/MM/DDTHH:mm:ss.SSS 2016/06/23T09:07:21.205 YYYY/MM/DDTHH:mm:ss.SS 2016/06/23T09:07:21.20 YYYY/MM/DDTHH:mm:ss.S 2016/06/23T09:07:21.2 YYYY/MM/DDTHH:mm:ssZ 2016/06/23T09:07:21-07:00 YYYY/MM/DDTHH:mm:ss 2016/06/23T09:07:21 YYYY/MM/DDTHH:mmZ 2016/06/23T09:07-07:00 YYYY/MM/DDTHH:mm 2016/06/23T09:07 YYYY/MM/DDTHHZ 2016/06/23T09-07:00 YYYY/MM/DDTHH 2016/06/23T09 ISO 8601 no T Format Example YYYY-MM-DD HH:mm:ss.SSSZ 2016-06-23 09:07:21.205-07:00 YYYY-MM-DD HH:mm:ss.SSZ 2016-06-23 09:07:21.20-07:00 YYYY-MM-DD HH:mm:ss.SZ 2016-06-23 09:07:21.2-07:00 YYYY-MM-DD HH:mm:ss.SSS 2016-06-23 09:07:21.205 YYYY-MM-DD HH:mm:ss.SS 2016-06-23 09:07:21.20 YYYY-MM-DD HH:mm:ss.S 2016-06-23 09:07:21.2 YYYY-MM-DD HH:mm:ssZ 2016-06-23 09:07:21-07:00 YYYY-MM-DD HH:mm:ss 2016-06-23 09:07:21 YYYY-MM-DD HH:mmZ 2016-06-23 09:07-07:00 YYYY-MM-DD HH:mm 2016-06-23 09:07 YYYY-MM-DD HHZ 2016-06-23 09-07:00 YYYY-MM-DD HH 2016-06-23 09 YYYY-MM-DD 2016-06-23 Variation of ISO 8601 no T Format Example YYYY/MM/DD HH:mm:ss.SSSZ 2016/06/23 09:07:21.205-07:00 YYYY/MM/DD HH:mm:ss.SSZ 2016/06/23 09:07:21.20-07:00 YYYY/MM/DD HH:mm:ss.SZ 2016/06/23 09:07:21.2-07:00 YYYY/MM/DD HH:mm:ss.SSS 2016/06/23 09:07:21.205 YYYY/MM/DD HH:mm:ss.SS 2016/06/23 09:07:21.20 YYYY/MM/DD HH:mm:ss.S 2016/06/23 09:07:21.2 YYYY/MM/DD HH:mm:ssZ 2016/06/23 09:07:21-07:00 YYYY/MM/DD HH:mm:ss 2016/06/23 09:07:21 YYYY/MM/DD HH:mmZ 2016/06/23 09:07-07:00 YYYY/MM/DD HH:mm 2016/06/23 09:07 YYYY/MM/DD HHZ 2016/06/23 09-07:00 YYYY/MM/DD HH 2016/06/23 09 YYYY/MM/DD 2016/06/23 US Date, 12h AM/PM time Format Example MM-DD-YYYY hh:mm:ss.SSS A 06-23-2016 09:07:21.205 AM MM-DD-YYYY hh:mm:ss.SS A 06-23-2016 09:07:21.20 AM MM-DD-YYYY hh:mm:ss.S A 06-23-2016 09:07:21.2 AM MM-DD-YYYY hh:mm:ss A 06-23-2016 09:07:21 AM MM-DD-YYYY hh:mm A 06-23-2016 09:07 AM MM/DD/YYYY hh:mm:ss.SSS A 06/23/2016 09:07:21.205 AM MM/DD/YYYY hh:mm:ss.SS A 06/23/2016 09:07:21.20 AM MM/DD/YYYY hh:mm:ss.S A 06/23/2016 09:07:21.2 AM MM/DD/YYYY hh:mm:ss A 06/23/2016 09:07:21 AM MM/DD/YYYY hh:mm A 06/23/2016 09:07 AM US Date, 24h time Format Example MM-DD-YYYY HH:mm:ss.SSS 06-23-2016 09:07:21.205 MM-DD-YYYY HH:mm:ss.SS 06-23-2016 09:07:21.20 MM-DD-YYYY HH:mm:ss.S 06-23-2016 09:07:21.2 MM-DD-YYYY HH:mm:ss 06-23-2016 09:07:21 MM-DD-YYYY HH:mm 06-23-2016 09:07 MM/DD/YYYY HH:mm:ss.SSS 06/23/2016 09:07:21.205 MM/DD/YYYY HH:mm:ss.SS 06/23/2016 09:07:21.20 MM/DD/YYYY HH:mm:ss.S 06/23/2016 09:07:21.2 MM/DD/YYYY HH:mm:ss 06/23/2016 09:07:21 MM/DD/YYYY HH:mm 06/23/2016 09:07 US Date, no time Format Example MM-DD-YYYY 06-23-2016 MM-DD-YY 06-23-16 MM/DD/YYYY 06/23/2016 MM/DD/YY 06/23/16 US Date, time (excel default on OSX) Format Example MM/DD/YY H:mm 06/23/16 9:07 MM/DD/YY H:mm:SS 06/23/16 9:07:20 MM/DD/YY HH:mm 06/23/16 09:07 MM/DD/YY HH:mm:SS 06/23/16 09:07:20 MM/DD/YY H 06/23/16 9 MM/DD/YY HH 06/23/16 09 MM/D/YY H:mm 06/23/16 9:07 MM/D/YY H:mm:SS 06/23/16 9:07:20 MM/D/YY HH:mm 06/23/16 09:07 MM/D/YY HH:mm:SS 06/23/16 09:07:20 MM/D/YY H 06/23/16 9 MM/D/YY HH 06/23/16 09 MM/D/YY 06/23/16 M/DD/YY H:mm 6/23/16 9:07 M/DD/YY H:mm:SS 6/23/16 9:07:20 M/DD/YY HH:mm 6/23/16 09:07 M/DD/YY HH:mm:SS 6/23/16 09:07:20 M/DD/YY H 6/23/16 9 M/DD/YY HH 6/23/16 09 M/DD/YY 6/23/16 M/D/YY H:mm 6/23/16 9:07 M/D/YY H:mm:SS 6/23/16 9:07:20 M/D/YY HH:mm 6/23/16 09:07 M/D/YY HH:mm:SS 6/23/16 09:07:20 M/D/YY H 6/23/16 9 M/D/YY HH 6/23/16 09 M/D/YY 6/23/16 US Date, time (excel default on Windows) Format Example MM/DD/YYYY H:mm 06/23/2016 9:07 MM/DD/YYYY H:mm:SS 06/23/2016 9:07:20 MM/DD/YYYY HH:mm 06/23/2016 09:07 MM/DD/YYYY HH:mm:SS 06/23/2016 09:07:20 MM/DD/YYYY H 06/23/2016 9 MM/DD/YYYY HH 06/23/2016 09 MM/D/YYYY H:mm 06/23/2016 9:07 MM/D/YYYY H:mm:SS 06/23/2016 9:07:20 MM/D/YYYY HH:mm 06/23/2016 09:07 MM/D/YYYY HH:mm:SS 06/23/2016 09:07:20 MM/D/YYYY H 06/23/2016 9 MM/D/YYYY HH 06/23/2016 09 MM/D/YYYY 06/23/2016 M/DD/YYYY H:mm 6/23/2016 9:07 M/DD/YYYY H:mm:SS 6/23/2016 9:07:20 M/DD/YYYY HH:mm 6/23/2016 09:07 M/DD/YYYY HH:mm:SS 6/23/2016 09:07:20 M/DD/YYYY H 6/23/2016 9 M/DD/YYYY HH 6/23/2016 09 M/DD/YYYY 6/23/2016 M/D/YYYY H:mm 6/23/2016 9:07 M/D/YYYY H:mm:SS 6/23/2016 9:07:20 M/D/YYYY HH:mm 6/23/2016 09:07 M/D/YYYY HH:mm:SS 6/23/2016 09:07:20 M/D/YYYY H 6/23/2016 9 M/D/YYYY HH 6/23/2016 09 M/D/YYYY 6/23/2016 HTM Studio - Supported Date/Time Formats","title":"HTM Studio - Supported Date/Time Formats"},{"path":"/htm-studio/faq/advanced-settings/","text":"What are the advanced settings for? What are the advanced settings for? HTM Studio determines the optimal parameters for each Hierarchical Temporal Memory (HTM) model and in some cases, aggregates your data for analysis. You can see what these parameters are in the advanced settings. We recommend that you follow the determined parameters for the best possible analysis. However, you may modify these parameters by clicking the advanced settings. For example, you can change the aggregation method and period. Or you can also suppress data aggregation by disabling the check box. See question What does aggregate my data mean? for information on aggregating data. What are the advanced settings for?","title":"What are the advanced settings for?"},{"path":"/htm-studio/faq/aggregate-data/","text":"What does &quot;aggregate my data&quot; mean? What does \"aggregate my data\" mean? HTM Studio determines how much to aggregate the input records (or not at all) before feeding them into the HTM model. Generally, aggregating noisy data will reduce the amount of noise and help the HTM model learn faster. Aggregation means that multiple values will be combined over an aggregation period using the aggregation method, sum or average. What does \"aggregate my data\" mean?","title":"What does &quot;aggregate my data&quot; mean?"},{"path":"/htm-studio/faq/data-formats/","text":"What data formats does HTM Studio accept? What data formats does HTM Studio accept? HTM Studio only accepts CSV files that meet certain requirements, which can be found in the get started section. What data formats does HTM Studio accept?","title":"What data formats does HTM Studio accept?"},{"path":"/htm-studio/faq/determine-anomalous/","text":"How does HTM Studio determine what is anomalous? How does HTM Studio determine what is anomalous? HTM Studio first learns patterns in your data and builds a model to predict what is likely to happen in the next CSV record. Based on these predictions, the HTM algorithm generates an anomaly score for each data point. If you would like to learn more about anomaly detection, please refer to our Science of Anomaly Detection White Paper. How does HTM Studio determine what is anomalous?","title":"How does HTM Studio determine what is anomalous?"},{"path":"/htm-studio/faq/initial-learning-period/","text":"What is the initial learning period? What is the initial learning period? HTM Studio begins to build models from the metric in your data immediately. During the initial learning period, the anomaly results are displayed as grey bars with the value N/A displayed in the chart area. Once a HTM model has enough data points to learn on, it will display anomalies indicated by green, yellow and red bars. What is the initial learning period?","title":"What is the initial learning period?"},{"path":"/htm-studio/faq/no-date-time-column/","text":"What if I don&#x27;t have a date/time column in my file, can I still use HTM Studio? What if I don't have a date/time column in my file, can I still use HTM Studio? You can create a mock column for date / time by numbering each row (for example: 0, 1, 2, 3) in your file and ensure you have a header row, with the mock column named time . What if I don't have a date/time column in my file, can I still use HTM Studio?","title":"What if I don&#x27;t have a date/time column in my file, can I still use HTM Studio?"},{"path":"/htm-studio/faq/not-seeing-anomalies/","text":"Why am I not seeing any anomalies? Why am I not seeing any anomalies? There are many reasons why this may occur, but some of the most common are: - If your data does not include any abnormal patterns, then HTM Studio cannot detect any anomalies. - HTM Studio learns and builds models from your data during its initial learning period, see question What is the initial learning period? HTM Studio needs to have enough data points, at least 500, to learn patterns and detect anomalies. See a full list of requirements here. - HTM Studio has not detected any anomalies during a given time period for this data. Although some of the data may look unusual, if HTM Studio has previously learned a pattern then it will not find it anomalous. Try looking at older data in the chart to see if similar patterns have previously occurred. Why am I not seeing any anomalies?","title":"Why am I not seeing any anomalies?"},{"path":"/htm-studio/faq/supported-platforms-versions/","text":"What are the supported platforms and versions? What are the supported platforms and versions? We support Mac OS/X (versions Yosemite and El Capitan) and Windows (64-bit versions 7, 8 and 10). What are the supported platforms and versions?","title":"What are the supported platforms and versions?"},{"path":"/htm-studio/faq/whats-next/","text":"I am interested in integrating HTM technology into my application, what can I do next? I am interested in integrating HTM technology into my application, what can I do next? Contact Us to discuss adding HTM technology to your system and for licensing opportunities. You can also engage with our HTM open source community at http://numenta.org. There you will find all of our code, and learning resources to develop a project using HTM. I am interested in integrating HTM technology into my application, what can I do next?","title":"I am interested in integrating HTM technology into my application, what can I do next?"},{"path":"/htm-studio/","text":"HTM Studio HTM Studio Video: HTM Studio Introduction (01:37) Find Real-Time Anomalies in your Streaming Data HTM Studio allows you to test whether our Hierarchical Temporal Memory (HTM) algorithms will find anomalies in your data. With just one click, you can uncover anomalies other techniques cannot find in your numeric, time-series data, in minutes. I agree to the Terms and Conditions Please agree to the Terms and Conditions above before downloading. Download HTM Studio - Available on Desktop only, for Mac OS/X and Windows (64 bit versions). - Installation on Windows will take several minutes. - Windows 10 users, click here for further information. Features No Coding Skills Required Skip the hassle of setting parameters. Discover anomalies with one click. Data Privacy Add local CSV (comma-separated value) files quickly with no upload or privacy issues. Run Simultaneous Models Run multiple data streams simultaneously and compare discovered anomalies. Summarized Results Visualize and export your results. Pre-Loaded Datasets Don t have your own data readily available? Experiment with our pre-loaded datasets, and see how HTM can be applied to a variety of use cases.Use CasesPreventative Maintenance Monitor machine sensors to detect failures before they occur.IoT Sensors Understand energy usage and adjust resources in a connected building.Traffic Patterns Identify unusual patterns in direction or speed from a vehicle.Network Servers Identify network changes and potential server degradation.Get Started Video: HTM Studio Walk-through (04:41) To get the full HTM Studio experience, watch our short walk-through video. Data imported into HTM Studio must be formatted to meet certain conditions. See requirements and watch our brief instructional videos to learn how to prepare your data. Video: Date/Time Format Tutorial (04:28) Date/Time Format Data imported into HTM Studio must be in CSV file format and meet the following conditions: - Only one Date/Time column - Only one header row - Number of rows in the CSV file should be minimum of 400. - Values in numeric columns will be skipped if equal to: \"NaN\", \"None\", \"null\", \"N/A\", \"NA\" (not case sensitive) - Any number of numeric columns - Data is listed in chronological order - Date/Time column must be in a supported format - Unix timestamp support (both milliseconds and seconds) as long as the column name contains the words \"time\" or \"date\" (case insensitive) Video: Isolating Data Sources Tutorial (02:47) Isolating Data Sources CSV files must contain data that has only been generated from one source. If you have multiple sources, you will need to split your data by source and into separate CSV files.Frequently Asked Questions I am interested in integrating HTM technology into my application, what can I do next? Contact Us to discuss adding HTM technology to your system and for licensing opportunities. You can also engage with our HTM open source community at http://numenta.org. There you will find all of our code, and learning resources to develop a project using HTM. What are the supported platforms and versions? We support Mac OS/X (versions Yosemite and El Capitan) and Windows (64-bit versions 7, 8 and 10). What if I don't have a date/time column in my file, can I still use HTM Studio? You can create a mock column for date / time by numbering each row (for example: 0, 1, 2, 3) in your file and ensure you have a header row, with the mock column named time . What data formats does HTM Studio accept? HTM Studio only accepts CSV files that meet certain requirements, which can be found in the get started section. What does \"aggregate my data\" mean? HTM Studio determines how much to aggregate the input records (or not at all) before feeding them into the HTM model. Generally, aggregating noisy data will reduce the amount of noise and help the HTM model learn faster. Aggregation means that multiple values will be combined over an aggregation period using the aggregation method, sum or average. What are the advanced settings for? HTM Studio determines the optimal parameters for each Hierarchical Temporal Memory (HTM) model and in some cases, aggregates your data for analysis. You can see what these parameters are in the advanced settings. We recommend that you follow the determined parameters for the best possible analysis. However, you may modify these parameters by clicking the advanced settings. For example, you can change the aggregation method and period. Or you can also suppress data aggregation by disabling the check box. See question What does aggregate my data mean? for information on aggregating data. What is the initial learning period? HTM Studio begins to build models from the metric in your data immediately. During the initial learning period, the anomaly results are displayed as grey bars with the value N/A displayed in the chart area. Once a HTM model has enough data points to learn on, it will display anomalies indicated by green, yellow and red bars. How does HTM Studio determine what is anomalous? HTM Studio first learns patterns in your data and builds a model to predict what is likely to happen in the next CSV record. Based on these predictions, the HTM algorithm generates an anomaly score for each data point. If you would like to learn more about anomaly detection, please refer to our Science of Anomaly Detection White Paper. Why am I not seeing any anomalies? There are many reasons why this may occur, but some of the most common are: - If your data does not include any abnormal patterns, then HTM Studio cannot detect any anomalies. - HTM Studio learns and builds models from your data during its initial learning period, see question What is the initial learning period? HTM Studio needs to have enough data points, at least 500, to learn patterns and detect anomalies. See a full list of requirements here. - HTM Studio has not detected any anomalies during a given time period for this data. Although some of the data may look unusual, if HTM Studio has previously learned a pattern then it will not find it anomalous. Try looking at older data in the chart to see if similar patterns have previously occurred. Resources - HTM Studio Data SheetDownload this one-page data sheet to learn more about HTM Studio. - Science of Anomaly Detection VideoLearn about the science behind our HTM machine intelligence algorithms in this educational video. - Terms and ConditionsTerms and Conditions for HTM Studio. - Numenta Anomaly Benchmark (NAB)An open-source benchmark for evaluating anomaly detection in streaming data.Feedback Provide your feedback on HTM Studio via the form below, or email htm-studio@numenta.com for further information on HTM. NameEmailFeedback Submit ","title":"HTM Studio"},{"path":"/htm-studio/terms/","text":"HTM Studio Terms and Conditions HTM Studio Terms and Conditions Numenta is happy to license HTM Studio to you if you accept all of the terms and conditions contained in this Agreement. By accepting this agreement and downloading HTM Studio, you indicate that you have read and understand this Agreement and accept all of its terms and conditions. If you agree to these terms and conditions on behalf of a business, government agency, or other entity, you warrant that you have authority to bind that business, agency, or other entity to this Agreement, and your agreement to these terms and conditions will be treated as the agreement of that business, agency, or other entity. In that event, you and your refer herein to that business, agency, or other entity. PREAMBLE The purpose of this Preamble is to give a plain English description of this Agreement. Please read the rest of the Agreement carefully for detailed terms and conditions. Numenta welcomes individuals, businesses, and other entities to explore and advance HTM technology. This license allows you to explore HTM ideas using HTM Studio in whole or in part, at no charge, as long as your work is for research and experimentation purposes only. You may not sell or distribute any portion of HTM Studio or your work product for commercial or production use unless you take an appropriate commercial license from us. HTM Studio collects anonymized application activity statistics (clicks, menus opened, etc.) and reports them to Numenta so we can learn about the use of HTM Studio and continue to improve it. HTM Studio will never collect or report information about HTM Studio users (names, IP addresses, etc.) or users data (file names, data points, results, etc.). 1. Definitions. HTM means the Hierarchical Temporal Memory theory. NuPIC means the Numenta Platform for Intelligent Computing. All NuPIC code is made available through the numenta GitHub organization at http://github.com/numenta, under an AGPLv3 license. HTM Studio refers to the application that can be used to find anomalies in streaming data. All HTM Studio code is made available through the \"numenta\" GitHub organization at http://github.com/numenta, under an AGPLv3 license. 1. License, Permitted Uses, Restrictions, and Ownership. - (a) License. Numenta hereby grants you a non-exclusive, non-transferable, royalty-free license during the term of this Agreement to install and use HTM Studio for the permitted uses detailed in section 2(b) subject to the restrictions detailed in section 2(c). Any technology that does not exist at http://github.com/numenta with an AGPL license is not included in this License. - (b) Permitted Uses. You may use HTM Studio to conduct research and analysis. You may use HTM Studio for evaluation of HTM and for validation of its applicability to specific problems. You may use HTM Studio for instruction and training. You may publish information regarding the results of your research as long as you include an appropriate citation. You may modify and create derivative works of HTM Studio. - (c) Restrictions. You may not offer for sale, distribute, or permit others to use any technology that includes the HTM Studio or NuPIC software or intellectual property, either free or for a fee, unless you have entered into an appropriate Numenta commercial license agreement. - (d) Ownership of Intellectual Property. You agree that Numenta owns all right, title and interest, including but not limited to copyright, patent, trade secret and all other intellectual property rights, in and to HTM Studio and NuPIC, and any changes, modifications, or corrections thereto that are made by or for Numenta. You hereby grant to Numenta a perpetual, irrevocable, world-wide, royalty-free, non-exclusive, license to use any feedback, suggestions, or ideas that you provide directly to Numenta regarding HTM Studio or NuPIC. 1. Application Analytics. HTM Studio collects anonymized application activity statistics, including but not limited to user clicks and frequency and order of menus opened in the application. These statistics are reported to Numenta. By accepting this agreement and downloading HTM Studio, you give your permission for Numenta to collect and use these statistics. HTM Studio will never collect or report information about HTM Studio users (names, IP addresses, etc.) or users data (file names, data points, results, etc.). 2. Software Updates. HTM Studio may automatically download and install updates from time to time from Numenta. These updates are designed to improve, enhance and further develop HTM Studio and may take the form of bug fixes, enhanced functions, new software modules and completely new versions. You agree to receive such updates (and permit Numenta to deliver these to you) as part of your use of HTM Studio. 3. No Support. You acknowledge and agree that Numenta undertakes no obligation to provide any support, error corrections, or upgrades for HTM Studio, and that you assume all risk arising from your use of HTM Studio. 4. Termination. You may terminate this Agreement at any time upon written notice to Numenta. Either party may terminate this Agreement immediately upon written notice to the other party: (i) in the event of the insolvency, bankruptcy or voluntary dissolution of the other party; or (ii) if the other party defaults in the performance of any provision hereunder, and if such default continues and is not cured within thirty (30) days after written notice thereof to the defaulting party. Upon any termination of this Agreement, you agree to immediately cease using HTM Studio. 5. No Warranties; Limitation of Liability. - (a) No Warranty. HTM Studio is provided as is without warranty of any kind including without limitation, any warranty of merchantability, fitness for a particular purpose, or non-infringement. Further, Numenta does not warrant results of use or that HTM Studio is bug free or that its use will be uninterrupted. The parties agree and acknowledge that NuPIC is an early-stage technology and there can be no assurance that either HTM Studio or NuPIC will be further developed or improved by Numenta into a commercially viable product. No advice or information, whether oral or written, obtained from Numenta or elsewhere will create any warranty not expressly stated in this Agreement. - (b) Limitation of Liability. Numenta will have no liability to you under this Agreement. In no event will either party be liable for costs of procurement of substitute goods, loss of profits, or for any special, indirect, consequential or incidental damages, however caused, whether for breach of warranty, breach of contract, repudiation of contract, negligence or otherwise. 1. General. Once executed, this Agreement takes precedence over the standard open source licenses provided at http://numenta.org, http://github.com/numenta and https://github.com/numenta/numenta-apps. The terms of this Agreement may only be modified by a written agreement signed by both parties. You may not assign this Agreement without the prior written consent of Numenta. This Agreement will be governed by the laws of the state of California and the United States of America. No failure of either party to enforce any of its rights under this Agreement will act as a waiver of such rights or of any other rights hereunder. HTM Studio Terms and Conditions","title":"HTM Studio Terms and Conditions"},{"path":"/htm-studio/windows/","text":"HTM Studio - Windows 10 HTM Studio - Windows 10If you are using Windows 10 Windows Defender - You may see the following error screen. Click More info. - After clicking More info, click Run anyway to continue downloading the application. Back to HTM Studio HTM Studio - Windows 10","title":"HTM Studio - Windows 10"},{"path":"/","text":"Numenta — Leading the New Era of Machine Intelligence Leading the New Era of Machine IntelligenceAboutNumenta develops machine intelligence technology based on neocortical theory.EstablishedFeb 4, 2005LocationRedwood City, CAEmployees15 20BusinessLicensingTypePrivateContentBlog NewsletterPressReleases LinksEventsEventsLatest Why did we overhaul our web design? The story behind our new look. New Numenta is tackling one of the most important scientific challenges of all time: reverse engineering the neocortex. Studying how the brain works helps us understand the principles of intelligence and build machines that work on the same principles. We believe that understanding how the neocortex works is the fastest path to machine intelligence, and creating intelligent machines is important for the continued success of humankind. We are at the beginning of a thrilling new era of computing that will unfold over the coming decades, and we invite you to learn about how our approach is helping to advance the state of brain theory and machine intelligence. On this site, you ll find information about our company. If you re looking for technical resources, including details of our research, software implementations, and how to get started with our technology, visit our open source community at http://numenta.org . Next: Mission & History ","title":"Numenta — Leading the New Era of Machine Intelligence"},{"path":"/legal/privacy/","text":"Privacy Policy Fri, Jul 22, 2016Privacy Policy These terms of service apply to the use of Numenta s streaming analytics product as distributed through cloud service providers (the Grok Product) and for the use of Numenta s web site. Together, the Grok Product and the Numenta web site are called the Numenta Offering. 1. ACCEPTANCE OF TERMS If you do not agree to these Terms, you should not use the Numenta Offering. We reserve the right to change, modify, add or remove portions of these Terms periodically. Such modifications shall be effective immediately upon posting of the modified Terms to the Numenta website. Your continued use of the Numenta Offering will mean that you accept these terms. 2. NO UNLAWFUL OR PROHIBITED USE You warrant to Numenta that you will not use the Numenta Offering, or any of the content therein, for any purpose that is unlawful or that is prohibited by these Terms. 3. LICENSE GRANT Your rights to access, download, and use the Grok Product will be subject to the terms and conditions of the software license agreement provided on the cloud service provider s site through which it is distributed. 4. YOUR CONTENT Numenta will not pre-screen or review your content, but Numenta shall have the right (but not the obligation) in its sole discretion to refuse or delete any content that it reasonably considers to violate the Terms or to be otherwise illegal. You grant Numenta the right to review your content for the purposes of debugging the Numenta Offering and for providing you with technical support. Numenta will not share your content with others without your explicit, written permission, except in the case where being required to do so by the appropriate court or government agency. 5. TERMINATION We may terminate your use of the Numenta Offering if we have reasonable belief that your use: 1) violates these Terms; or 2) abuses site resources or attempts to gain unauthorized entry to the site or site resources; or 3) we are required to do so by law, regulation, court or governing agency order. Our termination of any user s access to the Numenta Offering may be effected without notice and, on such termination, we may immediately deactivate or delete user s account and/or bar any further access to such files. Numenta shall not be liable to any Numenta user or other third party for any such termination. You may terminate your use of the Numenta Offering by stopping its use without notice to us. 6. PAYMENT The Numenta Product is delivered through a cloud service provider s marketplace. You will abide by the payment terms as detailed in that marketplace. If you do not wish to continue using and paying for the Numenta Product, you may stop using it at any time, and further charges will not accrue. We do not offer refunds for any amounts paid. 7. LINKS To the extent the Numenta website includes links to third parties, Numenta is not responsible or liable for the content of such sites. The Numenta website privacy statement is applicable only when you are on the Numenta websites. 8. SUPPORT Technical support for the Grok Product is provided by email. We will make a reasonable effort to respond to your email within 48 hours. Support inquiries are to be sent to support@numenta.com. 9. TRADEMARK INFORMATION Numenta, Grok, NuPIC, and the Numenta, Grok and NuPIC trademarks, logos and service marks are the intellectual property of Numenta, Inc. All trademarks, trade names, service marks and logos referenced herein are the property of their respective owners. 10. COPYRIGHTS If you believe that your work has been copied and is accessible in the Numenta Offering in a way that constitutes copyright infringement, you may notify us by providing our copyright agent with the following information in writing: - the electronic or physical signature of the owner of the copyright or the person authorized to act on the owner s behalf; - identification of the copyrighted work that you claim has been infringed; - identification of the material that is claimed to be infringing and information reasonably sufficient to permit Grok to locate the material; - your name, address, telephone number, and email address; - a statement by you that you have a good faith belief that the disputed use is not authorized by the copyright owner, its agent, or the law; - a statement, made under penalty of perjury, that the above information in your Notice is accurate and that you are the copyright owner or are authorized to act on the copyright owner s behalf. If Numenta receives such a claim, Numenta will investigate and report back to the complainant. Numenta reserves the right to delete such reported content or to terminate a user s account. Our designated agent to receive notification of claimed infringement under the Digital Millennium Copyright Act OF 1998 ( DMCA ) is: dmca@numenta.com 11. VIOLATIONS OF TERMS Please report any violations of the Terms to info@numenta.com. 12. PRIVACY Our Privacy Policy is located at http://numenta.com/legal/privacy/. 2016/07/22 Privacy Policy","title":"Privacy Policy"},{"path":"/legal/terms/","text":"Terms of Service Fri, Jul 22, 2016Terms of Service These terms of service apply to the use of Numenta s streaming analytics product as distributed through cloud service providers (the Grok Product) and for the use of Numenta s web site. Together, the Grok Product and the Numenta web site are called the Numenta Offering. 1. ACCEPTANCE OF TERMS If you do not agree to these Terms, you should not use the Numenta Offering. We reserve the right to change, modify, add or remove portions of these Terms periodically. Such modifications shall be effective immediately upon posting of the modified Terms to the Numenta website. Your continued use of the Numenta Offering will mean that you accept these terms. 2. NO UNLAWFUL OR PROHIBITED USE You warrant to Numenta that you will not use the Numenta Offering, or any of the content therein, for any purpose that is unlawful or that is prohibited by these Terms. 3. LICENSE GRANT Your rights to access, download, and use the Grok Product will be subject to the terms and conditions of the software license agreement provided on the cloud service provider s site through which it is distributed. 4. YOUR CONTENT Numenta will not pre-screen or review your content, but Numenta shall have the right (but not the obligation) in its sole discretion to refuse or delete any content that it reasonably considers to violate the Terms or to be otherwise illegal. You grant Numenta the right to review your content for the purposes of debugging the Numenta Offering and for providing you with technical support. Numenta will not share your content with others without your explicit, written permission, except in the case where being required to do so by the appropriate court or government agency. 5. TERMINATION We may terminate your use of the Numenta Offering if we have reasonable belief that your use: 1) violates these Terms; or 2) abuses site resources or attempts to gain unauthorized entry to the site or site resources; or 3) we are required to do so by law, regulation, court or governing agency order. Our termination of any user s access to the Numenta Offering may be effected without notice and, on such termination, we may immediately deactivate or delete user s account and/or bar any further access to such files. Numenta shall not be liable to any Numenta user or other third party for any such termination. You may terminate your use of the Numenta Offering by stopping its use without notice to us. 6. PAYMENT The Numenta Product is delivered through a cloud service provider s marketplace. You will abide by the payment terms as detailed in that marketplace. If you do not wish to continue using and paying for the Numenta Product, you may stop using it at any time, and further charges will not accrue. We do not offer refunds for any amounts paid. 7. LINKS To the extent the Numenta website includes links to third parties, Numenta is not responsible or liable for the content of such sites. The Numenta website privacy statement is applicable only when you are on the Numenta websites. 8. SUPPORT Technical support for the Grok Product is provided by email. We will make a reasonable effort to respond to your email within 48 hours. Support inquiries are to be sent to support@numenta.com. 9. TRADEMARK INFORMATION Numenta, Grok, NuPIC, and the Numenta, Grok and NuPIC trademarks, logos and service marks are the intellectual property of Numenta, Inc. All trademarks, trade names, service marks and logos referenced herein are the property of their respective owners. 10. COPYRIGHTS If you believe that your work has been copied and is accessible in the Numenta Offering in a way that constitutes copyright infringement, you may notify us by providing our copyright agent with the following information in writing: - the electronic or physical signature of the owner of the copyright or the person authorized to act on the owner s behalf; - identification of the copyrighted work that you claim has been infringed; - identification of the material that is claimed to be infringing and information reasonably sufficient to permit Grok to locate the material; - your name, address, telephone number, and email address; - a statement by you that you have a good faith belief that the disputed use is not authorized by the copyright owner, its agent, or the law; - a statement, made under penalty of perjury, that the above information in your Notice is accurate and that you are the copyright owner or are authorized to act on the copyright owner s behalf. If Numenta receives such a claim, Numenta will investigate and report back to the complainant. Numenta reserves the right to delete such reported content or to terminate a user s account. Our designated agent to receive notification of claimed infringement under the Digital Millennium Copyright Act OF 1998 ( DMCA ) is: dmca@numenta.com 11. VIOLATIONS OF TERMS Please report any violations of the Terms to info@numenta.com. 12. PRIVACY Our Privacy Policy is located at http://numenta.com/legal/privacy/. 2016/07/22 Terms of Service","title":"Terms of Service"},{"path":"/machine-intelligence-technology/","text":"Technology Overview Technology Overview Video: Intro to our Technology (02:23) Based on a wealth of neuroscience evidence, our HTM technology is not just biologically inspired. It s biologically constrained. When applied to computers, HTM is well suited for prediction, anomaly detection, classification and ultimately sensori-motor applications. We believe this technology will be the foundation for the next wave of computing. At the core of HTM are learning algorithms that can store, learn, infer and recall high-order sequences. Unlike most other machine learning methods, HTM learns time-based patterns in unlabeled data on a continuous basis. HTM is robust to noise, and high capacity, meaning that it can learn multiple patterns simultaneously. HTM works best with data that meets the following characteristics: - Streaming data rather than batch data files - Data with time-based patterns - Many individual data sources where hand crafting separate models is impractical - Subtle patterns that can t always be seen by humans - Data for which simple techniques such as thresholds yield substantial false positives and false negatives Our technology has been tested and implemented in software, all of which is developed with best practices and suitable for deploying in commercial applications. Next: Open Source Community ","title":"Technology Overview"},{"path":"/mission-and-history/","text":"Mission &amp; History Mission & HistoryMission Video: Our Story (02:32) Numenta s mission is to be a leader in the new era of machine intelligence. We believe the brain is the best example of an intelligent system, providing a roadmap for building intelligent machines. The brain s center of intelligence, the neocortex, controls a wide range of functions using a common set of principles. Because today s computers are programmed, they can only do exactly as they are told. In stark contrast, intelligent machines continuously and automatically learn patterns in their environment without being programmed, enabling them to tackle problems in entirely new ways. Intelligent machines that learn will have an enormous beneficial impact in the coming decades. We have made significant progress in understanding the neocortex and building software based on those principles. We put all of our research and software implementations into open source and encourage others to join us in building a community. From a commercial point of view, we license our technology and intellectual property.History Numenta was established in 2005 in Redwood City, CA. Our progress can be categorized by three distinct phases: 1. Testing the HTM theory and developing first generation algorithms. During this phase, vision was a main application focus area. 2. Developing a second generation of HTM Learning algorithms with stronger biological correlation and a roadmap for future work. During this phase, we continued to explore applications, built a prediction engine, and started our open source project. 3. Researching the third generation of HTM Learning algorithms. We are currently focusing on sensorimotor integration. Next: Brain Science ","title":"Mission &amp; History"},{"path":"/newsletter/2013/10/11/announcing-grok-for-it/","text":"Announcing Grok for IT Fri, Oct 11, 2013 NewsletterAnnouncing Grok for IT Donna Dubinsky CEO NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. Over the past year, we have tested our Grok technology on a variety of enterprise applications. Customers show substantial interest in our technology, with proposed applications ranging from remote equipment maintenance to power management to web advertising optimization, and many more. Although the interest level is strong, and we conducted many tests to prove the validity of the cortical learning algorithms, we found that it was difficult for customers to deploy Grok. The barriers to deployment included having clean access to data streams as well as integrating the results into existing business processes. Because of this experience, we decided to create a more targeted solution that makes it far easier for customers to deploy Grok. This product, currently under development, will monitor IT systems, automatically figuring out whether the network is healthy or is in an anomalous state. In essence, we are bringing deep science to the problem of detecting anomalies in servers and server based applications. The first version of the product is a simple-to-deploy tool focused on customers using Amazon Web Services (AWS). We have a few openings left for our private beta program, which will start shortly. If you have a current AWS environment (small or large) and would like to participate in the private beta, please send an email to grokbeta@numenta.com. We welcome your input and your help in finalizing this exciting new product. In other news, the NuPIC open source project we created in June is off to a great start. NuPIC contains the source code to our cortical learning algorithms, the same code used in our product Grok. We are pleased with the number of contributors, the email discussions, and overall interest. We are holding our second NuPIC Hackathon in San Francisco on November 2 3. To sign up for the Hackathon, go to http://numenta.org/events/. To learn more about the open source project, visit http://numenta.org/. Thank you for your interest in Grok and in Numenta.org. We look forward to meeting some of you in our beta program or at the NuPIC Hackathon. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2013/10/11 CEO Announcing Grok for IT","title":"Announcing Grok for IT"},{"path":"/newsletter/2013/11/08/grok-at-aws-reinvent/","text":"Grok at AWS re:Invent Fri, Nov 08, 2013 NewsletterGrok at AWS re:Invent Jeff Hawkins Founder NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. As we wrote to you in October, we have developed an exciting product based on our Cortical Learning Algorithms (CLA). The product, called Grok, is targeted towards Amazon Web Services (AWS) customers. We will be showing it publicly for the first time at the Amazon re:Invent Conference next week in Las Vegas. This may be of interest to you for two reasons. - This is the first commercial application of the cortical learning models we have developed over the past few years. It is a landmark event for us and a step on the path towards machine intelligence. - Some of you have expressed interest in using Grok. If you are attending re:Invent, we hope you will come by booth #1200, say hello, and see how we applied advanced cortical modeling to transform anomaly detection in computer servers. Because of the capabilities of the CLA, Grok automates the process of modeling normal behavior and identifying unusual behavior in Amazon instances. The patterns found by Grok go well beyond those found by static or dynamic thresholds. In addition, Grok provides a mobile client that enables a unique ability to monitor the health of your network anytime, anywhere. It is a remarkable product and the first showcase for the CLA. We continue to recruit participants in our private beta program as well, so let us know at grokbeta@numenta.com if you are interested in using Grok. Finally, last weekend in San Francisco we held our second NuPIC Hackathon for the open source community built around the CLA. It was a great success. Two big themes at this event were to apply the CLA to robotics and natural language processing. Matt Taylor, the NuPIC community flag-bearer, put together this summary. We hope to see some of you at re:Invent, and look forward to getting your feedback on Grok. We are excited about approaching the first commercial release of a product that is based on the CLA. Jeff Hawkins Founder All Newsletter Posts Jeff Hawkins 2013/11/08 Founder Grok at AWS re:Invent","title":"Grok at AWS re:Invent"},{"path":"/newsletter/2014/02/04/grok-soft-launch/","text":"Announcing Grok 1.0 Soft Launch Tue, Feb 04, 2014 NewsletterAnnouncing Grok 1.0 Soft Launch Donna Dubinsky CEO NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. I am pleased to share with our newsletter subscribers the availability of Grok 1.0 in soft launch . Grok monitors complex networks running on AWS and is the first commercial application of our groundbreaking Hierarchical Temporal Memory (HTM). Grok enables IT professionals to easily spot unusual activity, thus staying ahead of problems and preventing downtime. Grok includes the following features: - Very easy configuration and set-up - Using the CLA, automatically models each metric to determine normal patterns - Automatically identifies and ranks unusual patterns - Continuously learns new patterns as environments evolve - Does not require any manual threshold setting - Notifies the user when something curious is happening - Displays output graphically on a mobile Android device Using Grok will enable IT professionals to get insights to their system performance by providing an early warning that something has changed. Since everything happens automatically, using Grok can reduce costs of system monitoring by requiring less work from engineers. And, given the mobile interface, IT professionals can get this information anytime, anywhere. Grok 1.0 is available here: http://grokstream.com/ We plan to formally announce and exhibit at the AWS Summit on March 25-26 at the Moscone Center in San Francisco; please stop by and say hello. And be sure to check out our updated website. I m also happy to tell you that in addition to working on the Grok product release, we continue to push our biologically-inspired algorithms forward. We ve made some important progress recently and look forward to sharing it with you over the coming year. Our open source community, NuPIC, is growing and actively contributing to the advancement of the science. Thank you for your support and your interest. We hope you ll try Grok and give us your feedback. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2014/02/04 CEO Announcing Grok 1.0 Soft Launch","title":"Announcing Grok 1.0 Soft Launch"},{"path":"/newsletter/2014/03/25/announcing-grok-for-it-analytics-on-aws/","text":"Announcing Grok for IT Analytics on AWS Tue, Mar 25, 2014 NewsletterAnnouncing Grok for IT Analytics on AWS Donna Dubinsky CEO NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. Today is an important day for Numenta. We are pleased to announce the general availability of Grok. We will be showcasing Grok at the AWS Summit at the San Francisco Moscone Convention Center on March 26th. If you are attending, please join us in booth 100 to see a demo - and experience our breakthrough technology for anomaly detection. As we mentioned in our February newsletter, Grok for IT Analytics monitors servers running on AWS and is the first commercial application of our groundbreaking Cortical Learning Algorithm (CLA). Grok enables IT professionals to spot anomalous system behavior in order to stay ahead of problems and prevent business downtime, and to substantially reduce annoying false positives generated by threshold based systems. What makes us different is the powerful science behind our technology, enabling Grok to identify unusual patterns that many other monitoring tools may miss and to automatically learn changes in its environment without human intervention. We encourage you to read our new whitepaper [The Science of Anomaly Detection](/assets/pdf/whitepapers/Numenta White Paper - Science of Anomaly Detection.pdf) for details and examples of how Grok does its magic. Since our soft launch in February, our team has added valuable new features based on customer feedback: - Monitoring of AWS Auto-Scaling Groups - Monitoring of logically-related server clusters - Improved user-controlled notifications - Addition of a command line interface tool - Improved mobile interface on Android devices - Ability to ingest any streaming data source via custom metrics If you are an IT professional or just wanted to explore Grok, we have several options to make it easy to get started. Grok is available here: http://grokstream.com We also invite you to provide your feedback. Be sure to send us details on anomalies that Grok found that you would otherwise not have seen! And let us know about features you d like to have us implement in order to make Grok more useful. To support our launch, we have upgraded our website and made a number of helpful resources available. Thanks for your continued interest and support. We look forward to hearing how you like Grok. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2014/03/25 CEO Announcing Grok for IT Analytics on AWS","title":"Announcing Grok for IT Analytics on AWS"},{"path":"/newsletter/2014/06/10/progress-report-june-2014/","text":"Progress Report June 2014 Newsletter Tue, Jun 10, 2014 NewsletterProgress Report June 2014 Newsletter Donna Dubinsky CEO I m writing today to give you a progress report from Numenta. We have continued to make strides towards our mission of being a catalyst for machine intelligence. NuPIC Open Source Community Solid Growth in First Year One year ago we created the NuPIC open source project to support scientists and developers who are interested in machine intelligence based on neocortical principles. Since our launch, we ve made great progress in our goal of building a vibrant community, now with more than 800 subscribers to the NuPIC mailing list and nearly 100 contributors. We have recently concluded our third NuPIC Hackathon; the 32-hour weekend event drew 76 developers and yielded 14 demos ranging from simple games to complex word associations based on CEPT, the Cortical Engine for Processing Text. NuPIC Community Flag-Bearer, Matt Taylor, summarized it well, saying We ve come a long way since we started with 90,000 lines of code on Github and held our first Hackathon with 20 people. Today, I am happy to report we have an active community and a pattern of steady growth over the past year. If you are interested in biologically-inspired machine intelligence, there is no better place to be. Grok for IT Analytics on AWS Showcasing the Power of the CLA Grok, the first commercial product using Numenta s Cortical Learning Algorithm (CLA), is marking its first quarter in market. Grok learns patterns from its temporal data stream, makes predictions, and identifies anomalies. Simultaneously with the product s release, Numenta issued a Science of Anomaly Detection Whitepaper that explains how it applied the science of the CLA to the technology of anomaly detection. Here s what some of our first customers have to say: Having Grok monitor AWS CloudWatch to highlight unusual patterns is extremely useful. It highlighted leading indicators of problems in my AWS environment, which helped me prevent downtime. Greg Krill, Data Center Architect, Founder and Director, EdgeSense Grok is unique in that it delivers at-a-glance insight on top of our existing metrics. As it learns automatically, we spend less time maintaining it and more time working on our technology, Chris Alexander, SysAdmin and Engineer, Import IO If you d like to see Grok, we will be exhibiting at the AWS Summit in NYC on July 10th. Grok is also available on the AWS Marketplace with no license fee. We are recruiting for two positions in our marketing department, one for a product manager and one for a marketing manager [URL]. Help us find outstanding people by sharing this information with your friends and colleagues! We look forward to sharing more exciting news over the summer as we continue to drive new innovations with our technology. Thanks for your continued interest and support. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2014/06/10 CEO Progress Report June 2014 Newsletter","title":"Progress Report June 2014 Newsletter"},{"path":"/newsletter/2014/08/19/machine-intelligence-applications-summer-2014/","text":"Machine Intelligence Applications 2014 Tue, Aug 19, 2014 NewsletterMachine Intelligence Applications 2014 Donna Dubinsky CEO NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. We ve had a busy summer at Numenta. Since the launch of our first product, Grok for IT Analytics on Amazon Web Services (AWS), we ve created a variety of demonstration applications to showcase the breadth of the underlying Hierarchical Temporal Memory (HTM) technology. We ve also restructured our web site to highlight these new applications. First, let me give you an update on our product, Grok. We recently released version 1.5 which incorporates a great new web charting feature. In addition, we decided to eliminate the paid version of Grok in order to make it super easy for customers to try and to deploy Grok. If you are running an AWS installation but haven t tried out Grok, you can do so here. Then, in addition to Grok, we ve created a group of demonstration applications to show the potential use of our core technology in a variety of areas. We ve published white papers on two of the demonstrations: - Geospatial Tracking: using 2D or 3D speed and location data, learn travel patterns and detect anomalies in objects or people moving through the world - Rogue Behavior Detection: Model human behavioral patterns to highlight anomalies in employee actions such as financial trading patterns, computer and device usage, and internal system access. An additional demonstration application looks at anomalies in stock volume tracking. We are in our initial exploration of this application, but you can read more about it in this blog entry. Finally, we are doing some very exciting research with our partner Cortical IO on using HTM to predict and classify language using semantic encoding. We are getting more visibility for our progress as we start to showcase these applications. You may want to read Dean Takahashi of VentureBeat s article here. On August 20, Subutai Ahmad, our VP of Research will present Understanding Cortical Principles and Building Intelligent Machines at the Cognitive Computing Forum in San Jose. If you re interested, register using the discount code NUMENTA. I d like to add a welcome to Celeste Baranski, who has joined us as VP Engineering, taking over the daily operations of our engineering group, enabling Subutai to dedicate himself to research and writing. Finally, we re happy to celebrate the first anniversary of the creation of our NuPIC open source project. NuPIC interest has grown steadily, and we are pleased to see the strength and commitment building in this community. We will continue to update you as we build the demonstration applications into full-featured applications and as our research efforts continue. Thank you for your ongoing interest in Numenta. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2014/08/19 CEO Machine Intelligence Applications 2014","title":"Machine Intelligence Applications 2014"},{"path":"/newsletter/2014/09/16/fall-workshop-and-hackathon/","text":"Opportunities to Learn About and Try Numenta Technology - Fall Workshop and Hackathon Tue, Sep 16, 2014 NewsletterOpportunities to Learn About and Try Numenta Technology - Fall Workshop and Hackathon Donna Dubinsky CEO I m writing to let you know that we have two upcoming opportunities to learn about and try our technology: Numenta Training Workshop - Friday, Oct 17 2014, 12pm - 6pm - Redwood City, CA https://www.eventbrite.com/e/numenta-training-workshop-registration-12898835765 This half-day workshop for developers will review Numenta theory, technology and applications. Content will consist of presentations about HTM theory, including some detailed implementation topics, and will be technical in nature. The workshop will be followed by a networking reception. If you have been interested in our work and have wanted to get a thorough grounding in the subject matter, or if you already are active in our community but would like an update on our progress, attending this workshop is a great idea. Our capacity is limited, and early-bird pricing is available through September 26th, so we encourage you to register soon. Numenta Fall NuPIC Hackathon - Saturday, Oct 18 2014 - Sunday, Oct 19 2014 - San Jose, CA http://www.meetup.com/numenta/events/202402962/ The NuPIC fall hackathon follows our workshop and will be a 32-hour all-weekend hackathon. We ll start with a kickoff presentation from the NuPIC team, including a few words from Jeff Hawkins. During the event, we ll help you get NuPIC installed and provide several informational sessions about NuPIC. The event will end with demonstrations of hacks that attendees have created during the event. (See example of past demos here). The hackathon is appropriate both for experienced NuPIC developers as well as for new developers. I hope you ve had a chance to check out our updated web site, where we have released some new whitepapers, including an expanded version of The Science of Anomaly Detection. I look forward to seeing many of you at the Workshop and/or the Hackathon. Thank you for your ongoing interest in Numenta. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2014/09/16 CEO Opportunities to Learn About and Try Numenta Technology - Fall Workshop and Hackathon","title":"Opportunities to Learn About and Try Numenta Technology - Fall Workshop and Hackathon"},{"path":"/newsletter/2014/11/11/grok-1-6-showcasing-at-aws-re-invent-las-vegas-2014/","text":"Grok 1.6 Released - Showcasing at AWS ReInvent in Las Vegas, Nov 11-14 Tue, Nov 11, 2014 NewsletterGrok 1.6 Released - Showcasing at AWS ReInvent in Las Vegas, Nov 11-14 Donna Dubinsky CEO NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. Newsletter - November 11, 2014 Grok 1.6 Released - Showcasing at AWS Re:invent in Las Vegas, Nov 11-14 We are pleased to report that Numenta has released version 1.6 of Grok for IT Analytics, which is available for no license charge on the AWS Marketplace. This version offers several new important features: - Annotation of data streams, which allows sharing of information and collaboration among users - Increased support for additional data formats - Enhanced performance Based on Numenta s breakthrough Hierarchical Temporal Memory technology, Grok monitors servers running on AWS and enables complex pattern detection, automatic model building, and continuous learning. Grok output is displayed on a constantly updated mobile device, enabling IT professionals to assess the health of their systems anytime, anywhere. We will be showcasing this new version of Grok at the AWS re:Invent conference in Las Vegas, November 11-14. If you are attending, please visit us and see Grok 1.6 in action at Booth #648. I m also happy to announce that the videos from our Numenta Training Workshop held Friday, October 17th, are now available on our web site. You can access these videos on the Resources section of our website. This new material offers a great way to get up to speed on our work. Please check back on this page over the coming months as we plan to add more content shortly. Thank you for your ongoing interest in Numenta. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2014/11/11 CEO Grok 1.6 Released - Showcasing at AWS ReInvent in Las Vegas, Nov 11-14","title":"Grok 1.6 Released - Showcasing at AWS ReInvent in Las Vegas, Nov 11-14"},{"path":"/newsletter/2015/01/26/welcome-to-2015/","text":"Welcome to 2015! Mon, Jan 26, 2015 NewsletterWelcome to 2015! Donna Dubinsky CEO Newsletter - January 26, 2015 Welcome to 2015! As a fun and educational kick-off to the year, we are offering our second Super Bowl sparse football pool. Entering the pool is free, and prizes are offered for the top five winners (note that because of legal constraints, those people under 18 or outside of the U.S. cannot win prizes but they still can play for the glory of winning!). Participating is a fun way to learn more about Sparse Distributed Representations. Subutai explains here the details of the pool: In early January, we delivered NuPIC version 0.1, our first formal release of NuPIC. Says Matt Taylor, our NuPIC flag-bearer, With the NuPIC 0.1 release, most OS X and Linux users won t need to compile from source code to install. This makes the installation process much easier for those wanting to use NuPIC as a python project. In other news, we look forward to an exciting year at Numenta. We are beginning the hard work of publishing more information on our algorithms, including submissions for peer reviewed papers. We are progressing in the science with a lot of focus on sensory-motor integration. For those interested in the details, the concepts are often discussed in the HTM Community and in NuPIC office hours. We are continuing to support our product, Grok, and have an additional demonstration application in the works to announce later this year. We also will be speaking or exhibiting at a number of events this year, including: - Strata + Hadoop World, 2/20, Subutai (VP of Research) will give a talk on streaming analytics We are also planning a Spring NuPIC Hackathon, which we expect to be on the U.S. East Coast. Be sure to follow us on Twitter and check our events page as more speaking appearances or events are announced. You might enjoy seeing a short video featuring Jeff that describes our mission. In an effort to communicate more about our work, you can expect to see more material like this over the coming year. Best wishes for a happy new year! Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/01/26 CEO Welcome to 2015!","title":"Welcome to 2015!"},{"path":"/newsletter/2015/03/12/numenta-newsletter-mar-2015/","text":"Numenta Newsletter March 2015 Thu, Mar 12, 2015 NewsletterNumenta Newsletter March 2015 Donna Dubinsky CEO Numenta Newsletter March 12, 2015 As part of the community interested in machine intelligence, you may be following the current public debate about whether artificial intelligence should be feared or encouraged. Jeff Hawkins recently wrote a thoughtful opinion piece on this subject: The Terminator Is Not Coming. The Future Will Thank Us. I hope you will have time to read Jeff s piece and, if you find it worth sharing, to promote it within your social network. We feel that the future of machine intelligence is very exciting, and would welcome your help in spreading the word. We have confirmed the date and location for our next NuPIC hackathon: May 29-30 in New York City. The 32-hour all-weekend event is our first east coast hackathon. We hope that the New York location will facilitate attendance from the east coast as well as from international locations. - RSVP on our event page - Saturday, May 29 2015 Sunday, May 30 2015 - Cornell Tech Campus in NYC Congratulations to the winners of our Sparse Football Pool (including me!)! Learn about the connection between football, HTM learning algorithms and the brain in our blog post. We also have two additional short videos about Numenta that I would like to share: Intro to Technology and Intro to Applications. These videos are a quick way to learn more about Numenta s machine intelligence technology and its broad applicability, and are especially appropriate as introductory videos for those new to our work. Again, we hope you will share these videos, along with Jeff s overview video, with others who want to learn about Numenta. Thank your for your ongoing interest in Numenta. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/03/12 CEO Numenta Newsletter March 2015","title":"Numenta Newsletter March 2015"},{"path":"/newsletter/2015/04/29/numenta-newsletter-apr-2015/","text":"Numenta Newsletter April 2015 Wed, Apr 29, 2015 NewsletterNumenta Newsletter April 2015 Donna Dubinsky CEO Numenta Newsletter April 29, 2015 Dear Numenta newsletter subscriber: I have a lot of exciting news to share. Rather than making the newsletter overly long, I ve provided links to get more information on any of these topics. We re pleased to let you know about the establishment of a Cortical Learning Center at IBM, which is actively experimenting with Numenta s technology. You can view what Winfried Wilcke, a senior IBM researcher, has to say about his work. In the publications arena, we have posted an important paper on the mathematical properties of sparse distributed representations. You can read it here. We also have a hackathon coming up. For the first time, we are coming to the east coast for this hackathon: May 30-31 in New York City. Many of our Numenta engineers will be attending, as well as Jeff Hawkins and Subutai Ahmad. There are still spaces left! We have another project brewing called the Numenta Anomaly Benchmark. We have found it difficult to benchmark our algorithms given how few benchmarks exist with streaming data. Consequently we have decided to create an open source benchmark ourselves in the hope that it becomes an industry standard for real-time anomaly detection. If you are interested in this project and, specifically, if you have some streaming data sets that you can share, please contact us at nab@numenta.org. We plan to have the Numenta Anomaly Benchmark available around the end of the summer. We ve had a lot of positive reactions to Jeff s article on the reality of AI dangers, so be sure to view some of the commentary: - What Really Scares Tech Leaders about Artificial Intelligence - Graph Theory Helps To Decode The AI Fears of Tech Leaders Lastly, we have an opening in marketing at Numenta. If HTM and machine intelligence is a passion of yours, and you have a strong marketing communications background, please consider applying for our position. We are excited about the momentum growing behind HTM technology and hope you ll have a chance to review some of these developments. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/04/29 CEO Numenta Newsletter April 2015","title":"Numenta Newsletter April 2015"},{"path":"/newsletter/2015/05/14/announcing-relationship-with-cortical-io/","text":"May 2015 Newsletter: Cortical.io Relationship Thu, May 14, 2015 NewsletterMay 2015 Newsletter: Cortical.io Relationship Donna Dubinsky CEO Numenta Newsletter May 14, 2015 Dear Numenta newsletter subscriber: I am excited to let you know that we recently announced a relationship with Cortical.io, an innovative company based in Austria that is working on the next generation of natural language processing: language intelligence. Cortical.io has created a technology that can translate text into sparse distributed representations, called Semantic Folding. By using Cortical.io s Semantic Folding technology in combination with HTM, we plan to tackle problems in language that have frustrated computer scientists for many years. To learn more about Cortical.io, you can read our press release, view the Cortical.io website, or try the Cortical.io API at AWS. I also wanted to draw your attention to a new paper about HTM written by Sebastian Billaudelle, with Subutai Ahmad, our VP Research. As part of the European based Human Brain Project, Sebastian spent several months at Numenta porting HTM to the Heidelberg Neuromorphic Computing Platform, with positive results. Sebastian implemented HTM using spiking neurons, which are complex models often used by neuroscientists to reproduce actual biophysical characteristics of neurons. You can read about his work here. We have several great projects under development and look forward to sharing more with you over the coming months. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/05/14 CEO May 2015 Newsletter: Cortical.io Relationship","title":"May 2015 Newsletter: Cortical.io Relationship"},{"path":"/newsletter/2015/06/09/numenta-open-sourcing-two-htm-products/","text":"June 2015 Newsletter: Numenta Releasing Two Complete HTM Products into Open Source Tue, Jun 09, 2015 NewsletterJune 2015 Newsletter: Numenta Releasing Two Complete HTM Products into Open Source Donna Dubinsky CEO Numenta Newsletter June 09, 2015 Dear Numenta newsletter subscriber: I m writing to update you on exciting news for our open source project, NuPIC. In order to encourage our developers and to facilitate the creation of applications, we have decided to release substantially more of our technology into open source. To that end, we just added to the code base two complete products: Grok for IT Analytics and HTM for Stocks (an example application that will be made available to end users shortly). The released code for these products includes the HTM Engine as well as two different Android applications. The HTM Engine runs multiple anomaly models in an easy, scalable way, allowing a single server to manage and run thousands of HTM models. The Android applications act as a client to the HTM engine, pulling in the data to display it in a human-understandable format. We are developing tutorials that will help developers come up to speed on this new technology. This source code has been open-sourced under the AGPLv3.0 license*. You can find all the code on GitHub. We hope that developers will find this source code beneficial as example applications of NuPIC. If you are interested in creating a commercial application using this code, you may do so in accordance with the terms of the AGPLv3*, or may write us to request a separate, commercial license if you prefer different terms. Commercial licenses are handled on a case-by-case basis. For more information on our open source licensing, see: License, Patent Position, Commercial Licenses. We invite you to join our growing open source community. *This content has been updated to reflect our new AGPL license. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/06/09 CEO June 2015 Newsletter: Numenta Releasing Two Complete HTM Products into Open Source","title":"June 2015 Newsletter: Numenta Releasing Two Complete HTM Products into Open Source"},{"path":"/newsletter/2015/07/02/announcing-open-source-htm-app-grok-for-stocks/","text":"July 2015 Newsletter: Announcing HTM for Stocks - Open Source Example HTM App Thu, Jul 02, 2015 NewsletterJuly 2015 Newsletter: Announcing HTM for Stocks - Open Source Example HTM App Donna Dubinsky CEO Numenta Newsletter July 02, 2015 Dear Numenta newsletter subscriber: Over the last two years, we have created a series of example applications that illustrate the capabilities of HTM. Grok for IT Analytics, available for download on the Amazon Web Services Marketplace, uses HTM to detect anomalies in AWS server metrics. We have published source code for several other example applications that use HTM to detect anomalies in human behavior, and in GPS data. But up until now it hasn t been easy for an individual to get a sense of how HTM-based anomaly detection works; you either need to bring up an AWS server instance, or put in a reasonable amount of software development effort. So we have created a new example application, called HTM for Stocks, which makes it much easier for you to experience how HTM detects anomalies. HTM for Stocks is available for free here: Download HTM for Stocks. At this point, the application is available only for an Android mobile device. HTM for Stocks applies HTM modeling and anomaly detection to 200 large capitalization public companies. The application automatically models three data streams for each stock: stock volume, stock price, and Twitter volume. It figures out normal for each of these data streams for each company, and then lets you know if something abnormal has occurred. Here is what we hope you will notice when using HTM for Stocks: - HTM enables automatic modeling of many models here, we are creating 600 separate models (3 for each of 200 companies). No human intervention is required to adjust parameters or tune models. - HTM models learn continuously, with each new data point. If a company changes its fundamentals, taking its stock volume to a new level, at first it will show an anomaly, but after a short period, it will learn the new normal . - The models are ranked by the most anomalous to the least anomalous. If you scroll down, you will note that many of the stocks show no anomalies. This ranking of anomalies allows you to focus on the companies that are the most different from the norm. Some of the anomalies detected by HTM for Stocks may appear obvious but others are subtle and not easily detected by a human. For example, if you watch stock volumes, you will see that there often is a spike in the beginning and at the end of the trading day. It will notice if those spikes continue longer than normal for that particular stock. Such examples demonstrate the power of finding temporal patterns When you see an anomaly, it s very informative to look at the Twitter stream for the corresponding time frame. There, you often will be able to quickly determine the reason for the anomaly, such as an earnings announcement, a takeover bid, a lawsuit, or a rapidly growing interest in something the company did. In keeping with our focus as a technology provider, we do not intend to build HTM for Stocks into a full commercial application, and so we have provided the source code for HTM for Stocks alongside our NuPIC open source project at https://github.com/numenta/numenta-apps, available under a AGPL v3 license*. Developers may find that HTM for Stocks code can be used to create derivative products that track other data streams. We also welcome partners who are interested in a commercial license to the HTM for Stocks code; in this case please write to sales@numenta.com. We hope that you will enjoy using HTM for Stocks. We welcome your feedback at feedback@numenta.com. *This content has been updated to reflect our new AGPL license. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/07/02 CEO July 2015 Newsletter: Announcing HTM for Stocks - Open Source Example HTM App","title":"July 2015 Newsletter: Announcing HTM for Stocks - Open Source Example HTM App"},{"path":"/newsletter/2015/09/01/partnership-between-numenta-and-avik-partners-on-grok-for-it-analytics/","text":"September 2015 Newsletter: Partnership between Numenta and Avik Partners on Grok for IT Analytics Tue, Sep 01, 2015 NewsletterSeptember 2015 Newsletter: Partnership between Numenta and Avik Partners on Grok for IT Analytics Donna Dubinsky CEO Numenta Newsletter - Sep 01, 2015 Dear Numenta newsletter subscriber: I am excited to tell you about a new partnership between Numenta and Avik Partners, an IT services and advanced analytics company. Before I tell you more about Avik, I want to remind you of our strategy for deploying HTM technology. Over the past few years we have made excellent progress in turning HTM cortical theory into a valuable technology, first for streaming analytics, but ultimately as a core component of machine intelligence. In order to demonstrate how HTM technology can be used, we created several example applications. Our plan is to partner with applications developers to bring commercial solutions to the market while we focus on developing the science and technology. Earlier this year we announced our first such relationship with Cortical.io, a company using HTM technology for natural language applications. Avik Partners is our second commercial partnership. Casey Kindiger, CEO of Avik, is a proven entrepreneur with deep experience in IT and developer operations. Casey became intrigued with our Grok for IT Analytics example application, recognizing the substantial commercial potential for our advanced anomaly detection capability in the IT environment, and approached us about a license. Our relationship with Avik is structured as a strategic partnership. Avik will assume our Grok for IT product (including the name Grok), enhance the application with the many features that have been requested, and market it to enterprise IT organizations. Avik will be doing business on the http://grokstream.com website, where you can sign up to receive information when the product is available. We expect to complete the transition of the Grok for IT Analytics product to Avik within 30 days. As part of the license, Numenta has taken a minority ownership position in Avik. We believe that Avik is an ideal partner to apply HTM technology to solve major problems in complex IT organizations. Given the breadth of potential HTM applications, we are excited about our discussions with several other potential licensees who want to apply HTM technology to a wide variety of application domains. Over time, we hope to establish a constellation of partners building intelligent applications using HTM technology. In order to facilitate consideration of a license, we have created several standard license options. We realize that these standard licenses won t fit every situation, so we also offer custom licenses. We have just published a new license guide with details. If you are interested in becoming a licensee, please review this document, and feel free to write to us at sales@numenta.com. Please join me in congratulating Casey and Avik Partners. We look forward to working together to bring machine intelligence to improve management of IT infrastructure. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/09/01 CEO September 2015 Newsletter: Partnership between Numenta and Avik Partners on Grok for IT Analytics","title":"September 2015 Newsletter: Partnership between Numenta and Avik Partners on Grok for IT Analytics"},{"path":"/newsletter/2015/10/01/numenta-anomaly-benchmark-and-numenta-htm-challenge/","text":"Numenta Anomaly Benchmark (NAB), and Numenta HTM Challenge Thu, Oct 01, 2015 NewsletterNumenta Anomaly Benchmark (NAB), and Numenta HTM Challenge Donna Dubinsky CEO Numenta Newsletter October 2015 Numenta Anomaly Benchmark (NAB), and Numenta HTM Challenge To Numenta newsletter subscribers: I m writing with a few exciting updates from Numenta. To start with, I m pleased to announce that we have a paper accepted on the Numenta Anomaly Benchmark (NAB). I ve written to you about the development of NAB in the past. NAB is essentially two things. First, it consists of over 50 streaming data files with anomalies that are marked for ground truth. These files are a combination of real-world data sets along with some simulated data sets. Second, there is a scoring mechanism that is designed for streaming data. Numenta s HTM algorithms do a great job at finding temporal structure, learning continuously, and detecting anomalies early. These are valuable properties for real-time streaming applications but benchmarks designed for batch data don t incorporate them. For example, traditional benchmarks do not give credit for finding an anomaly sooner rather than later. Our development of NAB is an effort to create such a benchmark. We will be releasing NAB into open source such that the community can add new data sets, propose different scoring mechanisms, and test/compare other algorithms with HTM. We hope that the developers in the community will get behind NAB and enable a robust comparison of our anomaly detection with other techniques. For more information on NAB, go here. We will be presenting NAB at two conferences (MLconf SF on November 13 in San Francisco, and the IEEE Conference on Machine Learning and Applications on December 9-11 in Miami), so if you are in the vicinity, we hope you will be able to attend. Of course, once the paper is published, we will send you the link. My second topic is an update from the NuPIC community. We recently announced the HTM Challenge. The idea of the HTM Challenge is to provide a structure to encourage members of our open source community to create HTM sample applications. And, to add an extra incentive, we re offering cash prizes of $3000 for first place, $2000 for second place and $1000 for third place, along with some fun door prizes. The Numenta HTM Challenge is an online contest open for submissions now and running until November 14th. Participants propose ideas for real-world applications of HTM technology and submit them for approval before starting work. We will check that the problem being solved is applicable to HTM, and that the data being analyzed is a good fit for HTM. Once a project has been approved, hackers have until November 6th to work on it and submit a demo video for judging. This Challenge can be completed entirely online, but we encourage you to try to attend the onsite event that culminates the Challenge on Saturday, November 14 in Redwood City, California. At this event, all demonstration videos will be viewed by a judging panel and a live audience. Judges will get a chance to comment and ask questions to submission authors (either live or over the phone). At the end of the event, we ll announce the winners and cash prizes will be awarded. In addition to judging, there will also be at least two educational sessions by Numenta team members Subutai Ahmad and Jeff Hawkins. They will be talking about the history and evolution of HTM algorithms, the Numenta Anomaly Benchmark, and some details about new algorithm development. You don t have to participate in the Challenge to attend the onsite event. Maybe you just want to come see the latest presentations from Numenta or watch the Challenge demonstration judging. That s great! We welcome you to mingle with us HTM enthusiasts. Register here. And as long as you ll be in the area, there is a community event being planned on Friday, November 13, the day before the onsite event. I hope you ll come meet the rest of the HTM community. This event is run by the NuPIC community, for the NuPIC community. A schedule is in the works. RSVP here. Stay tuned for more information on NAB and on the HTM Challenge. I ll update you as both projects develop. Lastly, let me remind you that Avik Partners has now taken over the Grok for IT product. They have enhanced the product and are now in beta. If you want to experience breakthrough anomaly detection on IT infrastructure, register to give it a try. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/10/01 CEO Numenta Anomaly Benchmark (NAB), and Numenta HTM Challenge","title":"Numenta Anomaly Benchmark (NAB), and Numenta HTM Challenge"},{"path":"/newsletter/2015/11/10/numenta-anomaly-benchmark-nab-open-source-with-white-paper/","text":"Numenta Anomaly Benchmark (NAB) is Released, Open Source with White Paper Tue, Nov 10, 2015 NewsletterNumenta Anomaly Benchmark (NAB) is Released, Open Source with White Paper Donna Dubinsky CEO Numenta Newsletter November 2015 Numenta Anomaly Benchmark (NAB) is Released, Open Source with White Paper To Numenta newsletter subscribers: As I wrote you last month, we have been working hard on creating NAB, the Numenta Anomaly Benchmark, to test the HTM learning algorithms and enable comparison with other algorithms. Now, it s here! We have found the need to create a benchmark for many reasons, including: - We sought a benchmark that incorporated time series data, i.e. that gives credit if you find an anomaly earlier rather than later. - We wanted a benchmark that incorporated learning if something about the situation changes, and there is a new normal , does the algorithm keep finding anomalies (false positives), or does it automatically adjust? - We wanted real-world data files that have labeled anomalies . did a machine fail? Was it taken off line? Knowing ground truth is important to evaluate whether an algorithm correctly identifies an anomaly. - We wanted an open dataset and code in order for a benchmark to be accepted by the community, it must be accessible to everyone. - We saw the need for a new way of scoring. Scoring can be tricky because you need to think through questions such as: if you see the anomaly TOO far in advance, perhaps it is not related, and you didn t really spot it . how far in advance would that be? We are now pleased to announce that the Numenta Anomaly Benchmark (NAB) is released. You can read the technical paper here. The paper describes our data files, our scoring mechanism, and the test results of HTM algorithms along with other, publicly available anomaly detection algorithms. And, if you want to have a look at the code yourself, it is all in open source. You can see it here. For those readers less interested in technical details, we have created a more business focused paper, which you can download here. Our hope is that we can build a community around NAB. We d like to collect additional labeled data files that can be used for future versions. We expect that others will test their algorithms using our data files and scoring, and compare and publish the results. Since it is open source, companies can test their internal algorithms without sharing the results as well, although we hope that they will. We have received positive feedback from the research community so far, and we are confident that NAB will grow over time into a very useful tool. As a reminder, we will be presenting NAB at two conferences (MLconf SF on November 13 in San Francisco, and the IEEE Conference on Machine Learning and Applications on December 9-11 in Miami), so if you are in the vicinity, we hope you will be able to attend. I m happy to share a couple updates from our strategic partners: Avik Partners and Cortical.io. Avik Partners has had a successful beta for Grok for IT and they re getting ready to launch Grok 2.0. Cortical.io recently announced its latest venture capital round of $1.8M and the opening of its San Francisco office. We re excited to see their progress in next generation natural language processing. Lastly, for any of you that are in the Bay Area, we d love to see you at our HTM Challenge event this weekend. If you can t attend in person, you can still help choose the winner. Public voting for the 12 applications is now open. Read this blog post to learn more and cast your vote: http://numenta.org/blog/2015/11/09/vote-for-the-best-htm-challenge-submissions.html Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/11/10 CEO Numenta Anomaly Benchmark (NAB) is Released, Open Source with White Paper","title":"Numenta Anomaly Benchmark (NAB) is Released, Open Source with White Paper"},{"path":"/newsletter/2015/11/17/why-neurons-have-thousands-of-synapses-a-theory-of-sequence-memory/","text":"Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex Tue, Nov 17, 2015 NewsletterWhy Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex Donna Dubinsky CEO Numenta Newsletter November 17, 2015 Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex Hello Numenta newsletter subscribers! November is shaping up to be a busy and exciting month for Numenta. Earlier this month, I wrote you about the release of our Numenta Anomaly Benchmark (NAB). Today I m pleased to share more good news. Numenta founders Jeff Hawkins and Subutai Ahmad have written a paper that we believe will become a seminal work in the field of biological and machine intelligence. It is titled, Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex. We posted the paper to an academic archive a couple of weeks ago. This makes it available while it is undergoing the peer review process. MIT Technology Review noticed and wrote a thoughtful article about the paper that explains the concepts and their importance in a very understandable way. We thought we d share both the MIT Technology Review article and our paper. If you are interested in Numenta, brain theory, and machine intelligence I think you will be interested in reading them. MIT Technology Review article: http://www.technologyreview.com/view/543486/single-artificial-neuron-taught-to-recognize-hundreds-of-patterns/ Numenta paper: http://arxiv.org/abs/1511.00083 Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2015/11/17 CEO Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex","title":"Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex"},{"path":"/newsletter/2016/01/07/year-in-review-numenta-2015/","text":"Year in Review for Numenta 2015 Thu, Jan 07, 2016 NewsletterYear in Review for Numenta 2015 Donna Dubinsky CEO Numenta Newsletter January 07, 2016 As we look forward to a bright 2016 here at Numenta, I thought I d pause and review the highlights of 2015. From advancing our research to expanding our community, we had many accomplishments that laid the groundwork for significant progress going forward. I d like to share four highlights: Highlight #1 In 2015, we signed up two key strategic partners: Cortical.io and Avik Partners. In May, we announced our Cortical.io partnership, which focuses on advancing natural language processing (NLP). We believe that the combination of our HTM technology and Cortical s Semantic Folding technology provides new possibilities to understanding text. Co-founder Francisco Webber has been a long-time supporter of Numenta. We look forward to continued collaboration with him and his team. In August, we announced our partnership with Avik Partners, an IT services and advanced analytics startup to whom we transferred our Grok application. In a short time, Avik CEO Casey Kindiger launched a commercial application to use Grok to monitor IT infrastructure. This partnership is a great example of our technology transfer business model where other companies complete and commercialize our example applications. We can t wait to see exciting results from Cortical.io and Avik Partners, and I hope to share news of additional partnerships with you in the coming year. Highlight #2 We also released the Numenta Anomaly Benchmark (NAB), which was two years in the making. We believe NAB offers the definitive way to assess the performance of algorithms for detecting anomalies in streaming data. We presented NAB v1.0 at two conferences and continue to get positive feedback supporting the need for this benchmark. The launch was just the beginning for NAB. We are actively working to collect additional data sources and publish additional algorithm results to incorporate in the next version. Stay tuned for details on a NAB competition we are running this year in conjunction with the IEEE World Congress on Computational Intelligence. Highlight #3 This year also was a great year for our growing NuPIC community, which received a Top 3 ranking in a KDNuggets report on the Top 20 Python Machine Learning Open Source Projects. We increased the number of NuPIC followers by 750, put more of our technology into open source, and had two hackathons that demonstrated the broad applicability of HTM applications. I encourage you to view the videos from our most recent hackathon. Highlight #4 Perhaps one of the most exciting achievements of 2015 was the progress toward a goal that we set at the beginning of the year: to publish major papers about our work. We have several papers undergoing peer review, which we ve made available pre-publication on arxiv, an academic archive. I hope to be sharing news of publication over the coming months, but in the meantime, you can find all our papers here: http://numenta.com/papers/ As we kick off 2016, I am excited for what s in store. We are working to make Numenta technology even more accessible. We have several events and publications planned. And we will remain dedicated to driving the creation of machine intelligence through neocortical principles. Best wishes for a Happy New Year. Donna Dubinsky CEO All Newsletter Posts Donna Dubinsky 2016/01/07 CEO Year in Review for Numenta 2015","title":"Year in Review for Numenta 2015"},{"path":"/newsletter/2016/02/10/numenta-anomaly-benchmark-competition/","text":"Announcing the Numenta Anomaly Benchmark Competition Wed, Feb 10, 2016 NewsletterAnnouncing the Numenta Anomaly Benchmark Competition Christy Maver Director of Marketing Numenta Newsletter February 10, 2016 I m excited to update you on what s happening at Numenta this month, but before I do, I want to introduce myself, as some of you may notice a new name at the bottom of this newsletter. I joined Numenta as the Director of Marketing last fall, and I look forward to keeping you up to date on the latest Numenta news. This month, I am pleased to announce the Numenta Anomaly Benchmark competition, offered in conjunction with the IEEE WCCI (World Congress on Computational Intelligence). This contest follows the release last fall of our Numenta Anomaly Benchmark, which is designed to test algorithms that detect anomalies in streaming data and reward early detection. The competition provides cash awards for two categories: algorithms and datasets. In the algorithms category, we re looking for others to test and publish results of running anomaly detection algorithms on NAB. For the dataset category, we re looking for real-world, time-series data with labeled anomalies. Winning entrants that are participating in the WCCI contest will be announced during official conference proceedings. We are offering a parallel contest for those who are not able to attend the conference. We ll award cash prizes for the same two categories. All contest entries are due by July 1, 2016, but we encourage you to submit early. For more details on the NAB competition, visit http://numenta.org/nab/. Our intention with NAB is to create a community around it and grow it into a widely used tool. We hope the competition will be a fun way to add to the benchmark corpus and to position NAB as the standard benchmark for anomaly detection in streaming data. In other news, we recently shared a summary of our published and submitted research papers. You can now access all of these papers at http://numenta.com/papers/. I encourage you to bookmark the page as we will be updating it with new material throughout the year. Lastly, I want to share that we will be participating in Strata San Jose, March 29-31. We ll have a booth on the expo floor where you can meet our engineers and see our demonstration applications. We ll also preview a new tool to enable broader experimentation with HTM, so stay tuned for more details. If you re planning on attending Strata, please stop by and see us. Christy Maver Director of Marketing All Newsletter Posts Christy Maver 2016/02/10 Director of Marketing Announcing the Numenta Anomaly Benchmark Competition","title":"Announcing the Numenta Anomaly Benchmark Competition"},{"path":"/newsletter/2016/02/18/htm-for-stocks-available-in-the-app-store/","text":"HTM for Stocks available in the App Store Thu, Feb 18, 2016 NewsletterHTM for Stocks available in the App Store Christy Maver Director of Marketing Numenta Newsletter February 18, 2016 I m pleased to announce that we have released an iOS version of HTM for Stocks, a demonstration application that enables anybody to experience HTM technology firsthand. Previously available for Android only, HTM for Stocks now can be found in the App Store. HTM for Stocks continuously monitors stock price, stock volume and Twitter volume for roughly 200 publicly traded companies and alerts you in real time when something unusual is happening. Results are displayed from most to least anomalous, so you can determine what is important and where to focus. This application not only makes detecting securities anomalies easy, but it also highlights the value of HTM. For example, you don t have to know what you re looking for to find these real-time anomalies. HTM starts learning hundreds of models immediately. In this case, it creates a model for three data streams per stock: stock price, stock volume and Twitter volume. The application continuously compares a prediction of the next data point with the actual next point and, if the overall behavior is unexpected, it reports an anomaly. No human intervention is required. You don t have to tune it or define parameters. You don t need to know anything about the stocks. Because HTM for Stocks continuously learns, it adapts well to changes. For example, if a stock price spikes but then continues to stay at that level, HTM for Stocks learns the higher price is a new normal. Perhaps one of the nicest benefits of this application is that it displays stocks from most to least anomalous activity. This ability to cut through vast amounts of noisy data and surface only the companies where something unusual is happening is extremely valuable and time-saving. In this application, we re monitoring stocks, but you could use the same principles to find anomalous behavior in many types of data streams: - Machine sensor data - to do preventative maintenance and know which machines need repairs - Human behavior metrics to identify suspicious activity - GPS coordinates to track vehicles and find deviations from an expected route Like all of our sample applications, we ve made the source code available, and we hope to see developers create derivative products. If you are interested in developing HTM for Stocks into a commercial product, you can contact us at sales@numenta.com. In the meantime, we hope that our readers who are also iPhone users will download HTM for Stocks and give it a try. Christy Maver Director of Marketing All Newsletter Posts Christy Maver 2016/02/18 Director of Marketing HTM for Stocks available in the App Store","title":"HTM for Stocks available in the App Store"},{"path":"/newsletter/2016/03/28/neuron-paper-published-in-peer-reviewed-neuroscience-journal/","text":"Neuron Paper Published in Peer-reviewed Neuroscience Journal Mon, Mar 28, 2016 NewsletterNeuron Paper Published in Peer-reviewed Neuroscience Journal Christy Maver Director of Marketing Numenta Newsletter March 28, 2016 Numenta has an ambitious mission: reverse-engineer the neocortex to understand how it works and apply those principles to software to create intelligent machines. Because neuroscience is the foundation of everything we do, it s important to have our work published and critiqued in peer-reviewed neuroscience journals. I m excited to announce that Jeff Hawkins and Subutai Ahmad s recent manuscript, Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex, has been accepted to Frontiers in Neural Circuits Journal, a publication devoted to research in neural circuits, serving the worldwide neuroscience community. We believe this paper will prove to be a significant contribution to brain theory as well as introduce algorithms that will be important for machine intelligence. The paper proposes a model of cortical neurons that explains why they have thousands of synapses, why the synapses are segregated onto different parts of the dendrites, and how neurons integrate this input in a functionally meaningful way. There are many aspects of this neuron model that are novel. The paper also provides a new and detailed theory of how networks of neurons throughout the neocortex learn sequences and make predictions. This theory is radically different than the models used in most artificial neural networks such as deep learning and LSTM sequence memory. Deep learning and LSTM use artificial neurons that are simplistic and not biologically accurate. Many deep learning models do not incorporate sequence memory at all. Yet sequence memory is a critical component of the brain. In fact, we believe that learning and recalling sequences of patterns is the basic operation common to all brain function. Why is sequence memory so important? Because everything we as humans do is sequence based. When we hear someone talk, we take in a sequence of words; when we look at something, our eyes saccade, moving quickly over the image, leading to a sequence of inputs from the retina; when we move our bodies, we re outputting a sequence of motor commands, which causes changes in our inputs. It is this understanding of how sequence memory works in the brain that allows our software to perform continuous, unsupervised learning without any training data. In case you are not familiar with academic publishing, being published in a journal like Frontiers is not as simple as writing and submitting your paper. It involves a meticulous, multi-step review process where independent reviewers provide feedback and request changes before accepting or denying the paper. This paper is ambitious in how many new ideas it introduces, and took over a year from when we first decided to write it to now, when it has been accepted. I invite you to read the paper, and for those that want a less technical overview, I encourage you to read this article by MIT Tech Review, which summarizes the findings of our pre-published version. Speaking of papers, we also recently completed a new white paper that addresses one of the most popular topics that we re asked when people are learning about Numenta s HTM theory: encoders. The paper, Encoding Data for HTM Systems, written by Scott Purdy, our Director of Engineering, describes how to encode data into Sparse Distributed Representations (SDRs) so that the data can be used in HTM systems. Scott reviews several existing encoders, which are available through our open source project called NuPIC, and explains the requirements for creating encoders for new types of data. Lastly, for any of our readers that will be attending Strata + Hadoop World 2016 in San Jose, CA, please stop by and say Hi. We will be at Booth 540, along with representatives from our partners Cortical.io and Grok, giving demos and overviews on the company, our technology and our latest applications. Christy Maver Director of Marketing All Newsletter Posts Christy Maver 2016/03/28 Director of Marketing Neuron Paper Published in Peer-reviewed Neuroscience Journal","title":"Neuron Paper Published in Peer-reviewed Neuroscience Journal"},{"path":"/newsletter/2016/05/11/announcing-bami-biological-and-machine-intelligence/","text":"Announcing BAMI: Biological and Machine Intelligence, a Living Online Book Wed, May 11, 2016 NewsletterAnnouncing BAMI: Biological and Machine Intelligence, a Living Online Book Christy Maver Director of Marketing Numenta Newsletter May 11, 2016 We receive many requests for better documentation of our work, and as our research has progressed, we know that some of our most popular papers are now outdated. As a result, we have been working for some time on creating a living book , a cohesive body of documentation that provides readers with the A to Z of HTM, and that can be updated as our work progresses. I am pleased to announce that we have released the first four chapters of this book, called Biological and Machine Intelligence (BAMI). We are calling this release v.4 to represent the 4 chapters available. We include a list of future chapters that we hope to add, as well as links to research papers and supporting material. Material that is replaced by BAMI will be moved to the archive section of the resources section on our web site. In addition to publishing peer reviewed papers, we hope to build on BAMI to become the principal resource for those who want to learn about HTM. Over time, we will include problem sets and lecture notes, making it particularly appropriate for academics who intend to create courses teaching HTM theory. For those who are interested, we ve created a twitter account called @NumentaBAMI, which we will only use for BAMI updates. If you d like to be alerted when we add or revise a chapter, I encourage you to follow this account. We ve designed BAMI such that each chapter includes a revision history, so you will always be able to see what has changed. We hope you find BAMI to be a useful resource, and we welcome your feedback and comments. In addition to our BAMI news, we have some exciting events coming up this month as well. On May 12, Jeff Hawkins will be the featured guest at a NeurotechX meetup in San Francisco. Co-founded by one of our engineers, Marion Le Borgne, NeurotechX is a non-profit organization whose mission is to build a strong, global neurotechnology community by providing key resources and learning opportunities. Jeff will give a talk titled \"What is Intelligence, that a Machine Might Have Some? For those that are not in the Bay Area, you can watch the event live, and ask questions in the chat room. On May 19, Subutai Ahmad will be giving a talk titled, Detecting Anomalies in Streaming Data Real-time Algorithms for Real-world Applications at Data By the Bay 2016. Spanning 150 talks over 5 days, Data By The Bay is a by-data engineers, for-data engineers developer and data scientist conference. If you re interested in attending, you can get a 10% discount with the code NUMENTA10. Also on May 19, I will be speaking at the Business Analytics Innovation Summit in Chicago. As a sponsor of this event, we will have the opportunity to introduce and demonstrate our technology and its applications to a business-focused audience over the course of two days. In partner news, Cortical.io announced new releases to their products, which include more accurate results in the comparison of text similarity. This announcement comes on the heels of an independent academic study that concluded Cortical.io s Semantic Folding approach helps improve the prediction of stock return correlations. Visit their website for more details. Lastly, our Open Source Flag Bearer, Matt Taylor, has created a new YouTube series called HTM School. Designed for the layperson, Matt breaks down the basics of various HTM topics in bite-size videos. If you haven t been to HTM School, be sure to check it out. Christy Maver Director of Marketing All Newsletter Posts Christy Maver 2016/05/11 Director of Marketing Announcing BAMI: Biological and Machine Intelligence, a Living Online Book","title":"Announcing BAMI: Biological and Machine Intelligence, a Living Online Book"},{"path":"/newsletter/2016/06/28/numenta-releases-htm-studio-desktop-application/","text":"Numenta Releases HTM Studio Desktop Application Tue, Jun 28, 2016 NewsletterNumenta Releases HTM Studio Desktop Application Christy Maver Director of Marketing Numenta Newsletter June 28, 2016 Since I arrived at Numenta 9 months ago, one of the most common requests I ve heard is that people want an easy way to experiment with HTM without having to dive deep into our code and algorithms. Well, I m happy to share that this week we addressed that request when we announced the release of HTM Studio, a desktop tool that allows you to test whether HTM finds interesting anomalies in your own numeric, time-series data. The ability to detect anomalies as soon as possible in streaming data has value across a wide variety of applications from health monitoring to preventative maintenance to geospatial tracking and more. Yet early detection is easier said than done, and traditional methods like thresholds often miss the subtle anomalies common within streaming data. Because HTM learns continuously and without supervision, it finds these types of anomalies very well. HTM Studio provides a way for anyone, even non-technical people, to experiment with HTM for anomaly detection on their own data, without having to upload anything to the cloud. After downloading HTM Studio, you can import a local csv file, and with a few clicks, HTM analyzes your data and displays any anomalies it finds. For those who don t have streaming data sets, HTM Studio comes with pre-loaded sample data. We hope that this release encourages broad experimentation with our technology. Try it on your home automation data to uncover anomalies in your usage patterns, or your sleep data to find abnormalities in your sleep-wake cycles, or your company s sensors to see where unusual activity is occurring in the office. All you need is a csv file with one Date/Time column, one header row and at least 400 rows of numeric data listed in chronological order. For more on how to ensure your data is in the right format for HTM Studio, watch this short tutorial video. HTM Studio provides an easy way to do a proof of concept before fully implementing or deploying HTM. It also removes the technical hurdle and steep learning curve that typically accompanies HTM experimentation. As a company with a scientific mission to understand how the brain learns, it s been hard for us to make this technology accessible, which is why we are so proud of this release. If you d like to try it, you can download the Windows or Mac version, view our tutorials and give us feedback at http://numenta.com/htm-studio/. Feel free to write us about interesting anomalies that you find we hope to share guest blog posts of the best ones. While many of you are likely planning summer trips, Numenta will be traveling the globe this summer as well. Our Research Engineer, Yuwei Cui, just returned from speaking at two academic conferences in Greece (Dendrite and Areadne), and will be in Vancouver, BC next month to speak at the IEEE World Congress on Computational Intelligence. Subutai Ahmad, VP of Research, is headed to speak at the Playfair AI Summit in London, before returning to speak in San Francisco at the Data Science Summit. We ll be exhibiting at Data Science Summit as well, so if you re planning to attend, be sure to stop by our table for a demo of HTM Studio. For those of you who follow our open source project, you may have seen that we migrated our HTM mailing lists to the HTM Forum. With its clean, intuitive design, this new forum provides a better platform for fostering discussions as the community continues to grow. It categorizes content and allows you to choose which topics to follow. Moderated by our open source flag bearer, Matt Taylor, HTM Forum is open to anyone, so I encourage you to read the posts and join the conversation at https://discourse.numenta.org/. In other news, our partners have some exciting updates to share. Grok has made several product improvements over the past few months. Grok now supports workflow automation, features improvements to the anomaly dashboard and includes many new design enhancements. As Grok continues to grow, the company is looking to expand as well. If you know anyone who would make a great community manager or full stack developer, particularly in the Southern California area, contact tarun@grokstream.com. Cortical.io was recently named an IDC Innovator for the 2016 Machine-Learning based Text Analytics market. Much like Numenta, Cortical.io has been traveling the globe and will be speaking at several upcoming events, including the AI O Reilly Conference in New York September 26-27. Lastly, we are in the final countdown of our Numenta Anomaly Benchmark (NAB) competition. This short video explains how easy it is to win up to $5,000. Christy Maver Director of Marketing All Newsletter Posts Christy Maver 2016/06/28 Director of Marketing Numenta Releases HTM Studio Desktop Application","title":"Numenta Releases HTM Studio Desktop Application"},{"path":"/newsletter/2016/09/06/numenta-newsletter-september-6-2016/","text":"Numenta Newsletter - September 6, 2016 Tue, Sep 06, 2016 NewsletterNumenta Newsletter - September 6, 2016 Christy Maver Director of Marketing Video: Numenta Newsletter - September 6, 2016 Numenta Newsletter September 6, 2016 Summer may be winding down, but excitement has been brewing here at Numenta. We recently unveiled our newly designed website, numenta.com. Those who have been to our site in the past will recognize that this was not a minor reconstruction. We underwent a complete design overhaul, all stemming from an observation by our co-founder, Jeff Hawkins, on the current state of website design. He said that he found most websites today frustrating even our own! He also observed that he almost always started at Wikipedia when trying to learn about a new company. From that conversation, our website redesign effort was born. You ll see Wikipedia s influence in our new design, one that we hope makes it easier for any visitor to find the information they want. You can create your own experience: walk through each section in order, or start by expanding the section of your choice. I encourage you to take a tour of the site and get a feel for the new experience. While you re exploring the new design, you may want to stop by the Numenta blog. There you ll find several new posts, including a behind the scenes look at a filming of an interview with Jeff and Yang Lan, a well-known Chinese broadcast journalist. Yang Lan and her team are putting together a documentary series on Artificial Intelligence, and they ve been traveling the world to interview thought leaders in the space. The final piece is expected to be seen by roughly a billion people, and will be released in English as well as Chinese. We ll share the interview as soon as it is available. Another interesting blog post you ll find is from Jeff, who reflects on a brain theory essay he wrote thirty years ago. The ideas he penned in that 1986 paper formed the basis for the work we are doing at Numenta today. Some of the details may have changed, but the approach, the enthusiasm and the mission remain the same. Read the full post to get Jeff s perspective and a look back at where it all started. In other news, we recently announced the winners of the Numenta Anomaly Benchmark (NAB) Competition. NAB is a benchmark we created to evaluate anomaly detection techniques for streaming data. It contains a dataset with real-world streams and labeled anomalies, as well as a scoring mechanism that rewards early detection. We decided to run a competition because we wanted to continue to grow the benchmark. We created two categories for prizes: 1. Algorithms new anomaly detection algorithms and the results of running them on NAB v1.0. 2. Datasets real-world, time-series data with labeled anomalies. You can read more here about the winning entries and how we plan to incorporate them into NAB. Congratulations to all of these winners: Datasets Category Winners - 1st place: Samya Bagchi - 2nd place: BK Ramesh Algorithms Category Winners - 1st place: Mikhail Smirnov - 2nd place: Felix Andrews - 3rd place: Vladislav Ishimtsev & Evgeny Burnaev Christy Maver Director of Marketing All Newsletter Posts Christy Maver 2016/09/06 Director of Marketing Numenta Newsletter - September 6, 2016","title":"Numenta Newsletter - September 6, 2016"},{"path":"/numenta-anomaly-benchmark/","text":"Numenta Anomaly Benchmark (NAB) Numenta Anomaly Benchmark (NAB) Video: Numenta Anomaly Benchmark (NAB) (02:23) The First Benchmark For Evaluating Anomaly Detection In Streaming Data The Internet of Things has produced a world that s overflowing with streaming data. As these data sources continue to grow, so does the need for anomaly detection. Uncovering anomalies allows you to: - Detect potential machine failures - Recognize changes in Twitter activity - Identify unexpected traffic patterns There are different methods of anomaly detection in streaming data, but how do you measure their effectiveness? NAB is the first benchmark designed for time-series data that gives credit to finding anomalies earlier and adjusting to changed patterns.FeaturesReal-World Dataset NAB contains a dataset with real-world, labeled data files across multiple domains. We ve accumulated this valuable data from years of working with customers to address their anomaly problems.Scoring Mechanism We have developed a unique scoring function that rewards early detection, penalizes late or false results, and gives credit for on-line learning.Open Source Code Library NAB is a modular, open source code base. Numenta will be working to build a community around NAB to add data files and test additional algorithms.Resources Video: Evaluating Real-Time Anomaly Detection (19:23) Evaluating Real-Time Anomaly Detection: The Numenta Anomaly Benchmark (NAB) Subutai Ahmad, VP Research presenting NAB and discussing the need for evaluating real-time anomaly detection algorithms. This presentation was delivered at MLConf (Machine Learning Conference) in San Francisco 2015. See Slides White Paper: The Numenta Anomaly Benchmark (NAB) Why did we create this benchmark? Why is anomaly detection so hard in streaming data? This paper answers those questions and highlights how business managers can use NAB to ensure they re getting valuable insights as early as possible. Read Whitepaper Research Paper: Evaluating Real-time Anomaly Detection Algorithms the Numenta Anomaly Benchmark (NAB) This peer-reviewed paper was accepted to the IEEE Conference on Machine Learning and Applications December 9-11, 2015 in Miami. It contains technical details on NAB, including the mathematical explanation of the scoring system. Read Research PaperNAB Repository This open source library contains all data files, algorithms and documentation. Use this repository to try NAB for yourself. Test your own techniques against the published algorithms and share your results. Visit Repository Data Sheet: Numenta Anomaly Benchmark (NAB) Download this two-page data sheet to learn more about the key components of NAB. Download DatasheetTry NAB for Yourself Try the Numenta Anomaly Benchmark (NAB) We ve made it easy for you to try NAB. Visit the repository to test your own techniques and share your results. Use NAB to select the best algorithm for your specific application. Contribute Your Data We are committed to adding more real-world data files to our benchmark dataset. Do you have streaming data files with known anomalies? Contact us at nab@numenta.org to see if we can incorporate your data into a future version of NAB. ","title":"Numenta Anomaly Benchmark (NAB)"},{"path":"/open-source-community/","text":"Open Source Community Open Source Community Because we want our technology to be broadly adopted, we make it widely accessible in an open source community. There you ll find our algorithms, daily research, source code, and an active discussion forum with HTM community members covering a variety of topics. You ll also find our implementation of HTM theory, called NuPIC (Numenta Platform for Intelligent Computing), which is written in C++ and Python. Other implementations have been ported from NuPIC into other languages by community members. If you are interested in seeing, developing or working with our technology, we invite you to participate at http://numenta.org . Anyone is welcome to use our technology for free, under the AGPLv3 open source license. In addition, we have created a separate, trial license without commercial rights for those individuals or organizations who are unable to use the AGPLv3 license. For more on our licenses, see the Business Strategy & IP section. Next: Applications ","title":"Open Source Community"},{"path":"/papers-videos-and-more/","text":"Papers, Videos &amp; More Papers, Videos & More Video: The Hard Unsolved Problems in HTM Theory (1:00:00) To help you learn about our theory and technology, we have organized educational content below. It is designed for anyone who wants to learn about HTM cortical theory and its applications for machine intelligence. 1. Research Papers Here you ll find a collection of recent Numenta Research papers. Some of them are currently under review at journals/conferences but we have made all manuscripts available on arXiv, an online repository of self-archived scientific papers. 2. Biological and Machine Intelligence (BAMI) This living book (Biological And Machine Intelligence) documents our Hierarchical Temporal Memory framework for both biological and machine intelligence. 3. HTM School This YouTube series is designed to educate the general public about Hierarchical Temporal Memory (HTM). Each 10-15 minute episode dives into a particular topic of HTM theory. Videos 1. Machine Intelligence with Streaming Data Webinar Numenta Christy Maver & Scott Purdy 2016/04/26 2. HTM Videos from Jeff Hawkins Jeff Hawkins Co-Founder 2014/11/22 3. Applications of Hierarchical Temporal Memory (HTM) Chetan Surpur Software Engineer 2014/10/17 4. Getting Started With Numenta Technology Numenta Celeste Baranski & Matt Taylor 2014/10/17 5. Science of Anomaly Detection Scott Purdy Engineering Manager 2014/10/17 6. Sparse Distributed Representations - Our Brain's Data Structure Subutai Ahmad VP Research 2014/10/17 7. HTM Learning Algorithm Tutorial - Algorithm Basics Rahul Agarwal Software Engineer 2013/08/03 More 1. Hierarchical Temporal Memory (HTM) Whitepaper Jeff Hawkins Co-Founder 2011/09/12 2. On Intelligence (Book) Jeff Hawkins & Sandra Blakeslee Co-Founder & Co-Author 2005/07/14 Next: Careers & Team ","title":"Papers, Videos &amp; More"},{"path":"/papers-videos-and-more/resources/applications-of-hierarchical-temporal-memory/","text":"Applications of Hierarchical Temporal Memory (HTM) Fri, Oct 17, 2014 ResourcesApplications of Hierarchical Temporal Memory (HTM) Chetan Surpur Software Engineer Talk Video - This video talk on Applications of Hierarchical Temporal Memory (HTM) was delivered at a Numenta workshop. Slides Applications of Hierarchical Temporal Memory (HTM) from Numenta Chetan Surpur Software Engineer All Resources Posts Chetan Surpur 2014/10/17 Software Engineer Applications of Hierarchical Temporal Memory (HTM)","title":"Applications of Hierarchical Temporal Memory (HTM)"},{"path":"/papers-videos-and-more/resources/getting-started-with-numenta-technology/","text":"Getting Started With Numenta Technology Fri, Oct 17, 2014 ResourcesGetting Started With Numenta Technology Numenta Celeste Baranski & Matt Taylor Video This video is replaced by the Numenta License Guide! Presenters - Celeste Baranski, VP of Engineering - Matthew Taylor, Open Source Manager Slides - Getting Started with Numenta Technology from Numenta. Getting Started with Numenta Technology from Numenta Numenta Celeste Baranski & Matt Taylor All Resources Posts Numenta 2014/10/17 Celeste Baranski & Matt Taylor Getting Started With Numenta Technology","title":"Getting Started With Numenta Technology"},{"path":"/papers-videos-and-more/resources/hierarchical-temporal-memory-basics-tutorial/","text":"HTM Learning Algorithm Tutorial - Algorithm Basics Sat, Aug 03, 2013 ResourcesHTM Learning Algorithm Tutorial - Algorithm Basics Rahul Agarwal Software Engineer This video tutorial follows the 2011 HTM whitepaper, and is largely obsolete. The content of this tutorial will be replace by HTM School (over time). Note: This video refers to the HTM learning algorithm as the Cortical Learning Algorithm, or CLA; we have recently decided to sunset this term. Video Rahul Agarwal Software Engineer All Resources Posts Rahul Agarwal 2013/08/03 Software Engineer HTM Learning Algorithm Tutorial - Algorithm Basics","title":"HTM Learning Algorithm Tutorial - Algorithm Basics"},{"path":"/papers-videos-and-more/resources/hierarchical-temporal-memory-white-paper/","text":"Hierarchical Temporal Memory (HTM) Whitepaper Mon, Sep 12, 2011 ResourcesHierarchical Temporal Memory (HTM) Whitepaper Jeff Hawkins Co-Founder There have been changes in our thinking, in algorithm implementation, in terminology and in other areas since this paper was written, rendering part of this paper obsolete. Much of this paper has been replaced by BAMI and the current white papers, and we will continue to provide updated material in subsequent releases of BAMI. About At the heart of Hierarchical Temporal Memory (HTM), our machine intelligence technology, are time-based learning algorithms that store and recall spatial and temporal patterns. This paper describes how the learning algorithms work and their biological mapping. Download Whitepaper Note: This paper refers to the HTM learning algorithm as the Cortical Learning Algorithm, or CLA; we have recently decided to sunset this term as our technology has evolved. Translations Available Language Code Translator Link Chinese CN Yu Tianxiang Download French FR Laurent Julliard Download German DE Ingmar Baetge Download Japanese JP Akihiro Yoshikawa Download Korean KR Jihoon Oh Download Portuguese PT David Ragazzi Download Russian RU Mikhaile Netov Download Spanish ES Garikoitz Lerma Usabiaga Download Jeff Hawkins Co-Founder All Resources Posts Jeff Hawkins 2011/09/12 Co-Founder Hierarchical Temporal Memory (HTM) Whitepaper","title":"Hierarchical Temporal Memory (HTM) Whitepaper"},{"path":"/papers-videos-and-more/resources/htm-videos-from-jeff-hawkins/","text":"HTM Videos from Jeff Hawkins Sat, Nov 22, 2014 ResourcesHTM Videos from Jeff Hawkins Jeff Hawkins Co-Founder These two videos are similar, and provide an overview of HTM and associated topics by Numenta s founder, Jeff Hawkins. The talks have slightly different emphasis (for instance, the first video has more details on SDRs). At the time of BAMI 0.4 release, we are currently rethinking the role of hierarchy and the connections between the various layers of the neocortex, so the comments on these subjects in the videos are out of date. #1 What The Brain Says About Machine Intelligence Video talk on What The Brain Says About Machine Intelligence by Jeff Hawkins, Numenta Co-Founder. Nov 2014 in Redwood City, CA. Video Slides Link: What the Brain says about Machine Intelligence from Numenta. #2 Principles of HTM - Foundations of Machine Intelligence Video talk on Hierarchical Temporal Memory (HTM) and the Foundations of Machine Intelligence by Jeff Hawkins, Numenta Co-Founder. Numenta Workshop Oct 2014 in Redwood City, CA. Talk Q & A Session Slides Link: Principles of Hierarchical Temporal Memory from Numenta. Principles of Hierarchical Temporal Memory - Foundations of Machine Intelligence from Numenta Jeff Hawkins Co-Founder All Resources Posts Jeff Hawkins 2014/11/22 Co-Founder HTM Videos from Jeff Hawkins","title":"HTM Videos from Jeff Hawkins"},{"path":"/papers-videos-and-more/resources/machine-intelligence-with-streaming-data-webinar/","text":"Machine Intelligence with Streaming Data Webinar Tue, Apr 26, 2016 ResourcesMachine Intelligence with Streaming Data Webinar Numenta Christy Maver & Scott Purdy Machine Intelligence with Streaming Data A new approach for anomaly detection and time-based learning This webinar provides an overview of the current state of HTM, with an emphasis on the software implementation and example applications. The Q&A session at the end of the webinar answers some popular user questions. Presented by - Christy Maver (Director of Marketing, Numenta) - Scott Purdy (Director of Development, Numenta) Video Machine Intelligence with Streaming Data from ProHuddle on Vimeo. About Links: - Main Event Website - Numenta Event Page Across every industry, we are seeing an exponential increase in the availability of streaming, time-series data. The real-time detection of anomalies has significant practical application. Finding anomalies in such data can be very difficult, given the need to process data in real time, and learn while simultaneously making predictions. With the increasing variety of streaming data sources, automated deployment without manual parameter tuning is also becoming important. Numenta Christy Maver & Scott Purdy All Resources Posts Numenta 2016/04/26 Christy Maver & Scott Purdy Machine Intelligence with Streaming Data Webinar","title":"Machine Intelligence with Streaming Data Webinar"},{"path":"/papers-videos-and-more/resources/on-intelligence/","text":"On Intelligence (Book) Thu, Jul 14, 2005 ResourcesOn Intelligence (Book) Jeff Hawkins & Sandra Blakeslee Co-Founder & Co-Author The core concepts in Hierarchical Temporal Memory (HTM) theory were first described in this book titled On Intelligence, which was written by Jeff Hawkins with the help of Sandra Blakeslee. This book still provides background and a great introduction to our theory, though many of the ideas in chapter 6 ( How the Cortex Works ) are currently being revised. Buy Book: Purchase on Amazon Note: This book refers to the HTM learning algorithm as the Cortical Learning Algorithm, or CLA; we have recently decided to sunset this term as our technology has evolved. Translations Available Chinese, Finnish, French, German, Hebrew, Indonesian, Italian, Korean, Japanese, Polish, Portuguese, Russian, Spanish, Vietnamese. Jeff Hawkins & Sandra Blakeslee Co-Founder & Co-Author All Resources Posts Jeff Hawkins & Sandra Blakeslee 2005/07/14 Co-Founder & Co-Author On Intelligence (Book)","title":"On Intelligence (Book)"},{"path":"/papers-videos-and-more/resources/science-of-anomaly-detection/","text":"Science of Anomaly Detection Fri, Oct 17, 2014 ResourcesScience of Anomaly Detection Scott Purdy Engineering Manager This video talk on the Science of Anomaly Detection was delivered at a Numenta workshop and covers the application of HTM to anomaly detection in streaming data. Talk Video Slides Science of Anomaly Detection from Numenta Whitepaper Numenta PDF Whitepaper: Science of Anomaly Detection Scott Purdy Engineering Manager All Resources Posts Scott Purdy 2014/10/17 Engineering Manager Science of Anomaly Detection","title":"Science of Anomaly Detection"},{"path":"/papers-videos-and-more/resources/sparse-distributed-representations/","text":"Sparse Distributed Representations - Our Brain&#x27;s Data Structure Fri, Oct 17, 2014 ResourcesSparse Distributed Representations - Our Brain's Data Structure Subutai Ahmad VP Research Talk Video - This video talk on Sparse Distributed Representations (SDR) covers a subset of the topics in the BAMI chapter on SDRs. Slides Sparse Distributed Representations: Our Brain's Data Structure from Numenta Subutai Ahmad VP Research All Resources Posts Subutai Ahmad 2014/10/17 VP Research Sparse Distributed Representations - Our Brain's Data Structure","title":"Sparse Distributed Representations - Our Brain&#x27;s Data Structure"},{"path":"/papers/","text":"Research Papers Research Papers 1. Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex Jeff Hawkins & Subutai Ahmad Neuroscience Published in Frontiers in Neural Circuits Journal 2015/10/31 Foundational paper describing core HTM theory for sequence memory and its relationship to the neocortex. Written with a neuroscience perspective, the paper explains why neurons need so many synapses and how networks of neurons can form a powerful sequence learning mechanism. 2. Continuous Online Sequence Learning with an Unsupervised Neural Network Model Yuwei Cui, Subutai Ahmad, Jeff Hawkins & Chetan Surpur Machine learning Preprint of journal submission 2015/12/17 Analysis of HTM sequence memory applied to various sequence learning and prediction problems. Written with a machine learning perspective, the paper contains some comparisons to statistical and Deep Learning techniques. 3. Evaluating Real-time Anomaly Detection Algorithms - the Numenta Anomaly Benchmark Alexander Lavin & Subutai Ahmad Machine learning Published conference paper 2015/10/12 14th IEEE ICMLA 2015 - This paper discusses how we should think about anomaly detection for streaming applications. It introduces a new open-source benchmark for detecting anomalies in real-time, time-series data. 4. Real-Time Anomaly Detection for Streaming Analytics Subutai Ahmad & Scott Purdy Machine learning Preprint of journal submission 2016/07/08 Much of the worlds data is streaming, time-series data, where anomalies give significant information in critical situations. Yet detecting anomalies in streaming data is a difficult task, requiring detectors to process data in real-time, and learn while simultaneously making predictions. 5. How Do Neurons Operate on Sparse Distributed Representations? A Mathematical Theory of Sparsity, Neurons and Active Dendrites Subutai Ahmad & Jeff Hawkins Neuroscience Preprint of journal submission 2016/01/05 This paper describes a mathematical model for quantifying the benefits and limitations of sparse representations in neurons and cortical networks. 6. Properties of Sparse Distributed Representations and their Application To Hierarchical Temporal Memory Subutai Ahmad & Jeff Hawkins Neuroscience Research Paper 2014/10/28 An earlier version of the above submission, this paper applies our mathematical model of sparse representations to practical HTM systems. 7. Encoding Data for HTM Systems Scott Purdy Machine learning Research Paper 2016/02/18 Hierarchical Temporal Memory (HTM) is a biologically inspired machine intelligence technology that mimics the architecture and processes of the neocortex. In this white paper we describe how to encode data as Sparse Distributed Representations (SDRs) for use in HTM systems. We explain several existing encoders, which are available through the open source project called NuPIC, and we discuss requirements for creating encoders for new types of data. 8. Porting HTM Models to the Heidelberg Neuromorphic Computing Platform Sebastian Billaudelle & Subutai Ahmad Neuroscience Research Paper 2015/05/08 Recently there has been much interest in building custom hardware implementations of HTM systems. This paper discusses one such scenario, and shows how to port HTM algorithms to analog hardware platforms such as the one developed by the Human Brain Project. ","title":"Research Papers"},{"path":"/partners/","text":"Partners Partners Numenta works with strategic partners to bring the power of HTM to the market. While we focus on the science and the core technology, we select application partners who have deep domain knowledge and are able to add an application layer tuned to market needs. We are flexible in structuring these relationships in a way that works for both parties. If you are interested in becoming a partner, please review our license guide, and email us at sales@numenta.com . Cortical.io Cortical.io is leading the next generation of natural language processing: language intelligence. Founded on core principles of HTM, Cortical.io s Semantic Folding technology translates text into sparse distributed representations. This enables a host of exciting applications that have challenged computer scientists for decades including sentiment analysis, automatic summarization, semantic search and conversational dialogue systems. - Cortical.io - Whitepaper: Semantic Folding - Press Release - NewsletterGrok Grok is using HTM technology for advanced IT anomaly detection. Grok applies Numenta's breakthrough technology to solving the IT department s hardest problems, with a complete enterprise solution. Its modern user interface makes it easy to drill down to important anomalies and take action before a problem worsens. - Grok - Press Release - NewsletterNext: Business Strategy & IP ","title":"Partners"},{"path":"/press/2013/02/14/numenta-gigaom-presentation/","text":"Numenta to Present Grok, a Solution for Fast Data, as one of the Big Ideas at the GigaOM Structure:Data Conference on March 20, 2013 Thu, Feb 14, 2013 PressNumenta to Present Grok, a Solution for Fast Data, as one of the Big Ideas at the GigaOM Structure:Data Conference on March 20, 2013 Numenta Press Release NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. Numenta, a breakthrough machine intelligence company, today announced it has been selected as one of the four Big Ideas companies to be featured at the GigaOM Structure:Data conference March 20-21 in New York City. Numenta CEO Rami Branitzky will give an on-stage introduction of Grok, the company s first product, on March 20 at 5:20 p.m. Grok brings together Numenta s trailblazing R&D in biologically inspired machine intelligence software with a highly scalable infrastructure for acting on fast data. The Grok platform ingests data streams and creates actionable predictions in real time. Grok s automated modeling and continuous learning capability makes it uniquely suited for fast data. Machine generated streaming data is exploding. It has a short half-life and is constantly changing, said Branitzky. To date, the focus in the area of Big Data has been on machines to store and process data, with a short supply of data scientists to analyze and act on it. To best leverage fast data, we believe you must have systems that model and learn from data automatically and use the results to drive automated actions. That s what Grok was designed to do. The GigaOM editorial team hand picked four companies and speakers who embody great ideas that are shaping our industry for the Big Ideas session, and our editors are excited to have Numenta as one, said Surj Patel, GigaOM s Vice President for Events. Grok solutions currently are in private beta with customers in a variety of vertical markets, including electric energy, IT management, online advertising and finance. Numenta recently announced EnerNOC, Inc., a leading provider of energy management applications, as one of its first customers - entering a partnership that couples Numenta s Grok streaming analytics solution with EnerNOC s cloud-based software to create opportunities for demand response and increased ability to detect energy efficiency faults and anomalies. About GigaOM Structure:Data Structure:Data 2013 will explore the technical and business opportunities created by the rapid growth of big data. Many of the industry s brightest minds will converge to reveal how they are making the most of the data revolution. Discounted supersaver tickets are available through February 22. About Numenta Numenta s mission is to build solutions that help companies automatically and intelligently act on the world s data. Numenta s biologically inspired machine learning technology was first described in Numenta s co-founder Jeff Hawkin s book, On Intelligence. Numenta s Grok platform, based on this technology, ingests data streams and creates actionable predictions in real time. Grok s automated modeling and continuous learning capability makes it uniquely suited to drive intelligent action from fast data. Grok solutions are available directly from Numenta and Numenta partners in a variety of vertical markets, including electric energy, IT management, online advertising and finance. For more information on Numenta and Grok go to http://numenta.com. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2013/02/14 Press Release Numenta to Present Grok, a Solution for Fast Data, as one of the Big Ideas at the GigaOM Structure:Data Conference on March 20, 2013","title":"Numenta to Present Grok, a Solution for Fast Data, as one of the Big Ideas at the GigaOM Structure:Data Conference on March 20, 2013"},{"path":"/press/2013/04/18/thingworx-partnership/","text":"ThingWorx and Numenta Partner to offer Next Generation Predictive Maintenance and Operations for the Connected World Thu, Apr 18, 2013 PressThingWorx and Numenta Partner to offer Next Generation Predictive Maintenance and Operations for the Connected World Numenta Press Release Exton, Pa. April 18, 2013 ThingWorx, the provider of the first application development platform for the connected world, and Numenta, a leading provider of solutions that help companies intelligently act on machine-generated data, today announced a partnership to create the next generation of tools for predictive maintenance. The companies will work together to deliver advanced maintenance solutions to enable organizations to fully leverage the troves of data being generated by their connected machinery to achieve maximum operational efficiency and reduce maintenance costs. The proliferation of devices and sensors creating machine-generated data yield enormous opportunity for automated predictive maintenance solutions. According to leading device and network companies such as Ericsson and Cisco, the number of connected devices and machines is expected to reach 50 billion devices by 2020; ARC Research estimates that Predictive Maintenance is a global $20 billion opportunity To fully capitalize on this opportunity, ThingWorx and Numenta believe that a new generation of maintenance solutions are required that go beyond today s batch-driven analytics approaches. ThingWorx, which provides a powerful and flexible platform to rapidly deliver customizable applications and connected solutions, is architected for this explosion of devices and data across a range of industries. Numenta s industry leading biologically inspired machine intelligence technology, called Grok, is designed to automatically analyze data generated by these connected devices to drive actionable predictions. Grok ingests data streams and can detect anomalous patterns in data streams that indicate, for example, when a machine is in an unusual state and might fail. Our two companies bring a unique combination of assets to tackle problems in real-time predictive maintenance to help companies minimize or avoid downtime of mission critical systems and reduce maintenance costs, said Rami Branitzky, Numenta CEO. Grok capabilities especially its continuous learning and automated modeling are ideal for advanced, proactive monitoring of machinery that needs to have continuous uptime. Working closely with ThingWorx s industry leading connected device platform and rapid development environment we are well positioned to help transform the Predictive Maintenance market. ThingWorx is pleased to be able to offer plug-and-play access to the most innovative analytic framework in the market today, said Russ Fadel, CEO and Co- Founder of ThingWorx. Grok provides new capabilities for predictive maintenance applications. By integrating it into our platform we can eliminate the time-consuming process of data analysis and predictive modeling and provide customers in asset-intensive industries such as energy, oil and gas, healthcare, and manufacturing, and equipment OEMs, with the critical analysis and actions in order for them to operate more reliably and efficiently. We are excited to be offering a solution that we believe will allow companies to truly predict machine behavior, which will enable a step change in efficiency. As part of their collaboration, Grok has been certified as ThingWorx Ready and will be pre-integrated with the ThingWorx rapid application development platform. Further information on the combined predictive maintenance solution will be on display at the upcoming Field Service USA event, as well as during a live webcast on April 24, 2013, Smarter Services: The Future of Connected Products Today. About ThingWorx ThingWorx provides the first platform designed to efficiently build and run the applications of today s connected world. ThingWorx s model-based design and search-based intelligence reduces application development efforts by 10X, minimizing cost, risk and time to market. The ThingWorx platform combines the key functionality of Web 2.0, search, and social collaboration, and applies it to the world of things, including connected products, machines, sensors, and industrial equipment. Businesses use the ThingWorx platform to rapidly deliver innovative applications and connected solutions across markets ranging from manufacturing, energy, and food, to Machine-to-Machine (M2M) remote monitoring and service, as well as in emerging Internet of Things applications, including smart cities, smart grid, agriculture, and transportation. For more information, please visit our website at http://thingworx.com. About Numenta Numenta builds solutions that help companies automatically and intelligently act on their data. Its Grok technology and product platform are based on biologically inspired machine learning technology first described in co-founder Jeff Hawkin s book, On Intelligence. Grok ingests data streams and creates actionable predictions in real time. Grok s automated modeling and continuous learning capability makes it uniquely suited to drive intelligent action from fast data. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2013/04/18 Press Release ThingWorx and Numenta Partner to offer Next Generation Predictive Maintenance and Operations for the Connected World","title":"ThingWorx and Numenta Partner to offer Next Generation Predictive Maintenance and Operations for the Connected World"},{"path":"/press/2013/05/17/sybase-esp-integration/","text":"Grok’s Action Intelligence Solution Achieves Certified Integration with SAP® Sybase ESP Complex Event Processing Platform Fri, May 17, 2013 PressGrok s Action Intelligence Solution Achieves Certified Integration with SAP Sybase ESP Complex Event Processing Platform Numenta Press Release NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. Numenta, a leading provider of solutions that help companies intelligently act on machine-generated data, today announced its Grok solution has achieved certified integration with the SAP Sybase Event Stream Processor (SAP Sybase ESP). The SAP Integration and Certification Center (SAP ICC) has certified that the Grok 2.0 solution integrates with the SAP Sybase ESP 5.1 to send and receive streaming data, predictions, and anomalies found in data streams. Grok s patented machine intelligence product ingests data streams and creates actionable predictions and detects anomalies in real-time. The Grok solution features automated pattern discovery and predictive modeling capabilities based on its unique biologically inspired machine intelligence algorithm. Grok was recently named as one of the Cool Vendors in Analytics for 2013 by Gartner Research. Grok delivers real-time predictions and finds anomalies in streaming data. Grok s ability to learn from streaming data makes it a perfect add-on for customers who are looking to automatically and intelligently act on their machine-generated data, said Numenta CEO Rami Branitzky. The Grok solution is a natural complement to SAP Real-Time Data Platform. We look forward to working closely with SAP to serve this rapidly expanding market. In addition, Numenta has applied to join the SAP PartnerEdge program as an SAP software solution and technology partner. Through the program, partners work closely with SAP AG (NYSE: SAP) to develop and certify the technical integration of their solutions with SAP software. Integrated partner applications extend, complement and add value to SAP solutions, thereby helping mutual customers more successfully meet business needs and drive strong results. About Numenta Numenta builds solutions that help companies automatically and intelligently act on their data. Grok s technology and product platform are based on biologically inspired machine learning technology first described in co-founder Jeff Hawkins book, On Intelligence. Grok ingests data streams and creates actionable predictions in real time. Grok s automated modeling and continuous learning capabilities make it uniquely suited to drive intelligent action from fast data. Grok solutions are available directly from Grok and its partners in a variety of vertical markets, including energy, IT management, and finance. For more information go to http://grokstream.com. SAP, PartnerEdge and all SAP logos are trademarks or registered trademarks of SAP AG in Germany and in several other countries. Sybase is a trademark or registered trademark of Sybase, Inc. indicates registration in the United States. Sybase is an SAP company. All other product and service names mentioned herein are the trademarks of their respective owners. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2013/05/17 Press Release Grok’s Action Intelligence Solution Achieves Certified Integration with SAP® Sybase ESP Complex Event Processing Platform","title":"Grok’s Action Intelligence Solution Achieves Certified Integration with SAP® Sybase ESP Complex Event Processing Platform"},{"path":"/press/2013/07/22/nupic-open-source-project/","text":"NuPIC Open Source Project and Community Established at Numenta.org Mon, Jul 22, 2013 PressNuPIC Open Source Project and Community Established at Numenta.org Numenta Press Release Numenta.org has been created as the home for the NuPIC (Numenta Platform for Intelligent Computing) open source project and community. The project was announced today in a keynote address at the OSCON open source conference. The mission of this project is to build a community interested in machine intelligence based on biological principles, said Jeff Hawkins, co-founder of Numenta, Inc. Developers and scientists told us they wanted to work with our learning algorithms. There were already several independent implementations based on our publications. We felt that an open source structure was the best way to share knowledge and accelerate progress in machine intelligence. Hawkins, who has studied neuroscience for more than 30 years, wrote a book called On Intelligence (along with Sandra Blakeslee) in 2005 that described a theory of the neocortex. Numenta, Inc. was formed as a company to pursue the theory for commercial and scientific purposes shortly thereafter. NuPIC comprises a set of learning algorithms called the Hierarchical Temporal Memory (HTM) first described in a whitepaper published by Numenta in 2009. The CLA algorithms replicate part of the function of a region of the neocortex. They can be used for pattern recognition, prediction, and anomaly detection in many domains. They have been tested extensively and are embedded in a product called Grok, which the company released last year. Grok is now being branded and commercialized separately from Numenta. Understanding the brain and building fantastically intelligent machines is a grand quest for humanity, Hawkins continued. This is not a trivial pursuit, and there is a tremendous amount of work to be done, but we believe the CLA is a key building block that provides a path forward. Our hope is that NuPIC contributors will work on these problems, accelerate our progress, and uncover fascinating new applications. Anyone can access the NuPIC open source code under the AGPLv3 license*. For more information see the Introduction to NuPIC and go to http://numenta.org. * This content has been updated to reflect our new AGPL license. About Numenta.org Numenta.org is the home and community for the NuPIC (Numenta Platform for Intelligent Computing) open source project. NuPIC was developed by Numenta Inc. based on the theory of the neocortex first described in co-founder Jeff Hawkins 2005 book On Intelligence. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2013/07/22 Press Release NuPIC Open Source Project and Community Established at Numenta.org","title":"NuPIC Open Source Project and Community Established at Numenta.org"},{"path":"/press/2013/12/04/computing-like-the-brain/","text":"Computing Like the Brain: The Path to Machine Intelligence Wed, Dec 04, 2013Computing Like the Brain: The Path to Machine Intelligence Editor 2013/12/04 YOW Computing Like the Brain: The Path to Machine Intelligence","title":"Computing Like the Brain: The Path to Machine Intelligence"},{"path":"/press/2014/01/22/fujitsu-natf-video/","text":"Brains, Data, and Machine Intelligence Wed, Jan 22, 2014Brains, Data, and Machine Intelligence Editor 2014/01/22 Fujitsu Brains, Data, and Machine Intelligence","title":"Brains, Data, and Machine Intelligence"},{"path":"/press/2014/01/29/brains-view-of-economics/","text":"A Brain&#x27;s View of Economics Wed, Jan 29, 2014A Brain's View of Economics Ricardo Hausmann 2014/01/29 Project Syndicate A Brain's View of Economics","title":"A Brain&#x27;s View of Economics"},{"path":"/press/2014/03/25/numenta-releases-grok-for-it-analytics-on-aws/","text":"Numenta Releases Grok for IT Analytics on AWS Tue, Mar 25, 2014 PressNumenta Releases Grok for IT Analytics on AWS Numenta Press Release NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. Numenta, Inc. today announced the commercial availability of Grok for IT Analytics on Amazon Web Services (AWS). Grok anomaly detection leverages sophisticated machine intelligence algorithms to enable new insights into critical IT systems. Grok automatically learns complex patterns and then highlights unusual behavior. As software topologies and usage patterns change, Grok continuously learns and adapts, eliminating the need for frequent resetting of thresholds. Visualization of Grok output is displayed on a constantly updated mobile device, enabling IT professionals to assess the health of their systems anytime, anywhere. Using Grok, IT operators can better prevent business downtime while reducing false positives. Grok is the first commercial application of Numenta s groundbreaking Hierarchical Temporal Memory (HTM), biologically inspired algorithms for machine intelligence. The core HTM technology is ideal for large-scale analysis of continuously streaming datasets and excels at modeling and predicting patterns in data. Grok provides an early warning system to IT professionals to give them real- time insights into their system performance, said Numenta CEO Donna Dubinsky. Grok anticipates problems before they happen, reduces false positives, and lowers engineering costs through automated modeling and continuous learning. Grok features include: - Monitoring of performance and health of AWS environments or other systems - Automatic modeling to determine normal patterns - Automatic identification and ranking of unusual patterns - Continuous learning of new patterns as environments evolve no need for manual threshold setting - Notification to user when an anomaly occurs - Output displayed graphically on an Android mobile device - Simple setup via a web-based or command-line interface - Support for AWS auto-scaling groups and logical clusters Grok is available now: http://grokstream.com Grok will be demonstrated in Booth 100 at the AWS Summit on March 26 at the Moscone Center in San Francisco. In addition to working on the Grok product release, Numenta continues to push its biologically-inspired algorithms forward. We ve made some important progress recently and look forward to sharing it with our community over the coming year, said Jeff Hawkins, Numenta co-founder. Our open source community, NuPIC, is also growing and actively contributing to the advancement of the science. About Numenta Inc. Numenta, Inc., was founded in 2005 to be a catalyst in the emerging field of machine intelligence. Numenta builds solutions that help companies automatically and intelligently act on machine generated data. Its biologically inspired machine learning technology is based on a theory of the neocortex first described in co-founder Jeff Hawkins book, On Intelligence. Its first commercial product, called Grok, offers a breakthrough solution for anomaly detection for IT Operations. In addition, Numenta has created NuPIC (Numenta Platform for Intelligent Computing) as an open source project. Numenta is based in Redwood City, California. It is privately funded. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2014/03/25 Press Release Numenta Releases Grok for IT Analytics on AWS","title":"Numenta Releases Grok for IT Analytics on AWS"},{"path":"/press/2014/03/29/building-an-ai-that-mimics-our-neocortex/","text":"Meet the Man Building an AI that Mimics Our Neocortex Sat, Mar 29, 2014Meet the Man Building an AI that Mimics Our Neocortex Jack Clark 2014/03/29 The Register Meet the Man Building an AI that Mimics Our Neocortex","title":"Meet the Man Building an AI that Mimics Our Neocortex"},{"path":"/press/2014/04/07/triangulation-146-with-leo-laporte/","text":"Jeff Hawkins on Triangulation 146 with Leo Laporte Mon, Apr 07, 2014Jeff Hawkins on Triangulation 146 with Leo Laporte Leo Laporte 2014/04/07 Twit.tv Jeff Hawkins on Triangulation 146 with Leo Laporte","title":"Jeff Hawkins on Triangulation 146 with Leo Laporte"},{"path":"/press/2014/04/08/path-to-machine-intelligence/","text":"Jeff Hawkins on the Path to Machine Intelligence Tue, Apr 08, 2014Jeff Hawkins on the Path to Machine Intelligence Editor 2014/04/08 33rd Square Jeff Hawkins on the Path to Machine Intelligence","title":"Jeff Hawkins on the Path to Machine Intelligence"},{"path":"/press/2014/04/20/what-really-scares-tech-leaders-about-artificial-intelligence/","text":"What Really Scares Tech Leaders About Artificial Intelligence? Mon, Apr 20, 2015What Really Scares Tech Leaders About Artificial Intelligence? Anthony Wing Kosner 2015/04/20 Forbes What Really Scares Tech Leaders About Artificial Intelligence?","title":"What Really Scares Tech Leaders About Artificial Intelligence?"},{"path":"/press/2014/04/23/neuromorphic-chips-enhance-artificial-intelligence/","text":"Neuromorphic Chips: Microprocessors Configured Like Brains Wed, Apr 23, 2014Neuromorphic Chips: Microprocessors Configured Like Brains Robert D. Hof 2014/04/23 MIT Technology Review Neuromorphic Chips: Microprocessors Configured Like Brains","title":"Neuromorphic Chips: Microprocessors Configured Like Brains"},{"path":"/press/2014/04/30/when-big-data-is-old-news/","text":"As Big Data Becomes Old News Wed, Apr 30, 2014As Big Data Becomes Old News Editor 2014/04/30 Nordea Invest As Big Data Becomes Old News","title":"As Big Data Becomes Old News"},{"path":"/press/2014/05/29/computer-programming-is-a-dying-art/","text":"Computer Programming is a Dying Art Thu, May 29, 2014Computer Programming is a Dying Art Kevin Maney 2014/05/29 Newsweek Computer Programming is a Dying Art","title":"Computer Programming is a Dying Art"},{"path":"/press/2014/06/03/big-data-dump-overwhelms-spy-agencies/","text":"The Big Data Dump: How Info-Hoarding Can Overwhelm Startups and Spy Agencies Tue, Jun 03, 2014The Big Data Dump: How Info-Hoarding Can Overwhelm Startups and Spy Agencies Jordan Robertson 2014/06/03 Bloomberg The Big Data Dump: How Info-Hoarding Can Overwhelm Startups and Spy Agencies","title":"The Big Data Dump: How Info-Hoarding Can Overwhelm Startups and Spy Agencies"},{"path":"/press/2014/07/09/numenta-apps-mimic-way-brain-works/","text":"After Nine Years of Research Numenta Finally Has Apps That Mimic the Way the Brain Works Wed, Jul 09, 2014After Nine Years of Research Numenta Finally Has Apps That Mimic the Way the Brain Works Dean Takahashi 2014/07/09 Venture Beat After Nine Years of Research Numenta Finally Has Apps That Mimic the Way the Brain Works","title":"After Nine Years of Research Numenta Finally Has Apps That Mimic the Way the Brain Works"},{"path":"/press/2014/08/13/when-cloud-monitoring-falls-short/","text":"Network Monitoring Tools For When Cloud Monitoring Falls Short Wed, Aug 13, 2014Network Monitoring Tools For When Cloud Monitoring Falls Short Dan Sullivan 2014/08/13 Search Cloud Computing Network Monitoring Tools For When Cloud Monitoring Falls Short","title":"Network Monitoring Tools For When Cloud Monitoring Falls Short"},{"path":"/press/2014/09/02/mimicking-brain-function-is-revolutionising-nlp/","text":"How Mimicking Brain Function is Revolutionising NLP Tue, Sep 02, 2014How Mimicking Brain Function is Revolutionising NLP Eileen McNulty 2014/09/02 Dataconomy How Mimicking Brain Function is Revolutionising NLP","title":"How Mimicking Brain Function is Revolutionising NLP"},{"path":"/press/2014/09/05/cognitive-computing-truly-amazing-apps/","text":"Cognitive Computing Makes It Possible To Build Truly Amazing Apps Fri, Sep 05, 2014Cognitive Computing Makes It Possible To Build Truly Amazing Apps Janet Wagner 2014/09/05 ProgrammableWeb Cognitive Computing Makes It Possible To Build Truly Amazing Apps","title":"Cognitive Computing Makes It Possible To Build Truly Amazing Apps"},{"path":"/press/2014/09/16/ten-machine-learning-experts/","text":"Ten Machine Learning Experts You Need to Know Tue, Sep 16, 2014Ten Machine Learning Experts You Need to Know Eileen McNulty 2014/09/16 Dataconomy Ten Machine Learning Experts You Need to Know","title":"Ten Machine Learning Experts You Need to Know"},{"path":"/press/2014/09/24/jeff-hawkins-on-his-approach-to-ai/","text":"Jeff Hawkins on why his approach to AI will become the approach to AI Wed, Sep 24, 2014Jeff Hawkins on why his approach to AI will become the approach to AI Derrick Harris 2014/09/24 Gigaom Jeff Hawkins on why his approach to AI will become the approach to AI","title":"Jeff Hawkins on why his approach to AI will become the approach to AI"},{"path":"/press/2014/10/22/jeff-hawkins-limitations-of-artificial-neural-networks/","text":"Jeff Hawkins on the Limitations of Artificial Neural Networks Wed, Oct 22, 2014Jeff Hawkins on the Limitations of Artificial Neural Networks Augustus Van Dusen 2014/10/22 Thinking Machine Jeff Hawkins on the Limitations of Artificial Neural Networks","title":"Jeff Hawkins on the Limitations of Artificial Neural Networks"},{"path":"/press/2014/11/05/numenta-showcases-new-version-grok-aws-reinvent-2014/","text":"Numenta to Showcase New Version of Grok at AWS reInvent 2014 Wed, Nov 05, 2014 PressNumenta to Showcase New Version of Grok at AWS reInvent 2014 Numenta Press Release NOTE: Numenta has announced a strategic partnership with Avik Partners, please read more about the future of Grok for IT Analytics. REDWOOD CITY, Calif. --(BUSINESS WIRE) Numenta Inc., a leader in machine intelligence technology, today announced the newest release of Grok IT for Analytics. The application, which runs on Amazon Web Services, will be featured at the upcoming AWS re:Invent 2014, November 11-14 in Las Vegas. Visit Numenta and see Grok in action at AWS Booth 648. Based on Numenta s breakthrough Hierarchical Temporal Memory technology, Grok monitors servers running on AWS and enables complex pattern detection, automatic model building, and continuous learning. Grok output is displayed on a constantly updated mobile device, enabling IT professionals to assess the health of their systems anytime, anywhere. The latest Grok 1.6 release features: - A major new feature called Annotations, which allows sharing of information and collaboration among users - Increased ability to support additional sources and formats of data - Enhanced performance Grok enables IT professionals to easily spot unusual activity and to gain immediate insights into the health of their critical IT systems. Now, with annotations, they can more easily share these insights with colleagues, enabling the organization to get ahead of problems before they become serious, noted Numenta CEO Donna Dubinsky. Unlike other tools that rely on static thresholds or simple statistics, Grok automatically learns complex patterns in the AWS environment, and then identifies unusual behavior in those systems. Key features of Grok IT for Analytics include: - Very easy configuration and set-up - Automatically models each metric to determine normal patterns - Automatically identifies and ranks unusual patterns - Continuously learns new patterns as environments evolve - Does not require any manual threshold setting - Notifies the user when something curious is happening - Displays output graphically on a mobile Android device To learn more about use cases for IT operators, and to download Grok, please visit http://grokstream.com. About Numenta Numenta, Inc. was founded in 2005 to be a catalyst in the new era of machine intelligence. Its biologically inspired machine learning technology is based on a theory of the neocortex first described in co-founder Jeff Hawkins book, On Intelligence. The technology can be applied to anomaly detection in servers and applications, human behavior, and geo-spatial tracking data, and to the predication and classification of natural language. In addition, Numenta has created NuPIC (Numenta Platform for Intelligent Computing) as an open source project. Based in Redwood City, CA, the company is privately funded. For more information go to numenta.com. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2014/11/05 Press Release Numenta to Showcase New Version of Grok at AWS reInvent 2014","title":"Numenta to Showcase New Version of Grok at AWS reInvent 2014"},{"path":"/press/2014/11/10/innovation-lite-modern-day-technology-is-stuck/","text":"Innovation Lite - Modern-Day Technology is Stuck Mon, Nov 10, 2014Innovation Lite - Modern-Day Technology is Stuck Kevin Maney 2014/11/10 Newsweek Innovation Lite - Modern-Day Technology is Stuck","title":"Innovation Lite - Modern-Day Technology is Stuck"},{"path":"/press/2014/11/12/cortical-io-gain-over-1-million-in-new-venture-capital/","text":"Cortical.io Gain $1.25 Million in New Venture Capital, Share Grand Plans for The Future Wed, Nov 12, 2014Cortical.io Gain $1.25 Million in New Venture Capital, Share Grand Plans for The Future Eileen McNulty 2014/11/12 Dataconomy Cortical.io Gain $1.25 Million in New Venture Capital, Share Grand Plans for The Future","title":"Cortical.io Gain $1.25 Million in New Venture Capital, Share Grand Plans for The Future"},{"path":"/press/2014/11/21/cognitive-computing-what-it-means-to-you/","text":"Cognitive Computing - What It Means To You Fri, Nov 21, 2014Cognitive Computing - What It Means To You Dan Hartveld 2014/11/21 Techworld Cognitive Computing - What It Means To You","title":"Cognitive Computing - What It Means To You"},{"path":"/press/2014/12/09/smart-panel-ponders-ais-future/","text":"Smart Panel Ponders AI&#x27;s Future Tue, Dec 09, 2014Smart Panel Ponders AI's Future Jessica Lipsky 2014/12/09 EE Times Smart Panel Ponders AI's Future","title":"Smart Panel Ponders AI&#x27;s Future"},{"path":"/press/2014/12/29/deep-learning-and-machine-intelligence-eat-the-world-2015/","text":"Tech 2015 Deep Learning And Machine Intelligence Will Eat The World Mon, Dec 29, 2014Tech 2015 Deep Learning And Machine Intelligence Will Eat The World Anthony Wing Kosner 2014/12/29 Forbes Tech 2015 Deep Learning And Machine Intelligence Will Eat The World","title":"Tech 2015 Deep Learning And Machine Intelligence Will Eat The World"},{"path":"/press/2015/01/09/artificial-intelligence-is-real-now/","text":"Artificial Intelligence Is Real Now and It’s Just Getting Started Fri, Jan 09, 2015Artificial Intelligence Is Real Now and It s Just Getting Started Derrick Harris 2015/01/09 GigaOm Artificial Intelligence Is Real Now and It’s Just Getting Started","title":"Artificial Intelligence Is Real Now and It’s Just Getting Started"},{"path":"/press/2015/02/19/life-happens-ai-will-happen-probably-at-ibm-numenta/","text":"Life happens, AI will happen, probably at IBM/Numenta Thu, Feb 19, 2015Life happens, AI will happen, probably at IBM/Numenta Alex Alaniz 2015/02/19 Science 2.0 Life happens, AI will happen, probably at IBM/Numenta","title":"Life happens, AI will happen, probably at IBM/Numenta"},{"path":"/press/2015/03/02/terminator-not-coming-future-will-thank-us/","text":"The Terminator Is Not Coming. The Future Will Thank Us. Mon, Mar 02, 2015The Terminator Is Not Coming. The Future Will Thank Us. Jeff Hawkins 2015/03/02 Re/Code The Terminator Is Not Coming. The Future Will Thank Us.","title":"The Terminator Is Not Coming. The Future Will Thank Us."},{"path":"/press/2015/03/05/many-scientists-dismiss-the-fear-of-robots-heres-why/","text":"Many Scientists Dismiss the Fear of Robots — Here&#x27;s Why Thu, Mar 05, 2015Many Scientists Dismiss the Fear of Robots Here's Why Erik Sherman 2015/03/05 Fortune Many Scientists Dismiss the Fear of Robots — Here's Why","title":"Many Scientists Dismiss the Fear of Robots — Here&#x27;s Why"},{"path":"/press/2015/03/26/artificial-intelligence-could-have-prevented-the-germanwings-crash/","text":"Artificial Intelligence Could Have Prevented The Germanwings Crash Thu, Mar 26, 2015Artificial Intelligence Could Have Prevented The Germanwings Crash Anthony Wing Kosner 2015/03/26 Forbes Artificial Intelligence Could Have Prevented The Germanwings Crash","title":"Artificial Intelligence Could Have Prevented The Germanwings Crash"},{"path":"/press/2015/04/02/how-we-learn-to-stop-worrying-and-love-the-bots/","text":"How We Learn to Stop Worrying and Love the Bots Thu, Apr 02, 2015How We Learn to Stop Worrying and Love the Bots Wired 2015/04/02 Wired How We Learn to Stop Worrying and Love the Bots","title":"How We Learn to Stop Worrying and Love the Bots"},{"path":"/press/2015/04/08/ibm-tests-mobile-computing-pioneers-controversial-brain-algorithms/","text":"IBM Tests Mobile Computing Pioneer’s Controversial Brain Algorithms Wed, Apr 08, 2015IBM Tests Mobile Computing Pioneer s Controversial Brain Algorithms Tom Simonite 2015/04/08 MIT Technology Review IBM Tests Mobile Computing Pioneer’s Controversial Brain Algorithms","title":"IBM Tests Mobile Computing Pioneer’s Controversial Brain Algorithms"},{"path":"/press/2015/04/14/numenta-the-bruce-lee-of-ai-and-deep-learning/","text":"Numenta, The Bruce Lee of AI and Deep Learning Tue, Apr 14, 2015Numenta, The Bruce Lee of AI and Deep Learning Alex Alaniz 2015/04/14 Science 2.0 Numenta, The Bruce Lee of AI and Deep Learning","title":"Numenta, The Bruce Lee of AI and Deep Learning"},{"path":"/press/2015/05/07/jeff-hawkins-of-firing-up-the-silicon-brain/","text":"Jeff Hawkins on Firing Up the Silicon Brain Thu, May 07, 2015Jeff Hawkins on Firing Up the Silicon Brain Caleb Garling 2015/05/07 Wired Jeff Hawkins on Firing Up the Silicon Brain","title":"Jeff Hawkins on Firing Up the Silicon Brain"},{"path":"/press/2015/05/14/numenta-and-cortical-io-form-strategic-partnership/","text":"Numenta and Cortical.io Form Strategic Partnership Thu, May 14, 2015 PressNumenta and Cortical.io Form Strategic Partnership Numenta Press Release Redwood City, CA May 14, 2015 Numenta, Inc., a leader in machine intelligence, and Cortical.io, an innovator in natural language processing (NLP), are pleased to announce a strategic partnership to create a new computing approach to understanding text. As part of the strategic relationship, Cortical.io has taken a broad general license to Numenta s Hierarchical Temporal Memory (HTM) technology, and Numenta has taken an ownership position in Cortical.io. The combination of Cortical.io s Semantic Folding technology and Numenta s HTM technology enables a host of exciting applications that have challenged computer scientists for decades, including sentiment analysis, automatic summarization, semantic search, and conversational dialogue systems. Cortical.io s Semantic Folding technology is a clever and elegant way to feed natural language into our HTM technology , said Jeff Hawkins, founder of Numenta. Cortical.io takes advantage of the semantic encoding and predictive modeling of HTM systems in a way that will lead to significant advances in natural language processing. Natural language understanding is one of the central problems of artificial intelligence, said Francisco Webber, founder and CEO of Cortical.io. We aim to build the next generation of NLP, Language Intelligence, and in so doing, show the path to broadly applied machine intelligence. Building on their existing commercial product, the Retina API, Cortical.io will make the combined technologies available through their industrial-grade cloud service for customers ranging from innovative startups to international corporations. About Cortical.io Headquartered in Vienna, Austria, Cortical.io is a science-based start-up that has developed a fundamentally new approach to Natural Language Processing (NLP), Semantic Folding, inspired by the latest findings on the way the human neocortex processes information. By representing language with highly efficient semantic fingerprints, the Retina API is the first semantic engine that painlessly handles the avalanche of text data experienced by global business today in any language and in real-time. A US subsidiary has been incorporated recently. Cortical.io Media Contact: Marie-Pierre Garnier, Cortical.io: mp.garnier@Cortical.io About Numenta Numenta, Inc., was founded in 2005 to be a leader in the emerging field of machine intelligence. Numenta builds technology that helps companies automatically and intelligently act on machine generated data. Its biologically inspired machine learning technology is based on a theory of the neocortex first described in co-founder Jeff Hawkins book, On Intelligence. Its first commercial product, called Grok, offers a breakthrough solution for anomaly detection for IT Operations. In addition, Numenta has created NuPIC (Numenta Platform for Intelligent Computing) as an open source project (http://numenta.org). Numenta is based in Redwood City, California. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2015/05/14 Press Release Numenta and Cortical.io Form Strategic Partnership","title":"Numenta and Cortical.io Form Strategic Partnership"},{"path":"/press/2015/05/22/numenta-and-ibm-to-build-biologically-inspired-intelligent-machines/","text":"Numenta And IBM To Build Biologically Inspired Intelligent Machines Fri, May 22, 2015Numenta And IBM To Build Biologically Inspired Intelligent Machines Alex Alaniz 2015/05/22 Science 2.0 Numenta And IBM To Build Biologically Inspired Intelligent Machines","title":"Numenta And IBM To Build Biologically Inspired Intelligent Machines"},{"path":"/press/2015/05/22/on-gps-with-fareed-zakaria-the-threat-of-intelligent-machines/","text":"On GPS: The Threat of Intelligent Machines Fri, May 22, 2015On GPS: The Threat of Intelligent Machines Fareed Zakaria, GPS 2015/05/22 CNN On GPS: The Threat of Intelligent Machines","title":"On GPS: The Threat of Intelligent Machines"},{"path":"/press/2015/07/08/numenta-grok-for-stocks-app-uses-ai-decipher-stock-market-patterns/","text":"Numenta’s HTM for Stocks app uses A.I. to decipher stock market patterns Wed, Jul 08, 2015Numenta s HTM for Stocks app uses A.I. to decipher stock market patterns Dean Takahashi 2015/07/08 VentureBeat Numenta’s HTM for Stocks app uses A.I. to decipher stock market patterns","title":"Numenta’s HTM for Stocks app uses A.I. to decipher stock market patterns"},{"path":"/press/2015/07/08/numenta-ships-new-htm-example-app-htm-for-stocks/","text":"Numenta Ships New HTM Example App: HTM for Stocks Wed, Jul 08, 2015 PressNumenta Ships New HTM Example App: HTM for Stocks Numenta Press Release An Easy Way to Experience HTM Machine Learning Technology Redwood City, CA July 8, 2015 Numenta, Inc., today announced the availability of HTM for Stocks, the newest example application showing how Hierarchical Temporal Memory (HTM) technology can be applied to streaming data and the Internet of Things. HTM for Stocks is a mobile application that continually monitors stock price, stock volume, and Twitter activity for hundreds of publicly traded companies. HTM for Stocks learns the normal patterns for each company and notifies you if something unusual is happening to any of the companies. During the past two years, Numenta has created a series of example applications to illustrate the capabilities of HTM. The first application, Grok for IT Analytics, uses HTM to detect anomalies in AWS server metrics and is available at http://grokstream.com. Numenta also published example source code that uses HTM to detect anomalies in human behavior and in GPS tracking data. HTM for Stocks is our most accessible demonstration of Numenta HTM technology, said Numenta CEO Donna Dubinsky. Until now, it has required programming expertise to experience HTM-based anomaly detection. With HTM for Stocks, it is as simple as downloading the app to your smartphone from the Google Play store. In keeping with its mission to be a technology provider, Numenta is providing the source code for HTM for Stocks under an open source license at: https://github.com/numenta/numenta-apps. Said Dubinsky, We encourage developers to use the HTM for Stocks code to create derivative products that track a variety of data streams. HTM for Stocks shows how thousands of data streams can be made useful in a mobile application using HTM technology. How HTM for Stocks Works HTM for Stocks applies Numenta s HTM modeling and anomaly detection to 200 large capitalization public companies. It automatically models three data streams for each company: stock volume, stock price, and Twitter volume. The HTM models learn continuously, receiving new data every five minutes. HTM learns what is normal for each of the data streams for each company. The companies are ranked from the most anomalous to the least anomalous over the previous hour. HTM for Stocks lets you see the text of the Tweets as well, often explaining why the company is showing an anomaly. About Numenta Numenta, Inc., is a leader in the field of machine intelligence. Numenta builds technology that helps companies automatically act on streaming data. Its machine learning technology is based on a theory of the neocortex first described in co-founder Jeff Hawkins book, On Intelligence. In addition, Numenta has created NuPIC (Numenta Platform for Intelligent Computing) as an open source project (http://numenta.org). Numenta is based in Redwood City, California. To obtain more info about partnering and licenses write to sales@numenta.com. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2015/07/08 Press Release Numenta Ships New HTM Example App: HTM for Stocks","title":"Numenta Ships New HTM Example App: HTM for Stocks"},{"path":"/press/2015/08/19/numenta-announces-licensing-of-grok-for-it-to-avik-partners/","text":"Numenta Announces Licensing of Grok for IT Analytics to Avik Partners Wed, Aug 19, 2015 PressNumenta Announces Licensing of Grok for IT Analytics to Avik Partners Numenta Press Release REDWOOD CITY, CA August 19, 2015 Numenta, Inc., a leader in machine intelligence, today announced a strategic partnership with Avik Partners, a new IT services and advanced analytics company, for its Grok for IT Analytics on AWS technology. The announcement was made during the Smart Data Conference being held in San Jose, CA. (See Numenta at Booth #406). Grok for IT Analytics on AWS detects anomalies in Amazon Web Services server metrics and is currently available at http://grokstream.com. As part of this strategic relationship, Numenta will transfer the Grok application and the Grok brand to Avik under a broad general licensing agreement for Numenta s Hierarchical Temporal Memory (HTM) technology. Numenta also will take a minority ownership position in Avik. Our core HTM technology can be applied to such a broad array of machine intelligence solutions, it would be impossible for us to pursue commercialization in all of these verticals. We decided that the best approach for us, like that taken by premier research institutions, is a licensing and technology transfer model. It is an exciting way for us to see our HTM applications built out for commercial use, said Numenta CEO Donna Dubinsky. She added, In Casey Kindiger, the CEO of Avik, we found the perfect match to take Grok for IT Analytics and run with it. He is a proven entrepreneur who is starting this new venture to apply HTM technology to solve problems in IT analytics. Kindiger, a veteran enterprise software solutions provider and consultant, founded Avik after more than a decade of designing and developing process automation solutions for companies like JP Morgan Chase, T-Mobile, Allstate Insurance, and others. HTM offers substantially better technology for finding anomalies and is well suited to the needs of today s streaming data in IT and dev ops environments, said Kindiger. We are very excited to be able to take the Grok technology and brand, move it forward and build on it. During the past two years, Numenta has created a series of example applications to illustrate the capabilities of HTM, beginning with Grok for IT Analytics on AWS. The HTM technology also has been applied to anomaly detection in stock prices and volumes (HTM for Stocks), human behavior, geo-spatial tracking data, and to the predication and classification of natural language. For the latter application, Numenta recently announced a partnership and licensing agreement with Cortical.io, an innovator in natural language processing (NLP), to license HTM and use the technology for the development of language intelligence products. We will continue to create example applications to inspire others, and hope to create a constellation of partnerships like Avik and Cortical.io going forward to enable broad commercialization of HTM technology, Dubinsky concluded. Numenta, Inc. was founded in 2005 to be a leader in the emerging field of machine intelligence. Numenta builds technology that helps companies automatically and intelligently act on machine generated data. Its biologically inspired machine learning technology is based on a theory of the neocortex first described in co-founder Jeff Hawkins book, On Intelligence. In addition, Numenta has created NuPIC (Numenta Platform for Intelligent Computing) as an open source project (http://numenta.org). Numenta is based in Redwood City, California. To contact Avik Partners and for further information about Grok for IT Analytics, go to http://grokstream.com. Avik Partners Media Contact: Paula Johns: paula@paulajohnscommunications.com Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2015/08/19 Press Release Numenta Announces Licensing of Grok for IT Analytics to Avik Partners","title":"Numenta Announces Licensing of Grok for IT Analytics to Avik Partners"},{"path":"/press/2015/09/05/numentas-grok-for-it-artificial-intelligence-meets-network-performance-analysis/","text":"Numenta&#x27;s Grok for IT: Artificial Intelligence Meets Network Performance Analysis Sat, Sep 05, 2015Numenta's Grok for IT: Artificial Intelligence Meets Network Performance Analysis Mark Gibbs 2015/09/05 Network World Numenta's Grok for IT: Artificial Intelligence Meets Network Performance Analysis","title":"Numenta&#x27;s Grok for IT: Artificial Intelligence Meets Network Performance Analysis"},{"path":"/press/2015/10/06/avik-partners-unfurls-machine-learning-service-to-optimize-it-operations/","text":"Avik Partners Unfurls Machine Learning Service to Optimize IT Operations Tue, Oct 06, 2015Avik Partners Unfurls Machine Learning Service to Optimize IT Operations Mike Vizard 2015/10/06 IT Business Edge Avik Partners Unfurls Machine Learning Service to Optimize IT Operations","title":"Avik Partners Unfurls Machine Learning Service to Optimize IT Operations"},{"path":"/press/2015/10/29/usd-2-million-for-brain-inspired-algorithm-made-in-austria-cortical-io/","text":"USD 1.8 Million for Cortical.io Brain-Inspired Algorithm Made in Austria Thu, Oct 29, 2015USD 1.8 Million for Cortical.io Brain-Inspired Algorithm Made in Austria Cortical.io 2015/10/29 PRWeb USD 1.8 Million for Cortical.io Brain-Inspired Algorithm Made in Austria","title":"USD 1.8 Million for Cortical.io Brain-Inspired Algorithm Made in Austria"},{"path":"/press/2015/11/10/numenta-anomaly-benchmark-nab-evaluates-anomaly-detection-techniques/","text":"Numenta Anomaly Benchmark Evaluates Anomaly Detection Techniques for Real-time, Streaming Data Tue, Nov 10, 2015 PressNumenta Anomaly Benchmark Evaluates Anomaly Detection Techniques for Real-time, Streaming Data Numenta Press Release Open Source Tool Tests Effectiveness of Algorithms on IoT Data REDWOOD CITY, CA November 10, 2015 Numenta, Inc., a leader in machine intelligence, today launched the Numenta Anomaly Benchmark (NAB), an open-source benchmark and tool designed to help data researchers evaluate the effectiveness of algorithms for anomaly detection in streaming, real-time applications. Anomalies in streaming data are patterns that do not conform to past patterns of behavior for a given data stream. Until now, no benchmark has existed to evaluate anomaly detection in real-time streaming data. NAB will be publicly unveiled on November 13 during MLconf in San Francisco in a presentation by Numenta Research VP Subutai Ahmad, Real-time Anomaly Detection for Real-time Data Needs. A peer-reviewed paper on NAB also was accepted by the IEEE Conference on Machine Learning and Applications and will be presented during the conference on December 9-11 in Miami. The Need for Anomaly Detection in Time-Series Data Explosive growth in streaming data is happening across industries, largely driven by the rise of the Internet of Things (IoT) and the proliferation of connected real-time data sources and applications with sensors producing waves of data. Voluminous amounts of this data are being stored for later analysis, though it often isn t necessary or practical to capture and store all the information. Instead, data analysts need a way to analyze time-series data in real time, identify when something is different and act upon that insight. Different approaches are being pursued to solve this problem, in the form of anomaly detection algorithms. But until now, a measurement to gauge the effectiveness of real-time anomaly detection algorithms has been lacking. With this goal in mind, Numenta created NAB. There is an explosion in real-time streaming data sources. Data owners want to be able to model this data and figure out if anything has changed, commented Numenta CEO Donna Dubinsky. We created this open benchmark as a tool to help data scientists evaluate the effectiveness of different algorithms in finding anomalous behavior in these data streams. Early anomaly detection in streaming data has practical and significant applications across many industries from monitoring critical IT infrastructure to detecting potential fraudulent financial transactions, from understanding energy consumption to geo-tracking of vehicles in logistics networks. The Numenta Anomaly Benchmark NAB is an open source framework that was created to help data professionals test, score and evaluate anomaly detection algorithms on time-series data and to compare their internal anomaly detection techniques to published algorithms. NAB also allows people to test their algorithms against Numenta s HTM detector, which is based on Numenta s Hierarchical Temporal Memory technology. It uses a biologically inspired memory prediction algorithm to model real-time data streams and continuously learns. The major components to the NAB framework include: - Real-world data. Includes 58 labeled streaming data files that are a combination of real-world data sets along with some simulated datasets. All anomalies are marked. - Anomaly windows. These are defined ranges of data points that surround a known anomaly label. NAB uses these windows to decide whether, and how early, an algorithm detected each anomaly. - A scoring mechanism. Scoring is specifically designed for streaming data and rewards early detection. NAB s emphasis on anomaly windows and early detection is pioneering. In addition the research community stands to benefit greatly from an open dataset containing real world data, and an open source tool for measuring the effectiveness of real-time anomaly detection algorithms, said Varun Chandola, Assistant Professor in Computer Science and Engineering, SUNY Buffalo. Having a standard benchmark could spur innovation in real-time anomaly detection algorithms. Our hope is the open source community will add new data sets, propose different scoring mechanisms, and test and compare other algorithms with our HTM algorithms, said Dubinsky. For more detailed information on NAB, go to: - NAB Peer-Reviewed Research Paper - NAB Business White Paper - Numenta Anomaly Benchmark Repository - Algorithm & product code About Numenta Founded in 2005, Numenta has developed a cohesive theory, core software technology, and numerous applications all based on principles of the neocortex. Laying the groundwork for the new era of machine intelligence, this technology is ideal for large-scale analysis of continuously streaming data sets and excels at modeling and predicting patterns in data. Numenta has also developed a suite of products and demonstration applications that utilize its flexible and generalizable HTM learning algorithms to provide solutions that encompass the fields of machine generated data, human behavioral modeling, geo-location processing, semantic understanding and sensory-motor control. In addition, Numenta has created NuPIC (Numenta Platform for Intelligent Computing) as an open source project. Numenta is based in Redwood City, California. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn BusinessWire Numenta Press Release All Press Posts Numenta 2015/11/10 Press Release Numenta Anomaly Benchmark Evaluates Anomaly Detection Techniques for Real-time, Streaming Data","title":"Numenta Anomaly Benchmark Evaluates Anomaly Detection Techniques for Real-time, Streaming Data"},{"path":"/press/2015/11/12/single-artificial-neuron-taught-to-recognize-hundreds-of-patterns/","text":"Single Artificial Neuron Taught to Recognize Hundreds of Patterns Thu, Nov 12, 2015Single Artificial Neuron Taught to Recognize Hundreds of Patterns Emerging Technology 2015/11/12 MIT Technology Review Single Artificial Neuron Taught to Recognize Hundreds of Patterns","title":"Single Artificial Neuron Taught to Recognize Hundreds of Patterns"},{"path":"/press/2016/03/07/the-terminator-and-the-washing-machine/","text":"The Terminator and the Washing Machine Mon, Mar 07, 2016The Terminator and the Washing Machine U.S. & Politics Retro Report 2016/03/07 The New York Times The Terminator and the Washing Machine","title":"The Terminator and the Washing Machine"},{"path":"/press/2016/04/12/numenta-researchers-discover-how-the-brain-learns-sequences/","text":"Numenta Researchers Discover How The Brain Learns Sequences, A Key to Intelligent Systems Tue, Apr 12, 2016 PressNumenta Researchers Discover How The Brain Learns Sequences, A Key to Intelligent Systems Numenta Press Release REDWOOD CITY, CA April 12, 2016 How do our brains learn and understand the world? That question is of paramount importance to both neuroscientists and technologists who want to build intelligent machines. It has been understood for over a hundred years that the inputs and outputs of the brain are constantly changing sequences of patterns and therefore learning and recalling sequences must be a fundamental operation of neurons. Numerous proposals have been made for how neural networks might learn sequences. However, these proposals did not match the anatomy and function observed in the brain. Numenta s theory of how the brain learns and understands sequences of patterns may be an essential component for creating intelligent machines Now, researchers at Numenta Inc. have published a new theory that represents a breakthrough in understanding how networks of neurons in the neocortex learn sequences. A paper, authored by Numenta co-founder Jeff Hawkins and VP of Research Subutai Ahmad, Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex, * has been published in the Frontiers in Neural Circuits Journal, a publication devoted to research in neural circuits, serving the worldwide neuroscience community. This study is a key milestone on the path to achieving that long-sought goal of creating truly intelligent machines that simulate human cerebral cortex and forebrain system operations, commented Michael Merzenich, PhD, Professor Emeritus UCSF, Chief Scientific Officer for Posit Science. The Numenta paper introduces two advances. First, it provides an explanation of why neurons in the neocortex have thousands of synapses, and why the synapses are segregated onto different parts of the cell, called dendrites. The authors propose that the majority of these synapses are used to learn transitions of patterns, a feature missing from most artificial neural networks. Second, the authors show that neurons with these properties, arranged in layers and columns - a structure observed throughout the neocortex - form a powerful sequence memory. This suggests the new sequence memory algorithm could be a unifying principle for understanding how the neocortex works. Through simulations, the authors show the new sequence memory exhibits a number of important properties such as the ability to learn complex sequences, continuous unsupervised learning, and extremely high fault tolerance. Comparison of Biological and Artificial Neuron Models The Hawkins-Ahmad paper on the theory of sequence memory in the neocortex proposes a model of cortical neurons that explains why they have thousands of synapses, why the synapses are segregated onto different parts of the dendrites, and how neurons integrate this input in a functionally meaningful way. This diagram draws a comparison between the human neocortical pyramidal neuron, the HTM biologically-inspired neuron model, and the model used in most mathematically-inspired artificial neural networks and Deep Learning models today. Our paper makes contributions in both neuroscience and machine learning, Hawkins noted. From a neuroscience perspective, it offers a computational model of pyramidal neurons, explaining how a neuron can effectively use thousands of synapses and computationally active dendrites to learn sequences. From a machine learning and computer science perspective, it introduces a new sequence memory algorithm that we believe will be important in building intelligent machines. This research extends the work Jeff first outlined in his 2004 book On Intelligence and encompasses many years of research we have undertaken here at Numenta, said Ahmad, It explains the neuroscience behind our HTM (Hierarchical Temporal Memory) technology and makes several detailed predictions that can be experimentally verified. The software we have created proves that the theory actually works in real world applications. Numenta s primary goal is to reverse engineer the neocortex, to understand the detailed biology underlying intelligence. The Numenta team also believes this is the quickest route to creating machine intelligence. As a result of this approach, the neuron and network models described in the new paper are strikingly different than the neuron and network models being used in today s deep learning and other artificial neural networks. Functionally, the new theory addresses several of the biggest challenges confronting deep learning today, such as the lack of continuous and unsupervised learning. *Hawkins, J., and Ahmad, S. (2016). Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex. Front. Neural Circuits 10. doi:10.3389/fncir.2016.00023 About Frontiers in Neural Circuits Frontiers is a leading open-access publisher. Established in 2007, Frontiers drives innovations in peer review, post-publication review, impact metrics, and an ecosystem of open-science tools. Frontiers has published over 43,000 articles across 55 journals and over 400 disciplines, which receive 4 million monthly views, and are supported by over 210,000 researchers. About Numenta Founded in 2005, Numenta develops theory, software technology, and applications all based on reverse engineering the neocortex. Laying the groundwork for the new era of machine intelligence, this technology is ideal for analysis of continuously streaming data sets and excels at modeling and predicting patterns in data. Numenta has also developed a suite of products and demonstration applications that utilize its flexible and generalizable Hierarchical Temporal Memory (HTM) learning algorithms to provide solutions that encompass the fields of machine generated data, human behavioral modeling, geo-location processing, semantic understanding and sensory-motor control. In addition, Numenta has created NuPIC (Numenta Platform for Intelligent Computing) as an open source project. Numenta is based in Redwood City, California. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn Numenta Press Release All Press Posts Numenta 2016/04/12 Press Release Numenta Researchers Discover How The Brain Learns Sequences, A Key to Intelligent Systems","title":"Numenta Researchers Discover How The Brain Learns Sequences, A Key to Intelligent Systems"},{"path":"/press/2016/05/01/brain-like-computing/","text":"Brain-Like Computing Sun, May 01, 2016Brain-Like Computing Tiejun Huang 2016/05/01 Computing Now Brain-Like Computing","title":"Brain-Like Computing"},{"path":"/press/2016/05/22/new-chips-propel-machine-learning/","text":"New Chips Propel Machine Learning Sun, May 22, 2016New Chips Propel Machine Learning Don Clark 2016/05/22 Wall Street Journal New Chips Propel Machine Learning","title":"New Chips Propel Machine Learning"},{"path":"/press/2016/05/29/donna-dubinsky-standing-up-to-steve-jobs-and-being-right/","text":"Donna Dubinsky – Standing Up To Steve Jobs And Being Right Sun, May 29, 2016Donna Dubinsky Standing Up To Steve Jobs And Being Right Ryan Hawk 2016/05/29 Learning Leader Donna Dubinsky – Standing Up To Steve Jobs And Being Right","title":"Donna Dubinsky – Standing Up To Steve Jobs And Being Right"},{"path":"/press/2016/06/16/here-is-what-uk-developers-need-to-know-about-machine-learning/","text":"Here&#x27;s what UK Developers Need to Know about Machine Learning Thu, Jun 16, 2016Here's what UK Developers Need to Know about Machine Learning Charlotte Jee 2016/06/16 Techworld Here's what UK Developers Need to Know about Machine Learning","title":"Here&#x27;s what UK Developers Need to Know about Machine Learning"},{"path":"/press/2016/06/25/from-not-working-to-neural-networking/","text":"From Not Working to Neural Networking Sat, Jun 25, 2016From Not Working to Neural Networking Tom Standage 2016/06/25 Economist From Not Working to Neural Networking","title":"From Not Working to Neural Networking"},{"path":"/press/2016/06/26/numenta-releases-htm-studio/","text":"Numenta Releases HTM Studio Sun, Jun 26, 2016 PressNumenta Releases HTM Studio Numenta Press Release HTM Studio - Uncover anomalies in your streaming data REDWOOD CITY, Calif. (BUSINESS WIRE)-- Numenta, Inc., a leader in machine intelligence, today announced the release of HTM Studio for anomaly detection, a desktop tool that makes it easy for businesses to experiment with advanced machine intelligence algorithms to uncover anomalies in their streaming data. Simply add numeric, time-series data files to HTM Studio and with the click of a button, discover and visualize within minutes what anomalies can be found. #Numenta #HTMStudio for anomaly detection makes it easy to experiment with advanced machine intelligence HTM Studio is based on Numenta s HTM (Hierarchical Temporal Memory) biologically inspired machine intelligence technology. HTM learns time-based patterns in unlabeled streaming data, making it ideal for prediction, classification and anomaly detection. Because of its ability to perform continuous, unsupervised learning, HTM can find subtle, temporal anomalies that other techniques cannot find. \"I was impressed with the ease of use and how quickly it is to iterate on testing a variety of data streams. The HTM was able to pick out and forecast the needle I was interested in, within a haystack of needles, commented early beta tester Vaughn DiMarco, Lead Data Science Consultant at Montreal-based VONALYTICS. HTM Studio provides an easy way for businesses interested in using Numenta s technology for anomaly detection to undertake a proof of concept securely using their own data. If HTM Studio finds interesting anomalies, then a user can do a full implementation or deployment of HTM. Detecting anomalies early in streaming data can have significant value, but it s difficult to do. We wanted to make it easy to try HTM on your own streaming data, said Donna Dubinsky, CEO of Numenta. With HTM Studio, no coding skills are required. Parameters are automatically set. In a matter of minutes, you can visualize anomalies in your datasets. For those who don t have streaming data readily available, HTM Studio includes pre-loaded datasets for experimentation. Sample datasets include a variety of use cases: IoT sensors, preventative maintenance, tracking vehicles and network servers. The tool is available at no charge for Mac and Windows desktop systems. Go to http://numenta.com/htm-studio/ for details and to get started with HTM Studio. To learn more about HTM go to http://numenta.com. About Numenta Founded in 2005, Numenta has developed a cohesive theory, core software technology, and numerous applications all based on principles of the neocortex. Laying the groundwork for the new era of machine intelligence, this technology is ideal for large-scale analysis of continuously streaming data sets and excels at modeling and predicting patterns in data. Numenta has also developed a suite of demonstration applications that utilize its flexible and generalizable HTM learning algorithms to provide solutions that encompass the fields of machine generated data, human behavioral modeling, geo-location processing, semantic understanding and sensory-motor control. In addition, Numenta has created NuPIC (Platform for Intelligent Computing) as an open source project. Numenta is based in Redwood City, California. Numenta Media Contact: Krause Taylor Associates, Betty Taylor: bettyt@krause-taylor.com 408-981-7551 Connect with Numenta: Twitter, Facebook, YouTube and LinkedIn BusinessWire Numenta Press Release All Press Posts Numenta 2016/06/26 Press Release Numenta Releases HTM Studio","title":"Numenta Releases HTM Studio"},{"path":"/press/2016/06/27/this-is-why-your-fears-about-artificial-intelligence-are-wrong/","text":"This Is Why Your Fears About Artificial Intelligence Are Wrong Mon, Jun 27, 2016This Is Why Your Fears About Artificial Intelligence Are Wrong Kara Swisher 2016/06/27 Re/Code This Is Why Your Fears About Artificial Intelligence Are Wrong","title":"This Is Why Your Fears About Artificial Intelligence Are Wrong"},{"path":"/press/2016/07/26/machine-learning-expert-check-6-tips-for-getting-started-in-the-machine-learning/","text":"Machine Learning Expert Check: 6 Tips for Getting Started in the Machine Learning Tue, Jul 26, 2016Machine Learning Expert Check: 6 Tips for Getting Started in the Machine Learning Kypriani Sinaris 2016/07/26 Jaxenter Machine Learning Expert Check: 6 Tips for Getting Started in the Machine Learning","title":"Machine Learning Expert Check: 6 Tips for Getting Started in the Machine Learning"}]