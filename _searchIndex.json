[{"path":"/404/","text":"Page Not Found Page Not FoundSorry, the page you were looking for does not exist (404). - Please Contact Us if you are having problems, and we will respond as soon as possible. - Visit the Numenta.org homepage for more information. Page Not Found","title":"Page Not Found"},{"path":"/500/","text":"Website Server Error Website Server ErrorSorry, this website is experiencing technical difficulties (500). - Please Contact Us if you are having problems, and we will respond as quickly as possible. - Visit the Numenta.org homepage for more information. Website Server Error","title":"Website Server Error"},{"path":"/blog/2016/01/11/machine-intelligence-machine-learning-deep-learning-artificial-intelligence/","text":"What is Machine Intelligence vs. Machine Learning vs. Deep Learning vs. Artificial Intelligence (AI)? Mon, Jan 11, 2016 BlogWhat is Machine Intelligence vs. Machine Learning vs. Deep Learning vs. Artificial Intelligence (AI)? Numenta Jeff Hawkins & Donna Dubinsky We are frequently asked how we distinguish our technology from others. This task is made difficult by the fact that there is not an agreed vocabulary; everybody uses the above terms (and other associated terms) differently. In addition, the commonly understood meaning of some of these terms has evolved over time. What was meant by AI in 1960 is very different than what is meant today. In our view, there are three major approaches to building smart machines. Let s call these approaches Classic AI, Simple Neural Networks, and Biological Neural Networks. The rest of this blog post will describe and differentiate these approaches. At the end, we ll include an example as to how each approach might address the same problem. This analysis is intended for a business rather than technical audience, so we simplify somewhat and thus beg the indulgence of technical experts who might quibble with the details. Classic AI Approach The earliest approaches to AI were computer programs designed to solve problems that human brains performed easily, such as understanding text or recognizing objects in an image. Results of this work were disappointing and progress was slow. For many problems, researchers concluded that a computer had to have access to large amounts of knowledge in order to be smart . Thus they introduced expert systems , computer programs combined with rules provided by domain experts to solve problems, such as medical diagnoses, by asking a series of questions. If the disease was not properly diagnosed, the expert adds additional questions/rules to narrow the diagnosis. A Classic AI system is highly tuned for a specific problem. IBM s Watson could be viewed as a modern version of a Classic AI system. It focuses on creating a sophisticated knowledge base on a particular issue. Although Watson doesn t rely on encoded rules, it requires the close involvement of domain experts to provide data and evaluate its performance. Classic AI has solved some clearly defined problems but is limited by its inability to learn on its own and by the need to create specific solutions to individual problems. In this regard, in spite of it being called artificial intelligence, it has very little in common with general human intelligence. Simple Neural Network Approach Some early researchers explored the idea of neuron models for artificial intelligence. When the limits of Classic AI became clear, this notion picked up steam and with the addition of back propagation techniques, started proving useful. The resulting technology, artificial neural networks (ANNs), was created over 50 years ago when very little was known about how real neurons worked. Since then, neuroscientists have learned a great deal about neural anatomy and physiology, but the basic design of ANNs has changed very little. Therefore, despite the name neural networks, the design of ANNs has little in common with real neurons. Instead, the emphasis of ANNs moved from biological realism to the desire to learn from data without human supervision. Consequently, the big advantage of Simple Neural Networks over Classic AI is that they learn from data and don t require an expert to provide rules. Today ANNs are part of a broader category called machine learning which includes other mathematical and statistical techniques. Machine learning techniques, including ANNs, look at large bodies of data, extract statistics, and classify the results. ANNs have recently evolved into Deep Learning networks, whose advances have been enabled by access to fast computers and vast amounts of data for training. Deep Learning has successfully addressed many problems such as image classification, language translation and identifying spam in email. Although Simple Neural Network systems can solve many problems that were not solvable using Classic AI, they have limitations. For example, they don t work well when there is limited data for training, and they don t handle problems where the patterns in the data are constantly changing. Essentially, the Simple Neural Network approach is a sophisticated mathematical technique that finds patterns in large, static data sets. There is a deeper and more important issue beyond the current limitations of Classic AI and of Simple Neural Networks. In our view, both of these approaches are not on a path to achieve true machine intelligence; they don t provide a roadmap to get there, which brings us to the third approach. Biological Neural Network Approach Everyone agrees that the human brain is an intelligent system; in fact it is the only system everyone agrees is intelligent. We believe that by studying how the brain works we can learn what intelligence is and what properties of the brain are essential for any intelligent system. For example we know the brain represents information using sparse distributed representations (SDRs), which are essential for semantic generalization and creativity. We are confident that all truly intelligent machines will be based on SDRs. SDRs are not something that can be added to existing machine learning techniques; they are more like a foundation upon which everything else depends. Other essential attributes include that memory is primarily a sequences of patterns, that behavior is an essential part of all learning, and that learning must be continuous. In addition, we now know that biological neurons are far more sophisticated than the simple neurons used in the Simple Neural Network approach and the differences matter. We believe you can t get to machine intelligence by incrementally building upon the simple neuron approach, but instead must throw it away and start over with a more realistic biological approach. Numenta s technology, Hierarchical Temporal Memory (HTM), is the best example of the Biological Neural Network approach. Today, HTM systems are able to learn the structure of streaming data, make predictions and detect anomalies. They learn continuously from unlabeled data. By taking a robust biological approach, the brain gives us a roadmap of where to direct our work in the future, such as completing our understanding of behavior, attention and short term memory. This roadmap distinguishes HTM from other techniques and makes it the best candidate for creating intelligent machines. An Example Let s take a problem and think about how it might be addressed in the three different approaches. Again, we oversimplify a bit in order to distinguish the main differences of the three approaches. We have been asked to detect rogue behavior of an employee within an organization. For example, companies with confidential information want to know if people with internal access are abusing that information. A change in employee behavior might be totally legitimate the employee has changed roles, and now has new responsibilities or it could be a problem. Rogue behavior is difficult to identify. The Classic AI approach would address this problem with a series of rules. For example, let s consider an analyst who works with confidential customer data. The Classic AI system would need a human to figure out likely problem scenarios then program the system to look for those scenarios. This solution might flag any instance where the analyst has accessed the customer file more than 10 times in the month. As the Classic AI system is deployed, and false positives and false negatives are examined, the rules would be strengthened. The new rule might say that an analyst accessing customer data in the first few days of the month is not flagged, but it is for the remainder of the month. The Simple Neural Network approach would start with lots of historical data, namely a large database of known problem scenarios. The Simple Neuron Network system might figure out, for example, that abuse of this information only happens in the last week of the month. The system identifies such features and then classifies an individual as unusual or not unusual . Although it sounds similar to the Classic AI approach, in this case, the features are learned from the data, not from an expert. Both approaches have some problems. With the Classic AI solution you need to know what you are looking for. But criminals constantly change strategies to avoid detection and the rules don t adapt. The Simple Neural Network approach requires a lot of labeled data to be able to find common features, but this kind of data generally doesn t exist for unusual behavior. Both approaches are unsuitable for modeling individual behaviors and require the system to be retrained when new patterns arise. The Biological Neural Network approach would stream the data from each analyst (such as the details of the files routinely accessed, numbers of emails, numbers of postings, etc.) and would automatically build individual models of normal behavior for each person. The system would then predict what would be normal for each analyst and would flag anything abnormal. One could stream a lot of different metrics without knowing which will be important all the modeling is automated. The Biological Neural Network system does not need to know what it is looking for, can model each individual separately, and continuously learns as data changes. In summary, below are the characteristics of the three different approaches: Classic AI Simple Neural Network Biological Neural Network Examples Watson Deep Learning Hierarchical Temporal Memory (HTM) Associated terms Expert systems Artificial Neural Nets (ANN) Machine learning Machine intelligence Data sources Rules from experts Large datasets Data streams Training Programmed by experts Derived from labeled databases Derived from unlabeled data streams Outputs Answers to questions Classification Prediction Anomaly detection Classification Batch vs. continuous learning Batch Batch Continuous Need to know what you are looking for Yes Requires labeled data No Many individual models Hard Hard Easy Biological basis None Simple Realistic Provides roadmap to machine intelligence No No Yes Summary We return to the question of terminology that we started this post with. Our feeling is that the term artificial intelligence has been used in so many ways that it is now confusing. People use AI to refer to all three approaches described above, plus others, and therefore has become almost meaningless. The term machine learning is a more narrowly defined term for machines that learn from data, including simple neural models such as ANNs and Deep Learning. We use the term machine intelligence to refer to machines that learn but are aligned with the Biological Neural Network approach. Although there still is much work ahead of us, we believe the Biological Neural Network approach is the fastest and most direct path to truly intelligent machines. This blog entry was modified on Thu Mar 24 2016 to clarify the timing of neural network research. Numenta Jeff Hawkins & Donna Dubinsky All Blog Posts Numenta 2016/01/11 Jeff Hawkins & Donna Dubinsky What is Machine Intelligence vs. Machine Learning vs. Deep Learning vs. Artificial Intelligence (AI)?","title":"What is Machine Intelligence vs. Machine Learning vs. Deep Learning vs. Artificial Intelligence (AI)?"},{"path":"/blog/2016/01/14/and-the-award-goes-to/","text":"And the award goes to... Thu, Jan 14, 2016 BlogAnd the award goes to... Christy Maver Director of Marketing This morning, as Hollywood anxiously awaited to hear the nominees for this year s Academy Awards, another set of winners was recognized not for motion pictures, but for artificial intelligence. The Global Annual Achievement Awards for Artificial Intelligence were announced today by http://Awards.AI. Awards.AI is part of the Informed.AI Network, which provides a range of information resources for Artificial Intelligence and Machine Learning. The awards are voted on by its community and designed to celebrate the various achievements in developing new algorithms, products and services across a number of different categories and industries, as well as the work of startups and individuals whose focus on AI is advancing the field. There s no question that interest, activity and progress in the field of artificial intelligence, (or machine intelligence, as we would say here at Numenta) is increasing every day. The existence of these awards is a testament to the growing enthusiasm for this space. We were honored to see the community recognize our work, along with our strategic partner, Cortical.io, in several of the 10 categories of achievement in 2015: Award Winner AI Company of the Year Numenta AI Person of the Year Jeff Hawkins AI Application of the Year NuPIC AI Startup of the Year Cortical.io Our most recent newsletter shared what we thought to be highlights of our achievements in 2015. Cortical.io was recognized for developing a new approach for handling Big Text Data with highly efficient semantic fingerprints and the Cortical.io Retina, which is the first semantic engine able to process terabytes of unstructured text in real time, for any language or business domain. You can see the full list of winners at http://awards.ai/ or follow them on Twitter @Awards_AI. Most awards ceremonies include the seemingly never-ending I d like to thank speeches. Don t worry; no need to cue the orchestra here. I will simply say on behalf of Numenta, thanks to those who voted, and more importantly, thanks for following us and our work here. We appreciate the support, and it is great motivation as we set out to accomplish even more in 2016. Christy Maver Director of Marketing All Blog Posts Christy Maver 2016/01/14 Director of Marketing And the award goes to...","title":"And the award goes to..."},{"path":"/blog/2016/02/11/numenta-anomaly-benchmark-contest-ieee-wcci-2016/","text":"The NAB Competition 2016 Thu, Feb 11, 2016 BlogThe NAB Competition 2016 Taylor Wirfs Marketing Numenta Anomaly Benchmark (NAB) Competition IEEE WCCI (World Congress on Computational Intelligence) 2016 We are excited to announce the Numenta Anomaly Benchmark (NAB) Competition! Last year, we released NAB, the first ever open-source benchmark for evaluating real-time anomaly detection algorithms. This year, we want to further expand NAB by including more real-world datasets and benchmarked algorithms, through a fun competition - with cash prizes. The contest will be held in conjunction with the IEEE WCCI 2016 on July 25 29 in Vancouver, Canada. The competition offers two submission categories: Algorithms and Datasets. Want to see how your anomaly detection algorithm performs? Have a dataset with labeled anomalies? Then this contest is for you. Entries can be submitted to either category, or both. All entries should be sent to nab@numenta.org. Example entry of satellite data with labeled anomalies. See more examples. Entry Categories Algorithms Category We are looking for algorithms that detect anomalies in streaming data. Entries in this category must submit the following: - Detailed description of the algorithm and NAB results - Code to run the algorithm and re-create the results (GitHub link OK) - List of contributors and their contact information We will evaluate your algorithm by running your code on NAB v1.0. Results will be added to the NAB repository scoreboard, following the conference. Datasets Category We are looking for real-world, time-series datasets with labeled anomalies. Entries in this category must submit the following: - Data file(s) in CSV format - Anomaly labels, with timestamps at which the anomalies start - Detailed description of the data and anomalies - List of contributors and their contact information We will evaluate the dataset on the following characteristics: types of anomalies, relevance to real applications, quality, difficulty for algorithms, quantity of data (more files in your set, the better), and feasibility for detection. Viable datasets will be added to the next version of NAB, shortly after the competition ends. Prizes $$ All work and no play is no fun. We will be awarding up to $10,000 in cash prizes for your contributions to NAB. Rules and Eligibility For a complete list of rules and contest eligibility, visit: http://numenta.org/nab/. Deadline and Questions Submissions are due by July 1, 2016. We encourage you to ask questions, and submit entries ASAP so we can ensure they meet all the requirements. Contact us with any questions at nab@numenta.org. Ready to get started? Check out these resources: - NAB GitHub Repository - NAB Technical Paper - Evaluating Real-Time Anomaly Detection: The Numenta Benchmark Video presentation given by VP Research, Subutai Ahmad at MLConf (Nov. 2015) - Example Algorithms and Dataset Entries Taylor Wirfs Marketing All Blog Posts Taylor Wirfs 2016/02/11 Marketing The NAB Competition 2016","title":"The NAB Competition 2016"},{"path":"/blog/2016/02/18/real-time-insights-from-a-random-walk-htm-for-stocks-hits-the-iphone/","text":"Real-time Insights from a Random Walk: HTM for Stocks Hits the iPhone Thu, Feb 18, 2016 BlogReal-time Insights from a Random Walk: HTM for Stocks Hits the iPhone Christy Maver Director of Marketing While Numenta may not be in the business of selling traditional products, we are in the business of making our technology pervasive. To that end, we build sample applications that demonstrate the value of HTM, and we make the code available in our open source project. But while anyone can read about our technology and applications, experiencing them requires some serious computer science skills. That changed this month when we launched an iPhone version of our HTM for Stocks app. Android users can still access the app here. Now, all it takes to experience HTM is your cell phone. HTM can be applied in a variety of use cases, but we chose to focus this application on the stock market because you don t have to be an algorithms or investment expert to understand it. HTM for Stocks monitors financial and social data (specifically stock price, stock volume and Twitter volume) for a couple hundred stocks and alerts you in real-time when a significant anomaly is occurring. To illustrate the benefits of this application, think about how you would find securities anomalies without it. You d start with the list of 200 companies you want to monitor and you d have three data streams for each: the stock price, the stock volume and the Twitter volume. Rather than try to create 600 individual models and learn patterns in each one, you might set global thresholds like, Notify me when any stock price moves more than 1 standard deviation away from its moving average of the last 60 days. You would catch some anomalies this way, but you would miss the more subtle temporal anomalies. A couple recent examples demonstrate how HTM for Stocks finds these types of anomalies: Example #1 On February 17, HTM for Stocks found a purely temporal anomaly in the stock volume of FCX (Freeport-McMoRan). It is normal for stock volume to spike at the beginning and end of a trading day, with the data often resembling a U shape. However, it s very rare for a stock s volume to spike twice in a short time frame. HTM for Stocks catches this anomaly, where other detection methods like thresholding would not. Interestingly, HTM for Stocks identifies temporal anomalies in the Twitter volume just before the stock volume anomaly. The Twitter volume data not only indicates that something unusual is happening with this stock, it also serves as root cause analysis. You can view the underlying Twitter data by tapping on it to reveal the tweets. This allows you to get qualitative insights and see what people are saying about the company s stock. In this case, many of the tweets were advising shareholders to sell this particular stock if it go to a certain price. Example #2 On February 4, HTM for Stocks picked up an unusually high volume of Twitter activity for Conoco Phillips before the market opened. The company had announced a large decrease in dividends. This was followed by anomalous stock volume movement where again we see a double spike at the beginning of market hours. We also see multiple Twitter volume anomalies throughout the day. Much like the previous example, these anomalies are temporal in nature, and would not necessarily be caught using a global alert or thresholding technique. HTM for Stocks demonstrates the value of combining multiple metrics. If you were only monitoring any one of these 3 streams (stock price, volume and Twitter volume), you might miss some important anomalies. But if two or three data streams are displaying unusual behavior at the same time, something truly significant is happening. Numenta has no plans to turn this into a commercial application, but it s easy to see how someone could. The amount of data we are faced with in a single day continues to grow while the amount of hours in a day never will. The underlying technology is not specific to stocks but can be applied to many different streaming applications. The ability to do anomaly detection in streaming analytics with large, noisy data streams offer real-time insights and a competitive advantage. I hope you ll download HTM for Stocks and give it a try. Let us know what anomalies you find by contacting feedback@numenta.com or leave a comment below. Christy Maver Director of Marketing All Blog Posts Christy Maver 2016/02/18 Director of Marketing Real-time Insights from a Random Walk: HTM for Stocks Hits the iPhone","title":"Real-time Insights from a Random Walk: HTM for Stocks Hits the iPhone"},{"path":"/blog/2016/03/30/numenta-at-computational-and-systems-neuroscience-conference/","text":"Numenta at the Computational and Systems Neuroscience Conference (COSYNE) Wed, Mar 30, 2016 BlogNumenta at the Computational and Systems Neuroscience Conference (COSYNE) Yuwei Cui Research Engineer Earlier this month, I attended the annual Computational and Systems Neuroscience meeting (Cosyne) in Salt Lake City. Cosyne is a peer reviewed scientific conference that brings experimental and theoretical neuroscientists together to exchange data and ideas. Why does a machine intelligence company attend a neuroscience meeting? Numenta s approach to machine intelligence starts with a deep understanding of how the neocortex learns. We use the brain as a blueprint. The HTM theory is not only inspired by neuroscience concepts, but also constrained by detailed neuroscience findings. Neuroscientists, using many new tools, have made tremendous advancements in understanding the physiology and connectivity of the brain. We would like to see whether the latest experimental evidences could fit into the HTM theory. If not, how should we revise the theory to be consistent with the experimental observations? From neuroscience findings to machine intelligence This year we presented a poster on a theory of sequence memory in the neocortex. The ability to recognize and memorize regular temporal patterns from sensory input streams is critical for almost all cortical functions. The topic of neural representations of time and sequence in the cortex was very popular at Cosyne this year, as you can see in the program guide. Our work is unique, as it is not only built on concrete experimental findings from neuroscience and makes a number of experimentally testable predictions, but also achieves compelling performance on real-world sequence learning tasks. Neurons in the neocortex receive thousands of inputs on their highly elaborated dendritic trees. Unlike most artificial neural network models individual dendritic branches act as active pattern detectors: co-activation of a number of synapses leads to a dendritic spike that can depolarize the cell body for hundreds of milliseconds. This phenomenon of active dendrites has been known for a long time among neuroscientists. A number of presentations at Cosyne modeled the biophysical mechanism underlying dendritic spikes. Nevertheless, the function of dendritic spikes remains unclear and it is not incorporated in most neural network models. Left: A pyramidal neuron in the cortex (Spruston 2008, Nat Rev Neurosci). Right: Researchers stimulated individual synapses optically and measured voltage responses at the soma. Simultaneous stimulation of enough synapses (8 in this case) caused a large and sustained depolarization at the cell body (Major et al., 2013, Annu Rev Neurosci). The HTM sequence memory model utilizes the active dendrites of cortical neurons to learn sequences from data streams. Temporal sequences are learned via growth of new synapses and are represented with sparse distributed representations. Predictions of future inputs are made through the generation of dendritic spikes. The resulting model gives rise to a powerful sequence memory, which not only achieves comparable performance to state-of-the-art machine learning algorithms, but also exhibits many desirable attributes for real-world sequence learning with streaming data. HTM sequence memory model makes accurate 2.5 hour ahead-predictions of taxi demand in the New York City. Interactions with other neuroscientists Our work attracted wide interest among neuroscientists. Several experimental neuroscientists were very excited to learn about the important functional role of the long observed phenomena of dendritic spikes. Some even expressed interest in running more specific experiments to test the learning mechanisms used in HTM. We also benefited by discussing with other neuroscientists. For example, by talking with researchers that build detailed biophysical models of active dendrites, we now have a better idea of how HTM would work on a detailed biophysical level. I found quite a few other presentations at Cosyne that were related to HTM. Prof. Michael Berry s group from Princeton University recorded a large population of neurons in the primary visual cortex during the presentation of image sequences. The observed behavior of the real neural population matches many aspects of the HTM sequence memory model. Prof. Jose Carmena from UC Berkeley presented a novel paradigm for brain-machine interface where subjects continuously learn to control a small set of neurons. Interestingly, the performance over time looks quite similar to that of the HTM model on a continuous learning task. These studies, and many others, give us valuable insights on the development of future HTM algorithms. We would like to keep collaborating with the neuroscience community. We believe doing so would tremendously speed up our progress on machine intelligence. I encourage you to take a look at our poster and the accompanying paper. Please also check out this recently published Frontiers Neural Circuit paper to learn about the HTM theory. Let me know what you think of it by contacting ycui@numenta.com and join the discussion of HTM in the NuPIC community. Numenta Cosyne Poster. Click to enlarge. Yuwei Cui Research Engineer All Blog Posts Yuwei Cui 2016/03/30 Research Engineer Numenta at the Computational and Systems Neuroscience Conference (COSYNE)","title":"Numenta at the Computational and Systems Neuroscience Conference (COSYNE)"},{"path":"/blog/2016/06/16/can-neuroscientists-understand-the-brain/","text":"Can Neuroscientists Understand the Brain? Thu, Jun 16, 2016 BlogCan Neuroscientists Understand the Brain? Subutai Ahmad VP of Research Eric Jonas and Konrad Kording just released a provocative paper, Could a neuroscientist understand a microprocessor? [1] In their paper, they ask whether current neuroscience techniques could discover the operations of a simple microprocessor[2]. Their reasoning is as follows. The field of neuroscience is trying to understand the computational properties of the brain. If we think current neuroscience techniques are sufficient to understand something as complex as the brain, surely they will be able to handle a small microprocessor. If, on the other hand, current techniques are insufficient to understand even this simple CPU, it raises serious questions about the current approaches in the field. True, the brain is not a silicon processor but there are similarities (they list several in the paper). So let s apply these techniques to this simpler computational system as a litmus test. Their methodology includes applying an array of traditional techniques such as lesioning, examining statistics of bit patterns, analyzing tuning properties of transistors, dimensionality reduction, etc. They studied the microprocessor in vivo while playing a variety of video games (you can tell they had a lot of fun with this project!) They were able to discover that transistors exhibited very low pairwise correlations but were not actually independent (very similar to behavior of neurons[3]). They showed strong spatiotemporal structure in the activity of various processor components. The resulting plots and charts look remarkably similar to those in neuroscience papers. Yet these techniques did not uncover the true computational nature of the microprocessor nor its functional structure. Of course, in this process what they are really asking is Could a neuroscientist understand the brain ?[4] Their conclusion: an unequivocal NO . We all know that correlation does not imply causation . Current statistical techniques report all sorts of correlations, but little regarding true underlying structure. What does it mean to understand the brain? So what does it really mean to understand the brain? Unfortunately the paper does not answer this question. They do make vague comments that the field should understand how the output relates to the inputs , and that it should reward \"those who innovate methodologically.\" These statements are unsatisfactory at best. I propose a much stronger answer. As a computer scientist, I believe the only way to be certain you understand something is to build it. Write the program for it. We don t need to create an exact replica, just a system that demonstrates the important properties. This methodology is harder but demands that you uncover underlying structure and function. Let me give an analogy using a different paradigm. Suppose cars didn t exist. Humans somehow get access to a luxury Mercedes sedan and the race is on to understand how it works. Let s consider two alternative approaches. The first approach involves calculating a number of statistical measures and building predictive models. These models might accurately predict the car s gas mileage under different conditions, such as going uphill vs downhill. They might be able to plot precise acceleration profiles under different loads. They would know exactly how long it takes the air conditioning to cool the car in different climates. Scientists would publish thousands of peer-reviewed papers with all sorts of equations and charts proving the accuracy of these models. But would they really understand how the car works? The second approach involves using the car to deduce fundamental mechanisms such as a power source, transmission, and steering. It would focus on the function of these subsystems, and less on details such as the strength of bolts or the efficiency of water pumps. To test our theories of function we would build a much simpler machine from scratch, perhaps something like a Ford Model T[5]. This car would have a super simple engine and hand cranked starter. The controls might be awkward, the tires bad, and the seats uncomfortable. It would definitely have no air conditioning. It might not even be as fast as a horse! But, you could actually drive this car. Because we understand how our simple car works, over time we can improve it and eventually build vehicles even better than the Mercedes prototype. What is our approach? At Numenta we are using this second approach to understanding the brain. We are building the Model T equivalent of the neocortex. We use neuroscience discoveries and details to deduce the fundamental components of intelligence. For example, we know that the neocortex learns a predictive model of the world. It learns continuously without supervision. We know that behavior and sensory inference are not separate processes, but are intimately integrated such that learning cannot be achieved without behavior. Our theories are constrained by and consistent with a great many neurosciences details, but our software simulations only capture the functional properties of the brain and not all the details. We are often asked, How do you decide what neuroscience details to include in your simulations and which to leave out? The answer is we include neuroscience details when they are essential for function. When we hit stumbling blocks we return to experimental neuroscience to provide clues and hard constraints on how to solve problems. Our simulations also provide insights into the structure of cortex[6][7]. Compared to the brain, our software is at an early stage and primitive, like a Model T. But, you can actually take it for a spin, see how it performs, and then know what areas need improvement. Can we understand the brain? We have made excellent progress with our approach. If we stay focused on large-scale functional theories and building systems based on those theories, the answer to this question is an unequivocal YES ! Footnotes and Citations [1] Jonas, E., and Kording, K. (2016). Could a neuroscientist understand a microprocessor? Cold Spring Harbor Labs Journals bioRxiv doi:10.1101/055624. http://biorxiv.org/content/early/2016/05/26/055624.abstract [2] Specifically Motorola 6507, similar to what was used in the Apple I and Atari video game consoles 40 years ago. [3] Schneidman, E., Berry, M. J., Segev, R., and Bialek, W. (2006). Weak pairwise correlations imply strongly correlated network states in a neural population. Nature 440, 1007 12. doi:10.1038/nature04701. [4] Note that the paper specifically targets computational neuroscience techniques, not experimental neuroscience. The amount of experimental data in neuroscience has been exploding exponentially, but without good theoretical guidance uncovering value is like finding a needle in a haystack. [5] https://en.wikipedia.org/wiki/Ford_Model_T [6] Hawkins, J., and Ahmad, S. (2016). Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex. Front. Neural Circuits 10. doi:10.3389/fncir.2016.00023. http://journal.frontiersin.org/article/10.3389/fncir.2016.00023/full [7] Ahmad, S., and Hawkins, J. (2016). How do neurons operate on sparse distributed representations? A mathematical theory of sparsity, neurons and active dendrites. arXiv:1601.00720 [q bio.NC]. Available at: http://arxiv.org/abs/1601.00720. Subutai Ahmad VP of Research All Blog Posts Subutai Ahmad 2016/06/16 VP of Research Can Neuroscientists Understand the Brain?","title":"Can Neuroscientists Understand the Brain?"},{"path":"/blog/2016/08/04/revisiting-a-1986-essay-on-brain-theory/","text":"Revisiting a 1986 Essay on Brain Theory Thu, Aug 04, 2016 BlogRevisiting a 1986 Essay on Brain Theory Jeff Hawkins Co-Founder This week I received an email from a gentleman in Japan. He was creating materials for a course and asked permission to include an extensive passage I had written. What surprised me about his request was that the passage was not from a paper I wrote at Numenta, nor from my time at the Redwood Neuroscience Institute, nor was it from my book On Intelligence. It was from an essay I d written over 30 years ago when I was a graduate student at UC Berkeley. In January 1986 I gave up my career at a hot computer start-up company to become a full-time graduate student. I wanted to study how the brain works and this seemed my best option. When I arrived at Berkeley I was eager to take every neuroscience course they offered and to dive into my research. It didn t take long for me to become dismayed. I was told I had to take courses that were uninteresting to me, such as a foreign language and organic chemistry lab, and worse, I might not be able to study brain theory at all. I met with the chairman of the graduate group of neurobiology, Dr. Frank Werblin, to get his advice. He suggested that I write a paper on what I wanted to accomplish as a PhD student. So that s what I did in the spring of 1986. During that time I had the epiphany that the neocortex builds a predictive model of the world. Every part of the neocortex is continuously predicting what input it is going to receive. This is not the only thing the neocortex does but it is a tangible problem. If I could decipher how neurons learn to make predictions of changing inputs it would expose core principles underlying everything the neocortex does. The paper that I ultimately wrote made two arguments. First, I argued that it was possible to understand how the neocortex works, that it could be done in a matter of years, not centuries. I was surprised to learn that almost all neuroscientists and funding agencies disagreed. Second, I proposed that my research would initially focus on how neural tissue learns predictive models. Dr. Werblin read my paper and we sat down for lunch to discuss it. He was kind and supportive of my overall goal but he said the reality was that I could not work on brain theory for my PhD thesis. He explained that it was not possible to get funding for the kind of theoretical studies I wanted to do and because of this there were no faculty members at Berkeley, nor anywhere else, that I could work with. Being a theoretical neuroscientist was not an option at that time. The title of my paper was An Investigation of Adaptive Behavior towards a Theory of Neocortical Function*. It was from this paper that the gentleman from Japan wanted an excerpt. I had not read this paper in many years so I sat down to read it again this week. There are of course things that I would write differently today, and our neuroscience knowledge has advanced significantly, but many of the ideas and aspirations I had back then I still hold today. Thirty years later we have made significant progress in neocortical theory and I remain confident we can complete a comprehensive theory of the neocortex in the next few years. My enthusiasm and optimism have not changed, nor has my approach to the problem. If you are interested in a historical perspective underlying Numenta s goals you might enjoy reading my paper from thirty years ago. Understanding how the brain works is recognized by many as one of the most important scientific endeavors of all time and, I believe, worthy of a lifetime of effort. * There are a few typographical errors in the document, these came from scanning the original printed version many years ago. Jeff Hawkins Co-Founder All Blog Posts Jeff Hawkins 2016/08/04 Co-Founder Revisiting a 1986 Essay on Brain Theory","title":"Revisiting a 1986 Essay on Brain Theory"},{"path":"/blog/2016/08/10/numenta-anomaly-benchmark-nab-competition-2016-winners/","text":"NAB Competition 2016 Winners Wed, Aug 10, 2016 BlogNAB Competition 2016 Winners Zuha Agha Algorithms Intern The wait is over! We are proud to announce the winners of the 2016 Numenta Anomaly Benchmark (NAB) Competition, held in conjunction with IEEE World Congress on Computational Intelligence. The competition, which ran from February through July this year, comes to a close after an exciting round of submissions. This was the first ever publicly held contest for NAB. When NAB was introduced last year, its mission was to address the need for a standardized and publicly accessible benchmark for performance evaluation of real-time anomaly detection. NAB s open source repository includes over 50 labeled data streams from a wide range of real-world sources that capture the traits crucial for testing anomaly detection in streaming data. In addition, NAB contains a collection of popular anomaly detection algorithms and a unique scoring scheme that enables effective comparison of different detection methods against each other. In an effort to take our mission of expanding NAB even further, we launched the inaugural NAB Competition where participants can showcase their understanding of real-time anomaly detection by contributing suitable datasets or algorithms, and get a chance to win exciting cash prizes in return. Overall, the competition was well received by the research community and attracted submissions not only from the U.S but across the globe, including India and Russia. After careful consideration, we decided on the following list of winners for the two competition categories: Dataset Category Winners Prize Name #1 Samya Bagchi #2 BK Ramesh Algorithms Category Winners Prize Name(s) #1 Mikhail Smirnov #2 Felix Andrews #3 Vladislav Ishimtsev & Evgeny Burnaev All winning entries demonstrated creativity and a good sense of the problem definition. In the dataset category, the entry bagging first prize provided labeled anomalies for real patient blood pressure data, a very important domain for streaming analytics. The second prize was awarded to a dataset retrieved from a car engine motor system with annotated anomalies for voltage and current metrics. Here are some interesting examples of anomalies from our winning datasets, shown with red dots. The graph above shows a patient s blood pressure readings every 5 milliseconds as the pressure drops steadily from diastole to systole. Every small oscillatory pattern represents a heartbeat. The first anomaly indicates pressure noise and the second anomaly indicates an irregular heartbeat, given by subtle temporal pattern changes. This graph shows current sensor data of a motor engine. The first anomaly is an increase in maximum amplitude of a cycle, followed by another anomaly that shows a lag in starting the engine and the last anomaly resulting in engine failure. In the algorithms category, winning submissions also achieved very impressive scores on the benchmark. The entry securing first place worked with a novel contextual encoding scheme, followed closely in second place by a modified Hierarchical Temporal Memory algorithm, and third place by a k-nearest neighbor context based approach. All of these datasets and algorithms are valuable contributions to NAB, helping accelerate our efforts to grow this benchmark and improve its usefulness for all researchers. Winning entries are to be officially included in an upcoming version release of NAB, and the algorithm scores will be displayed on the NAB leaderboard. We would like to extend our heartiest congratulations to all of our winners on their achievement! We are also thankful to all participants for their commendable effort and enthusiasm. The NAB competition hopes to return next year, but until then we continue to welcome all relevant contributions at our open-source code base https://github.com/numenta/NAB. For any questions or comments on NAB, you can post at https://discourse.numenta.org/c/nupic/nab. Zuha Agha is spending her summer as an Algorithms Intern at Numenta. She is a student of PhD Computer Science at University of Pittsburgh. Her interests lie at the crossroads of Machine Learning, Artificial Intelligence and Computer Vision. In her free time, she loves reading and learning new skills. Zuha Agha Algorithms Intern All Blog Posts Zuha Agha 2016/08/10 Algorithms Intern NAB Competition 2016 Winners","title":"NAB Competition 2016 Winners"},{"path":"/blog/2016/08/18/an-insiders-look-interview-with-yang-lan-and-jeff-hawkins/","text":"An Insider’s Look: Interview with Yang Lan and Jeff Hawkins Thu, Aug 18, 2016 BlogAn Insider s Look: Interview with Yang Lan and Jeff Hawkins Taylor Wirfs Marketing In the two years I ve been at Numenta, I ve seen the field of AI grow to become a focal point of technology news. During this same time, I ve also witnessed the interest in our work continues to grow. So it didn t come as a surprise when I learned a Chinese TV crew wanted to film an interview with our co-founder, Jeff Hawkins, at our office. But it did come as a surprise to hear that the interview was with Yang Lan, a prominent broadcast journalist and figure who has been referred to as the Oprah of China. She hosts several TV talk shows, is the cofounder and chairperson of Sun Media Group and Sun Culture Foundation, and was listed by Forbes as one of the top 100 most powerful women. The interview with Jeff is to be featured as part of Yang Lan s upcoming documentary series on Artificial Intelligence. Yang Lan and her team travelled across the globe to interview knowledgeable researchers, technologists and leaders on their opinions and findings. The documentary series is set to air in China at the end of this year and will be seen by upwards of a billion people; there will be an English version afterwards as well. We ll update this blog when the interview becomes available, with instructions on how to access it. The View Behind the Scenes The film and production crew of 11 (yes eleven!) people arrived at our office in Redwood City, CA; a bit early for the 8:30 a.m. appointment and quickly took over our office. A coordinator based on the west coast had visited Numenta a week prior to the interview, to discuss details and scout the office for filming locations. The team chose to set up two chairs in the middle of the office, with a view of a neuron mural from neuroscientist Santiago Ramon y Cajal, on our wall in the background. We have a small team at Numenta, around 15 employees plus a few interns that join us every summer, so our office is small. Thursday is a no-meeting day, when many employees choose to work from home. This worked well to accommodate the large film crew, as the staff members who were present were displaced from their desks to various locations around the office. This photo only shows half of the production crew. Other members were busy in one of our conference rooms. Yang Lan arrived once the cameras were setup, and was greeted by our eager staff and her production crew. After a few introductions, sound checks and lighting adjustments, the cameras began rolling. Her first few questions focused on Jeff s background and how he arrived at Numenta s mission today - reverse-engineering the neocortex. Jeff referenced his prior work as computers were fun to work on, but my real passion was brains. He described solving brains as a difficult problem, but also as one of the most important problems in the world. The next series of questions from Yang Lan evoked a more lively discussion. It was clear that she knew Numenta s approach was different than traditional machine learning methods, but she wanted Jeff to explain why. He went into detail on why Numenta is studying the neocortex as a blueprint for machine intelligence. Jeff defined intelligence and highlighted one of the crucial processes involved when learning a model of the world: the brain works on time-based data. He also addressed the fears from those concerned with the creation of intelligent machines, a highly debated topic in artificial intelligence. Yang Lan interviews Jeff Hawkins at our office. The interview went smoothly, with the exception of an interruption from a deliveryman at our door. After the interview, Jeff showed Yang Lan several of our example applications and visualizations, to help her audience visualize our technology. A Numenta employee, who was working remotely, signed on to our tele-presence robot (made by Double Robotics) and introduced himself while navigating the robot through the office for Yang Lan and her film crew. Between set-up, the interview, b-roll footage and takedown, the production team spent four hours at our office, but by the afternoon, the office had returned to its norm. Seeing the effort that occurs behind the scenes of a documentary film interview was impressive. The real highlight though was witnessing the live, uncut version of an interview with Yang Lan. We don t know what the final piece will look like and how the producers plan to include Numenta, but it was exciting to be a part of this documentary series. Taylor Wirfs Marketing All Blog Posts Taylor Wirfs 2016/08/18 Marketing An Insider’s Look: Interview with Yang Lan and Jeff Hawkins","title":"An Insider’s Look: Interview with Yang Lan and Jeff Hawkins"},{"path":"/blog/2016/09/02/why-did-we-completely-change-our-website-design-the-story-behind-our-new-look/","text":"Why Did We Completely Change Our Website Design? The Story Behind Our New Look Fri, Sep 02, 2016 BlogWhy Did We Completely Change Our Website Design? The Story Behind Our New Look Christy Maver Director of Marketing If you ve been to numenta.com before you may notice that something looks a little or perhaps more than a little different. After months of behind the scenes remodeling, we ve launched our newly designed website. A website redesign is not an uncommon endeavor. In fact I ve been part of at least one redesign at every company where I have worked. Sometimes they re driven by welcome trends, like responsive design. Can you remember a time when you didn t look at a website on your phone and expect the same experience you get on your laptop? Other times they re driven by passing fads blinking marquees, background music and continuous carousels come to mind. Our redesign came out of a frustration and observation by Numenta co-founder, Jeff Hawkins. He found many websites frustrating to use and observed that he almost always first went to Wikipedia to learn about a company. According to Jeff, Websites have become so burdened with graphics, messages, and clever navigation that it can be challenging finding the information you want. I was struck by this one day when I couldn t find something on our own website! I also realized that Wikipedia had become my default first step when researching a new company. It was almost always faster and easier to get answers to my questions from a Wikipedia entry than from the company s own website. That was a sign that website designs have become broken. A discussion on Wikipedia ensued. Why does it work? For one thing, it does not contain the flowery marketing language and images woven through most websites. It presents just the facts or at least the facts according to the collective community. Just as importantly, it strips out the navigation complexities common to many sites. It gives you all of the information related to a topic on one page and presents it in a consistent format. From that discussion, an experiment was born. Could we take some of these principles and apply them to a corporate site? Could we tell Numenta s story in a way that lets the end user quickly find what they are looking for, whether it s a first-time visitor, someone interested in partnering with us, or a professor looking for a specific paper she once saw to use in her coursework? Could we present the information in a clear and concise manner that works quickly and efficiently on mobile and full screen devices? The newly designed numenta.com is our attempt to do just that. Our goal with this site is to educate people about Numenta and our approach to machine intelligence. For those who want a comprehensive view of Numenta, they can walk through each section in order, start to finish. For those who are looking for something in particular we hope they can find it quickly under one of the top-level headings. We believe the new site will allow us to engage with more people more efficiently. You ll notice that in this new design there is just one page with the content organized in a set of expandable categories, similar to how Wikipedia organizes content. You ll also find pointers to our companion site, numenta.org. Numenta.com focuses on the business side of Numenta. Numenta.org contains more technical information, including education about our Hierarchical Temporal Memory (HTM) technology, and how to get started with HTM in open source. I invite you to take a drive through the site. Whether it s your first or fiftieth time there, hopefully you ll learn something about Numenta that you didn t know before. Drop us a line and let us know what you think. Christy Maver Director of Marketing All Blog Posts Christy Maver 2016/09/02 Director of Marketing Why Did We Completely Change Our Website Design? The Story Behind Our New Look","title":"Why Did We Completely Change Our Website Design? The Story Behind Our New Look"},{"path":"/blog/2016/09/23/how-htm-studio-came-to-life/","text":"How HTM Studio Came to Life Fri, Sep 23, 2016 BlogHow HTM Studio Came to Life Numenta Marion Le Borgne & Taylor Wirfs It s been a few months since we first launched HTM Studio and things have calmed down from a development perspective. I sat down with Marion Le Borgne, project manager and lead engineer for HTM Studio, to get her thoughts on the process and efforts it took to build the application. Before we get into the nitty-gritty of software development, can you tell us a little more about yourself and role at Numenta? I am a Senior Software Engineer at Numenta and Project Manager for HTM Studio. I started my career as a Business Analyst at Partech Ventures in Europe and then joined CloudWeaver (acquired by F5 networks) as a Data Scientist. After attending a Hackathon organized by the Numenta OS community in 2014, I was hooked by the mission of the company. I started working at Numenta in 2015. In the same year, I co-founded NeuroTechX, an international non-profit for neurotechnology. Why did you build HTM Studio? HTM Studio was built in response to the many inquiries about our technology from users who wanted to use HTM algorithms, but lacked the technical skill needed to experiment with our open source code. We decided to build an app that would accomplish exactly that: allow users to try HTM algorithms on their own data in minutes, without prior coding experience or a knowledge of HTM algorithms. What was the development process like? Research and Product Design My initial research helped me develop the first set of features in HTM Studio. I started researching existing tools to understand how people packaged other streaming analytics offerings. I also reviewed past proof of concepts to learn what had and had not worked for Numenta. During my research, it became clear that HTM Studio needed to be a desktop app to address data privacy concerns. After that, I created a first round of wireframes for the general flow of the app. A couple of feedback sessions later, the wireframes started looking like today s HTM Studio. Architecting the Application Next, we began to greenfield the app and lay out the architecture. This leads me to the unique technical stack in HTM Studio. We wanted to build a desktop app that leveraged modern web technologies, so that HTM Studio was responsive and beautiful. We chose Github Electron, a framework that lets you write cross-platform desktop applications using JavaScript, HTML and CSS. We packaged Python with NuPIC, so it could run within HTM Studio. This allowed users with no programming knowledge to use NuPIC without having to install it separately. Testing the Machine Learning Algorithm We developed a method to simplify the process of finding the best HTM parameters called param finder . Historically we used a complex method called swarming, but the new param finder skips this step and quickly finds the optimal parameters. Then, we spent about a month on the accuracy of the algorithm results. It was important that the app (and especially the new param finder) provided accurate results on various datasets. We added compatibility tests with NAB to test the results. Testing the UX Once we had these three elements (Electron, portable NuPIC and param finder) in place, we started UX testing. The goal was to gather feedback from a variety of users with different datasets and use cases, to fine tune the app and ensure HTM Studio was easy to use. We launched the private beta in May, and went through a lot of QA testing and bug hunting. A few weeks later, we were finally able to launch the public release. Was there anything that surprised you during development? We had a couple setbacks that were mainly on the technical side. First, packaging NuPIC (the Python bindings and C libraries) along with a portable Python distribution was a project in itself. We wanted to ensure that users who did not have NuPIC or Python could run HTM Studio. Second, we wanted to incorporate dynamically updating charts to demonstrate the continuous learning that occurs in the HTM algorithms. It took us a while to reach a point where chart navigation was smooth and responsive. How was the launch experience? The launch went well. I had numerous 1:1 sessions with private beta users to get feedback on the app before the final launch, so there weren t any last minute surprises. The feedback from these sessions was very valuable. We learned about various use cases, data formats and how users intended to use HTM Studio. These 1:1 sessions confirmed two things: the target audience for HTM Studio and which features should be added or simplified. What s your favorite feature and why do you think it s useful? The param finder is a great feature. It allows you to get up and running with HTM technology in a couple of minutes, without having to worry about setting any parameters. I especially like that this feature is coupled with the advanced settings feature. That way, if you are familiar with HTM theory, you can have more control over the machine learning algorithm. HTM Studio automatically determines the best parameters for your dataset. Users familiar with HTM can tweak their parameters in advanced settings. If you had an infinite amount of resources available, what would you include in a future version? Predictions. I think this would be a really great addition to HTM Studio, which is currently geared towards anomaly detection. Any last thoughts? Shaping and building this app was a really collaborative process, with a lot of feedback from the Numenta team and private beta testers. Collaboration was required between research, engineering and product teams, and I enjoyed this aspect of the project the most. HTM Studio is built on years of research that made the HTM algorithms what they are today. It s great to see that HTM algorithms are now accessible to anyone. Numenta Marion Le Borgne & Taylor Wirfs All Blog Posts Numenta 2016/09/23 Marion Le Borgne & Taylor Wirfs How HTM Studio Came to Life","title":"How HTM Studio Came to Life"},{"path":"/community/","text":"Community Community Aside / Our community is an eclectic collection of researchers, scientists, hobbyists, and hackers interested in building biologically-inspired intelligent systems with Hierarchical Temporal Memory (HTM). To get involved in our community, join HTM Forum. You can login with your Google, Facebook, or Twitter account, or by creating an new account with your email address. This is the best place to ask questions, search for answers, or just interact with others working on similar problems. We aim to be a helpful and welcoming community, and we hope you'll join us. The HTM Community is sponsored by Numenta, the company behind HTM. Since Numenta open sourced their HTM implementations, they have dedicated one employee to help foster and grow the HTM community. Numenta also organizes and sponsors community events like meetups, hackathons, and workshops. We at Numenta believe that HTM will thrive because it will be easily accessible to many people. Our community exemplifies the type of people drawn toward new technology, and it shows in our curiosity and open-mindedness. Meetups, Hackathons, & other Live Events Take a look at all of our Upcoming Events. All our live events are scheduled via Meetup. Please join our Meetup Group for notifications of upcoming events, all of which are free and open to anyone. Please read our code of conduct before attending events. For recordings of previous events, please see our YouTube channel. You can also view our archive of Past Events.Next: Implementations ","title":"Community"},{"path":"/events/2015/03/17/what-the-brain-says-about-machine-intelligence/","text":"What the Brain Says About Machine Intelligence Tue, Mar 17, 2015 EventsWhat the Brain Says About Machine Intelligence Matthew Taylor Open Source Manager WhenTue, Mar 17, 2015 7:00 PM 9:00 PMWhereCornell TechNew York City, NY USAWebEvent WebsiteTopicWhat the Brain Says About Machine IntelligenceSpeakingJeff Hawkins This event features Jeff Hawkins speaking at Cornell Tech in New York City on March 17 from 7-9PM. See our meetup page for details and to RSVP. Matthew Taylor Open Source Manager All Events Posts Matthew Taylor 2015/03/17 Open Source Manager What the Brain Says About Machine Intelligence  ","title":"What the Brain Says About Machine Intelligence"},{"path":"/events/2015/03/25/bay-area-nupic-meetup/","text":"Bay Area NuPIC Meetup Wed, Mar 25, 2015 EventsBay Area NuPIC Meetup Matthew Taylor Open Source Manager WhenWed, Mar 25, 2015 6:00 PM 9:00 PMWhereCarnegie Mellon Silicon ValleyNASA Research Park, Moffett Field, CA USAWebEvent Website This community-organized Meetup will be at Carnegie Mellon in Silicon Valley on March 25 from 6-9PM. It s a great chance to meet with the NuPIC community and catch up with what s been going on with NuPIC development and projects. See our meetup page for details and to RSVP. Matthew Taylor Open Source Manager All Events Posts Matthew Taylor 2015/03/25 Open Source Manager Bay Area NuPIC Meetup  ","title":"Bay Area NuPIC Meetup"},{"path":"/events/2015/05/30/nupic-spring-hackathon-2015-nyc/","text":"NuPIC Spring Hackathon 2015 NYC Sat, May 30, 2015 EventsNuPIC Spring Hackathon 2015 NYC Matthew Taylor Open Source Manager WhenSat, May 30, 2015 10:00 AM Sun, May 31, 2015 8:00 PMWhereCornell TechNew York City, NY USAWebEvent WebsiteThe 5th NuPIC Hackathon will be held at: Cornell Tech 111 8th Avenue #302 New York, NY 10011 United States Saturday, May 30 10AM - Sunday, May 31 8PM RSVP NOW! To attend this event, you MUST RSVP through the Meetup page above. Matthew Taylor Open Source Manager All Events Posts Matthew Taylor 2015/05/30 Open Source Manager NuPIC Spring Hackathon 2015 NYC  ","title":"NuPIC Spring Hackathon 2015 NYC"},{"path":"/events/2016/03/14/bay-area-htm-meetup/","text":"Bay Area HTM Meetup Mon, Mar 14, 2016 EventsBay Area HTM Meetup Matthew Taylor Open Source Manager WhenMon, Mar 14, 2016 6:30 PM 10:00 PMWhereTrustlySanta Clara, CA USAWebEvent Website This community-organized Bay Area HTM Meetup will be at Trustly on March 14 from 6:30-10PM. It s a great chance to meet with the HTM community and catch up with what s been going on with NuPIC development and projects. See our meetup page for details and to RSVP. Matthew Taylor Open Source Manager All Events Posts Matthew Taylor 2016/03/14 Open Source Manager Bay Area HTM Meetup  ","title":"Bay Area HTM Meetup"},{"path":"/faq/","text":"NuPIC FAQ NuPIC FAQIs there a specific application for NuPIC? The algorithm lends itself well to high-speed temporal data, but it could potentially be applied to many different fields and endeavors. What s the difference between your contributor license and Apache s? Not much, really. Here s a diff. We ve also made a change to the contributor license that diverges from slightly from the Apache version, you can read more about it on our blog. What s the difference between this and your old offering? It is important to emphasize that the old and new NuPIC algorithms are completely different. This isn t an enhancement. It might be a bit confusing that we are using the same name but we figured only a few people would be aware of the old NuPIC offering. The main differences are: a) NuPIC today includes HTM whereas the old NuPIC had our previous algorithms, b) old NuPIC was tuned for vision whereas new NuPIC is tuned for our apps, and c) old NuPIC ran on Windows. Can I add an external library to NuPIC? You can add external libraries to NuPIC. They must have a license that permits proprietary use of the library. External libraries licensed under AGPL, for instance, will not be accepted. Does NuPIC implement hierarchy? Yes and no. The software architecture for hierarchies exists within the Network API of NuPIC.Core, as well as the Python client. You can create models and link them together into a hierarchy, with lower levels passing data up into higher levels. However, hierarchy is not implemented in the easier to use Online Prediction Framework. That wouldn t prevent anyone from experimenting with hierarchies themselves, however. The algorithmic mechanism for creating an effective learned spatiotemporal hierarchy using the CLA is still very much a research topic. A good mechanism for temporal pooling within a hierarchical architecture is an active area of research for Jeff and the NuPIC community. Please search our mailing list archives for discussion and proposals on that topic. What is the difference between HTM and CLA? The neocortex is the seat of intelligent thought in the mammalian brain. High level vision, hearing, touch, movement, language, and planning are all performed by the neocortex. Given such a diverse suite of cognitive functions, you might expect the neocortex to implement an equally diverse suite of specialized neural algorithms. This is not the case. The neocortex displays a remarkably uniform pattern of neural circuitry. The biological evidence suggests that the neocortex implements a common set of algorithms to perform many different intelligence functions. Hierarchical Temporal Memory (HTM) is a term coined by Jeff Hawkins to describe the overall space of systems that capture the structural and algorithmic properties of the neocortex. Many of the key properties concerning HTM algorithms were described in the book On Intelligence. These properties include continuous learning, sequence prediction, hierarchy, feedback, attention, and sensorimotor control. The HTM whitepaper introduced a new property, namely Sparse Distributed Representations (SDR). There could be many different HTM algorithms but so far no one has effectively implemented the full set of properties in a fully working system. The Cortical Learning Algorithm (CLA) is a specific algorithm that covers some of the key aspects of HTM. The CLA uses SDR s, is a continuously learning system, can learn complex sequences and make temporal predictions. There are strong relationships to what is currently known about the laminar structure in a single layer of the neocortex. CLA does not cover all the properties of HTM but we believe it forms a strong foundation for a more complete implementation. Current research at Numenta is focused on temporal pooling (required for effective spatiotemporal hierarchies) and sensorimotor control. Please see some of the recent talks for more detail on these topics. NuPIC FAQ","title":"NuPIC FAQ"},{"path":"/hierarchical-temporal-memory/","text":"Hierarchical Temporal Memory (HTM) Hierarchical Temporal Memory (HTM) HTM is a biologically-constrained theory of intelligence based on years of research in theoretical neuroscience.Overview For an excellent technical overview of HTM theory, read the HTM Overview chapter of our online text, Biological and Machine Intelligence.History - Creation of RNI - Founding of Numenta - Generations of our AlgorithmsHTM Today - Code implementations (link to homepage section) - What HTM Theory coversFuture of HTM - What we are/will be working on ","title":"Hierarchical Temporal Memory (HTM)"},{"path":"/htm-school/","text":"HTM School HTM School To help you learn about our theory and technology, we have organized educational content below. It is designed for anyone who wants to learn about HTM cortical theory and its applications for machine intelligence. HTM School on YouTubeNext: Back to Home ","title":"HTM School"},{"path":"/implementations/","text":"Implementations Implementations Hierarchical Temporal Memory (HTM) is a theory of intelligence that can be implemented in most computer programming languages. Below are descriptions of several HTM implementations currently active within our community. For detailed descriptions of HTM algorithms, see our living text, Biological and Machine Intelligence. It contains pseudocode for both the spatial pooling and temporal memory algorithms (PDFs). NuPIC , or the Numenta Platform for Intelligent Computing, is an HTM implementation created by Numenta and open-sourced in June 2013. This codebase is the original HTM codebase, and is architected in a way that allows algorithmic experimentation in Python, but more performant versions of HTM algorithms in C++. NuPIC Core (C++) Our C++ codebase contains all HTM algorithms written in C++, and SWiG language bindings to Python. Language bindings to other environments should be added here. This codebase exposes the Network API, which is the primary low-level interface for creating HTM systems. http://github.com/numenta/nupic.coreNuPIC (Python) The NuPIC Python codebase contains Python code implementations of HTM. Through this interface, uses may specify whether their code runs Python algorithms or the faster C++ algorithms using the Python bindings provided in nupic.core . In addition to providing Python bindings to the nupic.core Network API, this codebase also includes a higher-level client API called the Online Prediction Framework (OPF), which is tuned towards experimentation with predictions, anomaly detection, and identifying optimal model parameters (swarming). http://github.com/numenta/nupicHTM.Java While the copyright to HTM.Java was generously donated to Numenta by it's author, it is a community-created and maintained port of NuPIC algorithms into Java. This JVM runtime provides a similar experience to the NuPIC Network API, and has algorithmic parity with NuPIC. http://github.com/numenta/htm.javaComportex (Clojure) Comportex is an implementation of HTM as a Clojure library. It is not a port of NuPIC, it is a separate implementation based initially on the Numenta \"CLA white paper\" but significantly evolved. https://github.com/htm-community/comportexNext: HTM School ","title":"Implementations"},{"path":"/","text":"Numenta HTM Community — Numenta Hierarchical Temporal Memory (HTM) Community and Resources Numenta HTM CommunityHierarchical Temporal Memory (HTM)AboutHTM is a biologically-constrained theory of intelligence based on years of research in theoretical neuroscience.CommunityHTM ForumResearchResearch & PublicationsOpen SourceCodeLicenseAGPLv3ContentBlog EventsLatest Why did we overhaul our web design? The story behind our new look. New Numenta HTM Community is rad. / . Ullamco dolor reprehenderit sit id non esse voluptate minim cupidatat pariatur nisi sint consequat consectetur Lorem aliqua. Velit cupidatat culpa sunt anim adipisicing in ea in nisi sunt et. Minim magna nisi anim eu deserunt cupidatat pariatur ullamco irure ex deserunt id magna pariatur irure. Ut minim duis duis aliquip nostrud officia esse proident non incididunt sint. Enim labore ut eu voluptate quis culpa amet laboris Lorem sint ipsum ad aliquip dolor. Eu sunt tempor fugiat sit officia aliquip et aliquip dolor amet consequat ea. Veniam in anim fugiat fugiat id occaecat ex et nisi consequat enim duis. Next: Research & Publications ","title":"Numenta HTM Community — Numenta Hierarchical Temporal Memory (HTM) Community and Resources"},{"path":"/legal/privacy/","text":"Privacy Policy Fri, Jul 22, 2016Privacy Policy These terms of service apply to the use of Numenta s streaming analytics product as distributed through cloud service providers (the Grok Product) and for the use of Numenta s web site. Together, the Grok Product and the Numenta web site are called the Numenta Offering. 1. ACCEPTANCE OF TERMS If you do not agree to these Terms, you should not use the Numenta Offering. We reserve the right to change, modify, add or remove portions of these Terms periodically. Such modifications shall be effective immediately upon posting of the modified Terms to the Numenta website. Your continued use of the Numenta Offering will mean that you accept these terms. 2. NO UNLAWFUL OR PROHIBITED USE You warrant to Numenta that you will not use the Numenta Offering, or any of the content therein, for any purpose that is unlawful or that is prohibited by these Terms. 3. LICENSE GRANT Your rights to access, download, and use the Grok Product will be subject to the terms and conditions of the software license agreement provided on the cloud service provider s site through which it is distributed. 4. YOUR CONTENT Numenta will not pre-screen or review your content, but Numenta shall have the right (but not the obligation) in its sole discretion to refuse or delete any content that it reasonably considers to violate the Terms or to be otherwise illegal. You grant Numenta the right to review your content for the purposes of debugging the Numenta Offering and for providing you with technical support. Numenta will not share your content with others without your explicit, written permission, except in the case where being required to do so by the appropriate court or government agency. 5. TERMINATION We may terminate your use of the Numenta Offering if we have reasonable belief that your use: 1) violates these Terms; or 2) abuses site resources or attempts to gain unauthorized entry to the site or site resources; or 3) we are required to do so by law, regulation, court or governing agency order. Our termination of any user s access to the Numenta Offering may be effected without notice and, on such termination, we may immediately deactivate or delete user s account and/or bar any further access to such files. Numenta shall not be liable to any Numenta user or other third party for any such termination. You may terminate your use of the Numenta Offering by stopping its use without notice to us. 6. PAYMENT The Numenta Product is delivered through a cloud service provider s marketplace. You will abide by the payment terms as detailed in that marketplace. If you do not wish to continue using and paying for the Numenta Product, you may stop using it at any time, and further charges will not accrue. We do not offer refunds for any amounts paid. 7. LINKS To the extent the Numenta website includes links to third parties, Numenta is not responsible or liable for the content of such sites. The Numenta website privacy statement is applicable only when you are on the Numenta websites. 8. SUPPORT Technical support for the Grok Product is provided by email. We will make a reasonable effort to respond to your email within 48 hours. Support inquiries are to be sent to support@numenta.com. 9. TRADEMARK INFORMATION Numenta, Grok, NuPIC, and the Numenta, Grok and NuPIC trademarks, logos and service marks are the intellectual property of Numenta, Inc. All trademarks, trade names, service marks and logos referenced herein are the property of their respective owners. 10. COPYRIGHTS If you believe that your work has been copied and is accessible in the Numenta Offering in a way that constitutes copyright infringement, you may notify us by providing our copyright agent with the following information in writing: - the electronic or physical signature of the owner of the copyright or the person authorized to act on the owner s behalf; - identification of the copyrighted work that you claim has been infringed; - identification of the material that is claimed to be infringing and information reasonably sufficient to permit Grok to locate the material; - your name, address, telephone number, and email address; - a statement by you that you have a good faith belief that the disputed use is not authorized by the copyright owner, its agent, or the law; - a statement, made under penalty of perjury, that the above information in your Notice is accurate and that you are the copyright owner or are authorized to act on the copyright owner s behalf. If Numenta receives such a claim, Numenta will investigate and report back to the complainant. Numenta reserves the right to delete such reported content or to terminate a user s account. Our designated agent to receive notification of claimed infringement under the Digital Millennium Copyright Act OF 1998 ( DMCA ) is: dmca@numenta.com 11. VIOLATIONS OF TERMS Please report any violations of the Terms to info@numenta.com. 12. PRIVACY Our Privacy Policy is located at http://numenta.org/legal/privacy/. 2016/07/22 Privacy Policy","title":"Privacy Policy"},{"path":"/legal/terms/","text":"Terms of Service Fri, Jul 22, 2016Terms of Service These terms of service apply to the use of Numenta s streaming analytics product as distributed through cloud service providers (the Grok Product) and for the use of Numenta s web site. Together, the Grok Product and the Numenta web site are called the Numenta Offering. 1. ACCEPTANCE OF TERMS If you do not agree to these Terms, you should not use the Numenta Offering. We reserve the right to change, modify, add or remove portions of these Terms periodically. Such modifications shall be effective immediately upon posting of the modified Terms to the Numenta website. Your continued use of the Numenta Offering will mean that you accept these terms. 2. NO UNLAWFUL OR PROHIBITED USE You warrant to Numenta that you will not use the Numenta Offering, or any of the content therein, for any purpose that is unlawful or that is prohibited by these Terms. 3. LICENSE GRANT Your rights to access, download, and use the Grok Product will be subject to the terms and conditions of the software license agreement provided on the cloud service provider s site through which it is distributed. 4. YOUR CONTENT Numenta will not pre-screen or review your content, but Numenta shall have the right (but not the obligation) in its sole discretion to refuse or delete any content that it reasonably considers to violate the Terms or to be otherwise illegal. You grant Numenta the right to review your content for the purposes of debugging the Numenta Offering and for providing you with technical support. Numenta will not share your content with others without your explicit, written permission, except in the case where being required to do so by the appropriate court or government agency. 5. TERMINATION We may terminate your use of the Numenta Offering if we have reasonable belief that your use: 1) violates these Terms; or 2) abuses site resources or attempts to gain unauthorized entry to the site or site resources; or 3) we are required to do so by law, regulation, court or governing agency order. Our termination of any user s access to the Numenta Offering may be effected without notice and, on such termination, we may immediately deactivate or delete user s account and/or bar any further access to such files. Numenta shall not be liable to any Numenta user or other third party for any such termination. You may terminate your use of the Numenta Offering by stopping its use without notice to us. 6. PAYMENT The Numenta Product is delivered through a cloud service provider s marketplace. You will abide by the payment terms as detailed in that marketplace. If you do not wish to continue using and paying for the Numenta Product, you may stop using it at any time, and further charges will not accrue. We do not offer refunds for any amounts paid. 7. LINKS To the extent the Numenta website includes links to third parties, Numenta is not responsible or liable for the content of such sites. The Numenta website privacy statement is applicable only when you are on the Numenta websites. 8. SUPPORT Technical support for the Grok Product is provided by email. We will make a reasonable effort to respond to your email within 48 hours. Support inquiries are to be sent to support@numenta.com. 9. TRADEMARK INFORMATION Numenta, Grok, NuPIC, and the Numenta, Grok and NuPIC trademarks, logos and service marks are the intellectual property of Numenta, Inc. All trademarks, trade names, service marks and logos referenced herein are the property of their respective owners. 10. COPYRIGHTS If you believe that your work has been copied and is accessible in the Numenta Offering in a way that constitutes copyright infringement, you may notify us by providing our copyright agent with the following information in writing: - the electronic or physical signature of the owner of the copyright or the person authorized to act on the owner s behalf; - identification of the copyrighted work that you claim has been infringed; - identification of the material that is claimed to be infringing and information reasonably sufficient to permit Grok to locate the material; - your name, address, telephone number, and email address; - a statement by you that you have a good faith belief that the disputed use is not authorized by the copyright owner, its agent, or the law; - a statement, made under penalty of perjury, that the above information in your Notice is accurate and that you are the copyright owner or are authorized to act on the copyright owner s behalf. If Numenta receives such a claim, Numenta will investigate and report back to the complainant. Numenta reserves the right to delete such reported content or to terminate a user s account. Our designated agent to receive notification of claimed infringement under the Digital Millennium Copyright Act OF 1998 ( DMCA ) is: dmca@numenta.com 11. VIOLATIONS OF TERMS Please report any violations of the Terms to info@numenta.com. 12. PRIVACY Our Privacy Policy is located at http://numenta.org/legal/privacy/. 2016/07/22 Terms of Service","title":"Terms of Service"},{"path":"/licenses/conduct/","text":"Numenta Code of Conduct Numenta Code of ConductEvent Anti-Harassment Policy Numenta is dedicated to providing a harassment-free event experience for everyone, regardless of gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, or religious preferences. We do not tolerate harassment of event participants in any form. Sexual language and imagery is not appropriate for any event venue, including talks and Hackathon demos. Event participants violating these rules may be sanctioned or expelled from the event without a refund at the discretion of the event organizers. Harassment includes offensive verbal comments related to gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, or religious preferences, sexual images in public spaces, deliberate intimidation, stalking, following, harassing photography or recording, sustained disruption of talks or other events, inappropriate physical contact, and unwelcome sexual attention. Participants asked to stop any harassing behavior are expected to comply immediately. If a participant engages in harassing behavior, the event organizers may take any action they deem appropriate, including warning the offender or expulsion from the event with no refund. If you are being harassed, notice that someone else is being harassed, or have any other concerns, please contact a member of event staff immediately. Event staff can be identified by t-shirts with the word root on the back. Event staff will be happy to help participants contact venue security or local law enforcement, provide escorts, or otherwise assist those experiencing harassment to feel safe for the duration of the event. We value your attendance. - Matt Taylor <matt@numenta.org> - Scott Purdy <scott@numenta.org> - Teri Fry <tfry@numenta.com> - Taylor Wirfs <twirfs@numenta.com> We expect participants to follow these rules at all event venues and event-related social events. Numenta Code of Conduct","title":"Numenta Code of Conduct"},{"path":"/licenses/contrib/","text":"Numenta Contributor License (CL) Numenta Contributor License (CL) Although most open source projects refer to a Contributor License Agreement (CLA) , we have chosen to refer to this agreement as Numenta s Contributor License (CL) to prevent confusion between it and the Cortical Learning Algorithm (CLA) referenced in our source code and documentation. Please read and sign the Numenta Contributor License below: Use your github username as the optional Public Name value. You may also download the Numenta CL in the following formats: - Plain Text - PDF - Word Document Numenta Contributor License (CL)","title":"Numenta Contributor License (CL)"},{"path":"/licenses/","text":"Numenta Licenses Numenta LicensesSummary Our core algorithms are AGPL Version 3, but there are ways you can experiment with our technology without being constrained. We offer both a commercial license option (more details soon) and a trial license, which allows you to experiment temporarily without affecting your codebase with the AGPL, giving you time to decide whether a commercial license is worth it. - NuPIC and associated applications of NuPIC at http://github.com/numenta are licensed as dual commercial and iAGPL version 3 - Commercial licenses are also available from Numenta The goal of the license is to require that enhancements to NuPIC be released to the community. Patents Our CEO, Donna Dubinsky, wrote a blog post about our Patent Position. Contributor License Are you interested in getting involved in this project? You ll first have to sign the Contributor License Trial License In order to experiment with our technology without the constraints of the AGPL, you may sign up for our trial license. This will allow you to work under a temporary license and create a proof-of-concept and decide later whether to convert to a commercial license or go AGPL. Translations We welcome members of the NuPIC community who want to translate our documentation into languages other than English. Feel free to notify us about your translation so that we can link to it from our web site. We cannot take responsibility for the quality of the translations, but we appreciate your efforts to help us spread the word about this technology. We give you the rights to translate these materials under the following license: Copyright 2010-2017 Numenta, Inc. Numenta owns copyrights and patent rights on documentation related to hierarchical temporal memory (HTM) and cortical learning algorithms (CLA). This documentation may include white papers, blog posts, videos, audios, wikipages, text embedded in code, and other explanatory materials. Numenta grants you a license to translate any or all of these materials into languages other than English, and to use internally and distribute your translations subject to the following conditions: Numenta specifically disclaims any liability for the quality of any translations licensed hereunder, and you must include this text, both in this original English and in translation to the target language, in the translation. The foregoing applies only to documentation as described above all Numenta software code and algorithms remain subject to the applicable software license. Numenta Licenses","title":"Numenta Licenses"},{"path":"/licenses/trial/","text":"Numenta Trial License Numenta Trial LicensePlease read and sign the Numenta Trial License document below: You may also download the Numenta Trial License in the following formats: - PDF - Plain Text - Word Document Numenta Trial License","title":"Numenta Trial License"},{"path":"/papers/","text":"Research Papers Research Papers 1. Why Neurons Have Thousands of Synapses, A Theory of Sequence Memory in Neocortex Jeff Hawkins & Subutai Ahmad Neuroscience Published in Frontiers in Neural Circuits Journal 2016/03/30 Foundational paper describing core HTM theory for sequence memory and its relationship to the neocortex. Written with a neuroscience perspective, the paper explains why neurons need so many synapses and how networks of neurons can form a powerful sequence learning mechanism. 2. Continuous Online Sequence Learning with an Unsupervised Neural Network Model Yuwei Cui, Subutai Ahmad, Jeff Hawkins & Chetan Surpur Machine learning Preprint of journal submission 2015/12/17 Analysis of HTM sequence memory applied to various sequence learning and prediction problems. Written with a machine learning perspective, the paper contains some comparisons to statistical and Deep Learning techniques. 3. The HTM Spatial Pooler: A Neocortical Algorithm for Online Sparse Distributed Coding Yuwei Cui, Subutai Ahmad & Jeff Hawkins Neuroscience Preprint of journal submission 2016/11/02 This paper describes an important component of HTM, the HTM spatial pooler, which is a neutrally inspired algorithm that learns sparse distributed representations online. Written from a neuroscience perspective, the paper demonstrates key computational properties of HTM spatial pooler. 4. Evaluating Real-time Anomaly Detection Algorithms - the Numenta Anomaly Benchmark Alexander Lavin & Subutai Ahmad Machine learning Published conference paper 2015/10/12 14th IEEE ICMLA 2015 - This paper discusses how we should think about anomaly detection for streaming applications. It introduces a new open-source benchmark for detecting anomalies in real-time, time-series data. 5. Real-Time Anomaly Detection for Streaming Analytics Subutai Ahmad & Scott Purdy Machine learning Preprint of journal submission 2016/07/08 Much of the worlds data is streaming, time-series data, where anomalies give significant information in critical situations. Yet detecting anomalies in streaming data is a difficult task, requiring detectors to process data in real-time, and learn while simultaneously making predictions. 6. How Do Neurons Operate on Sparse Distributed Representations? A Mathematical Theory of Sparsity, Neurons and Active Dendrites Subutai Ahmad & Jeff Hawkins Neuroscience Preprint of journal submission 2016/01/05 This paper describes a mathematical model for quantifying the benefits and limitations of sparse representations in neurons and cortical networks. 7. Properties of Sparse Distributed Representations and their Application To Hierarchical Temporal Memory Subutai Ahmad & Jeff Hawkins Neuroscience Research Paper 2014/10/28 An earlier version of the above submission, this paper applies our mathematical model of sparse representations to practical HTM systems. 8. Encoding Data for HTM Systems Scott Purdy Machine learning Research Paper 2016/02/18 Hierarchical Temporal Memory (HTM) is a biologically inspired machine intelligence technology that mimics the architecture and processes of the neocortex. In this white paper we describe how to encode data as Sparse Distributed Representations (SDRs) for use in HTM systems. We explain several existing encoders, which are available through the open source project called NuPIC, and we discuss requirements for creating encoders for new types of data. 9. Porting HTM Models to the Heidelberg Neuromorphic Computing Platform Sebastian Billaudelle & Subutai Ahmad Neuroscience Research Paper 2015/05/08 Recently there has been much interest in building custom hardware implementations of HTM systems. This paper discusses one such scenario, and shows how to port HTM algorithms to analog hardware platforms such as the one developed by the Human Brain Project. ","title":"Research Papers"},{"path":"/research-and-publications/","text":"Research &amp;amp; Publications Research &amp; PublicationsAside Numenta s unique approach of focusing on large-scale cortical theory and simulation drives us to tackle one of humanity s greatest scientific challenges: reverse-engineering the neocortex. - Jeff Hawkins Numenta s team of researchers focuses on developing a comprehensive theory of the neocortex what it does and how its architecture implements this. We test our theories via simulation, mathematical analysis and collaborative partnerships with experimental laboratories, and we document our research in two primary forms: a living book called BAMI (Biological and Machine Intelligence), and scientific publications. Feel free to view our collection of research papers, which include peer-reviewed journal papers. Next: Community ","title":"Research &amp;amp; Publications"}]